{
  "paragraphs": [
    {
      "text": "%md\n\n# Binary Classification Algorithms with Pipelines API\n\nName(s): _student\u0027s name_\nClass: _SISE or BIBD_\n\n\u003chr\u003e\n\nIn this notebook, we will test out the Binary Classification algorithms available in the ML Pipelines API using the Adult dataset. The Pipelines API provides higher-level API built on top of DataFrames for constructing ML pipelines. You can read more about the ML Pipelines API in the [programming guide](http://spark.apache.org/docs/2.0.1/ml-guide.html).\n\n**Binary Classification** is the task of predicting a binary 0 or 1 label.  E.g., is an email spam or not spam?  Should I show this ad to this user or not?  Will it rain tomorrow or not?  This notebook demonstrates several algorithms for making these types of predictions.\n\n\u003chr\u003e\n\nThis notebook will act as your written assignment. As such, it should contain your code and all necessary explanations, like why did you use that or why do you think this happens. When I read it at the end, I should understand all of your reasoning.\n\nDon\u0027t forget to __frequently__ commit your code and push it back to Github. A good advice would be that anytime your answer a question with code and explanation, you should commit a message referencing the question and push it to Github. By versioning frequently, you keep a good history of your work and can eventually return back. At the end of the assignment, you will notify me of your work via a pull request.\n\nYour mark will be based on:\n- your commit activity\n- completing the full analysis of the dataset, from describing it to predicting the income value and evaluating that\n\nThe questions I have put serve as a guideline, but you are totally free to change the text and put your own descriptions (which is absolutely appreciated because it shows you have fully comprehended the problem)\n\n\u003chr\u003e\n\n####Table of Contents\n\n* Dataset Review\n* Load Data\n* Descriptive analysis\n* Data Preprocessing\n* Creation of models\n* Conclusion",
      "dateUpdated": "Feb 7, 2017 12:55:37 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110006257_-279747651",
      "id": "20170203-082006_1849162249",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eBinary Classification Algorithms with Pipelines API\u003c/h1\u003e\n\u003cp\u003eName(s): \u003cem\u003estudent\u0027s name\u003c/em\u003e\n\u003cbr  /\u003eClass: \u003cem\u003eSISE or BIBD\u003c/em\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIn this notebook, we will test out the Binary Classification algorithms available in the ML Pipelines API using the Adult dataset. The Pipelines API provides higher-level API built on top of DataFrames for constructing ML pipelines. You can read more about the ML Pipelines API in the \u003ca href\u003d\"http://spark.apache.org/docs/2.0.1/ml-guide.html\"\u003eprogramming guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBinary Classification\u003c/strong\u003e is the task of predicting a binary 0 or 1 label.  E.g., is an email spam or not spam?  Should I show this ad to this user or not?  Will it rain tomorrow or not?  This notebook demonstrates several algorithms for making these types of predictions.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eThis notebook will act as your written assignment. As such, it should contain your code and all necessary explanations, like why did you use that or why do you think this happens. When I read it at the end, I should understand all of your reasoning.\u003c/p\u003e\n\u003cp\u003eDon\u0027t forget to \u003cstrong\u003efrequently\u003c/strong\u003e commit your code and push it back to Github. A good advice would be that anytime your answer a question with code and explanation, you should commit a message referencing the question and push it to Github. By versioning frequently, you keep a good history of your work and can eventually return back. At the end of the assignment, you will notify me of your work via a pull request.\u003c/p\u003e\n\u003cp\u003eYour mark will be based on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eyour commit activity\u003c/li\u003e\n\u003cli\u003ecompleting the full analysis of the dataset, from describing it to predicting the income value and evaluating that\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe questions I have put serve as a guideline, but you are totally free to change the text and put your own descriptions (which is absolutely appreciated because it shows you have fully comprehended the problem)\u003c/p\u003e\n\u003chr\u003e\n\u003ch4\u003eTable of Contents\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eDataset Review\u003c/li\u003e\n\u003cli\u003eLoad Data\u003c/li\u003e\n\u003cli\u003eDescriptive analysis\u003c/li\u003e\n\u003cli\u003eData Preprocessing\u003c/li\u003e\n\u003cli\u003eCreation of models\u003c/li\u003e\n\u003cli\u003eConclusion\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:20:06 AM",
      "dateStarted": "Feb 7, 2017 12:55:38 PM",
      "dateFinished": "Feb 7, 2017 12:55:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## I. Dataset review\n\nThe Adult dataset is publicly available at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult). This data was obtained from the Census, and consists of information about 48842 individuals and their annual income. We will use this information to predict if an individual earns \u003e50k a year or \u003c\u003d50K a year. The dataset is rather clean, and consists of both numeric and categorical variables.\n\nAttribute Information:\n- age: continuous\n- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n- fnlwgt: continuous\n- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc...\n- education-num: continuous\n- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent...\n- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners...\n- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n- sex: Female, Male. \n- capital-gain: continuous\n- capital-loss: continuous\n- hours-per-week: continuous\n- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany...\n\n\nTarget/Label:\n- \u003c\u003d50K, \u003e50K",
      "dateUpdated": "Feb 7, 2017 12:55:38 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110092601_361345828",
      "id": "20170203-082132_1615989350",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eI. Dataset review\u003c/h2\u003e\n\u003cp\u003eThe Adult dataset is publicly available at the \u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/Adult\"\u003eUCI Machine Learning Repository\u003c/a\u003e. This data was obtained from the Census, and consists of information about 48842 individuals and their annual income. We will use this information to predict if an individual earns \u003e50k a year or \u0026lt;\u003d50K a year. The dataset is rather clean, and consists of both numeric and categorical variables.\u003c/p\u003e\n\u003cp\u003eAttribute Information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eage: continuous\u003c/li\u003e\n\u003cli\u003eworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\u003c/li\u003e\n\u003cli\u003efnlwgt: continuous\u003c/li\u003e\n\u003cli\u003eeducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc\u0026hellip;\u003c/li\u003e\n\u003cli\u003eeducation-num: continuous\u003c/li\u003e\n\u003cli\u003emarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent\u0026hellip;\u003c/li\u003e\n\u003cli\u003eoccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners\u0026hellip;\u003c/li\u003e\n\u003cli\u003erelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\u003c/li\u003e\n\u003cli\u003erace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\u003c/li\u003e\n\u003cli\u003esex: Female, Male.\u003c/li\u003e\n\u003cli\u003ecapital-gain: continuous\u003c/li\u003e\n\u003cli\u003ecapital-loss: continuous\u003c/li\u003e\n\u003cli\u003ehours-per-week: continuous\u003c/li\u003e\n\u003cli\u003enative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTarget/Label:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003c\u003d50K, \u003e50K\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:21:32 AM",
      "dateStarted": "Feb 7, 2017 12:55:40 PM",
      "dateFinished": "Feb 7, 2017 12:55:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## II. Load data\n\nI have downloaded adult.data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult) and put it into the `data/` folder of your project.\n\nThe following cells will do the necessary to load the data into a DataFrame.",
      "dateUpdated": "Mar 10, 2017 9:27:07 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110944465_2111795148",
      "id": "20170203-083544_2073974112",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eII. Load data\u003c/h2\u003e\n\u003cp\u003eI have downloaded adult.data from the \u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/Adult\"\u003eUCI Machine Learning Repository\u003c/a\u003e and put it into the \u003ccode\u003edata/\u003c/code\u003e folder of your project.\u003c/p\u003e\n\u003cp\u003eThe following cells will do the necessary to load the data into a DataFrame.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:35:44 AM",
      "dateStarted": "Mar 10, 2017 9:27:07 PM",
      "dateFinished": "Mar 10, 2017 9:27:07 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load data (run the cell)",
      "text": "import org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField}\n\nval schema \u003d StructType(Seq(\n    StructField(\"age\", DoubleType),\n    StructField(\"workclass\", StringType),\n    StructField(\"fnlwgt\", DoubleType),\n    StructField(\"education\", StringType),\n    StructField(\"education_num\", DoubleType),\n    StructField(\"marital_status\", StringType),\n    StructField(\"occupation\", StringType),\n    StructField(\"relationship\", StringType),\n    StructField(\"race\", StringType),\n    StructField(\"sex\", StringType),\n    StructField(\"capital_gain\", DoubleType),\n    StructField(\"capital_loss\", DoubleType),\n    StructField(\"hours_per_week\", DoubleType),\n    StructField(\"native_country\", StringType),\n    StructField(\"income\", StringType)\n    ))\n\ncase class Adult(\n    age: Double, \n    workclass: String, \n    fnlwgt: Double, \n    education: String, \n    education_num: Double, \n    marital_status: String, \n    occupation: String, \n    relationship: String, \n    race: String, \n    sex: String, \n    capital_gain: Double, \n    capital_loss: Double, \n    hours_per_week: Double, \n    native_country: String, \n    income: String\n    )\n    \nval dataset \u003d spark.read.schema(schema).csv(\"/opt/dataset/adult.data.csv\").as[Adult]\ndataset.registerTempTable(\"dataset\") \n",
      "dateUpdated": "Mar 10, 2017 9:27:11 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486111413898_843508411",
      "id": "20170203-084333_2125853520",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField}\n\nschema: org.apache.spark.sql.types.StructType \u003d StructType(StructField(age,DoubleType,true), StructField(workclass,StringType,true), StructField(fnlwgt,DoubleType,true), StructField(education,StringType,true), StructField(education_num,DoubleType,true), StructField(marital_status,StringType,true), StructField(occupation,StringType,true), StructField(relationship,StringType,true), StructField(race,StringType,true), StructField(sex,StringType,true), StructField(capital_gain,DoubleType,true), StructField(capital_loss,DoubleType,true), StructField(hours_per_week,DoubleType,true), StructField(native_country,StringType,true), StructField(income,StringType,true))\n\ndefined class Adult\n\ndataset: org.apache.spark.sql.Dataset[Adult] \u003d [age: double, workclass: string ... 13 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"
      },
      "dateCreated": "Feb 3, 2017 8:43:33 AM",
      "dateStarted": "Mar 10, 2017 9:27:12 PM",
      "dateFinished": "Mar 10, 2017 9:27:36 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\nLe fichier CSV adult.data.csv contient les 48842 personnes à étudier.\nCe fichier est déjà stocké dans la VM, à l\u0027emplacement /opt/dataset/adult.data.csv\nDans notre dépot GIT, le fichier CSV est présent dans le répertoire data/ il a été déposé sur la VM lors du vagrant up.\n\nLa méthode registerTempTable permet de déclarer les données comme s\u0027il s\u0027agissait d\u0027une table \"dataset\". Cette table temporaire pourra être appelée dans des blocs %sql\n\nNous réutiliserons ce mécanisme plus tard lorsque nous séparerons les personnes gagnant moins et plus de 50K dans deux datasets différents.",
      "dateUpdated": "Mar 10, 2017 11:34:33 AM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487263861652_-1383455283",
      "id": "20170216-165101_1076965843",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\n\u003cbr  /\u003eLe fichier CSV adult.data.csv contient les 48842 personnes à étudier.\n\u003cbr  /\u003eCe fichier est déjà stocké dans la VM, à l\u0027emplacement /opt/dataset/adult.data.csv\n\u003cbr  /\u003eDans notre dépot GIT, le fichier CSV est présent dans le répertoire data/ il a été déposé sur la VM lors du vagrant up.\u003c/p\u003e\n\u003cp\u003eLa méthode registerTempTable permet de déclarer les données comme s\u0027il s\u0027agissait d\u0027une table \u0026ldquo;dataset\u0026rdquo;. Cette table temporaire pourra être appelée dans des blocs %sql\u003c/p\u003e\n\u003cp\u003eNous réutiliserons ce mécanisme plus tard lorsque nous séparerons les personnes gagnant moins et plus de 50K dans deux datasets différents.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 16, 2017 4:51:01 AM",
      "dateStarted": "Mar 10, 2017 11:34:32 AM",
      "dateFinished": "Mar 10, 2017 11:34:32 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "dataset.printSchema()",
      "dateUpdated": "Feb 8, 2017 6:51:45 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486388735078_22636095",
      "id": "20170206-134535_81642944",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- age: double (nullable \u003d true)\n |-- workclass: string (nullable \u003d true)\n |-- fnlwgt: double (nullable \u003d true)\n |-- education: string (nullable \u003d true)\n |-- education_num: double (nullable \u003d true)\n |-- marital_status: string (nullable \u003d true)\n |-- occupation: string (nullable \u003d true)\n |-- relationship: string (nullable \u003d true)\n |-- race: string (nullable \u003d true)\n |-- sex: string (nullable \u003d true)\n |-- capital_gain: double (nullable \u003d true)\n |-- capital_loss: double (nullable \u003d true)\n |-- hours_per_week: double (nullable \u003d true)\n |-- native_country: string (nullable \u003d true)\n |-- income: string (nullable \u003d true)\n\n"
      },
      "dateCreated": "Feb 6, 2017 1:45:35 AM",
      "dateStarted": "Feb 8, 2017 6:28:49 AM",
      "dateFinished": "Feb 8, 2017 6:28:49 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql SELECT * FROM dataset LIMIT 10",
      "dateUpdated": "Mar 5, 2017 6:05:50 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486111269173_-275508312",
      "id": "20170203-084109_2027837333",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "age\tworkclass\tfnlwgt\teducation\teducation_num\tmarital_status\toccupation\trelationship\trace\tsex\tcapital_gain\tcapital_loss\thours_per_week\tnative_country\tincome\n39.0\t State-gov\t77516.0\t Bachelors\t13.0\t Never-married\t Adm-clerical\t Not-in-family\t White\t Male\t2174.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n50.0\t Self-emp-not-inc\t83311.0\t Bachelors\t13.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t0.0\t0.0\t13.0\t United-States\t \u003c\u003d50K\n38.0\t Private\t215646.0\t HS-grad\t9.0\t Divorced\t Handlers-cleaners\t Not-in-family\t White\t Male\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n53.0\t Private\t234721.0\t 11th\t7.0\t Married-civ-spouse\t Handlers-cleaners\t Husband\t Black\t Male\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n28.0\t Private\t338409.0\t Bachelors\t13.0\t Married-civ-spouse\t Prof-specialty\t Wife\t Black\t Female\t0.0\t0.0\t40.0\t Cuba\t \u003c\u003d50K\n37.0\t Private\t284582.0\t Masters\t14.0\t Married-civ-spouse\t Exec-managerial\t Wife\t White\t Female\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n49.0\t Private\t160187.0\t 9th\t5.0\t Married-spouse-absent\t Other-service\t Not-in-family\t Black\t Female\t0.0\t0.0\t16.0\t Jamaica\t \u003c\u003d50K\n52.0\t Self-emp-not-inc\t209642.0\t HS-grad\t9.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t0.0\t0.0\t45.0\t United-States\t \u003e50K\n31.0\t Private\t45781.0\t Masters\t14.0\t Never-married\t Prof-specialty\t Not-in-family\t White\t Female\t14084.0\t0.0\t50.0\t United-States\t \u003e50K\n42.0\t Private\t159449.0\t Bachelors\t13.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t5178.0\t0.0\t40.0\t United-States\t \u003e50K\n"
      },
      "dateCreated": "Feb 3, 2017 8:41:09 AM",
      "dateStarted": "Mar 5, 2017 6:05:45 AM",
      "dateFinished": "Mar 5, 2017 6:05:45 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Check settings of graph. See how we average age by income.",
      "text": "%sql SELECT income, avg(age) FROM dataset group by income",
      "dateUpdated": "Mar 5, 2017 6:05:56 AM",
      "config": {
        "colWidth": 5.0,
        "graph": {
          "mode": "pieChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "income",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "avg(age)",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "income",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486412404414_-1397675343",
      "id": "20170206-202004_49344056",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "income\tavg(age)\n \u003e50K\t44.24984058155847\n \u003c\u003d50K\t36.78373786407767\n"
      },
      "dateCreated": "Feb 6, 2017 8:20:04 AM",
      "dateStarted": "Mar 5, 2017 6:05:56 AM",
      "dateFinished": "Mar 5, 2017 6:06:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nPour connaitre l\u0027âge moyen par revenus il suffit de grouper les individus par revenus et faire une moyenne sur l\u0027age.\n\nLa moyenne d\u0027age est de 36.78 ans pour les personnes qui gagnent \u003c\u003d 50K\nLa moyenne d\u0027age est de 44.25 ans pour les personnes qui gagnent \u003e\u003d 50K",
      "dateUpdated": "Mar 9, 2017 11:15:51 AM",
      "config": {
        "colWidth": 7.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487264200555_1724837491",
      "id": "20170216-165640_1266315688",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003ePour connaitre l\u0027âge moyen par revenus il suffit de grouper les individus par revenus et faire une moyenne sur l\u0027age.\u003c/p\u003e\n\u003cp\u003eLa moyenne d\u0027age est de 36.78 ans pour les personnes qui gagnent \u003c\u003d 50K\n\u003cbr  /\u003eLa moyenne d\u0027age est de 44.25 ans pour les personnes qui gagnent \u003e\u003d 50K\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 16, 2017 4:56:40 AM",
      "dateStarted": "Mar 9, 2017 11:15:51 AM",
      "dateFinished": "Mar 9, 2017 11:15:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## III. Descriptive analysis\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nProvide a summary statistics graph for some columns you deem interesting. Summary statistics is comprised (but not limited) of:\n* mean, standard deviation and skewness for numeric columns.\n* counts and percentage of each value for categorical columns.\n\nIf you can, try to separate the two income groups and compare.\n\nTwo ways of doing this:\n* You should be able to it using standard SQL queries on the DataFrame and `show()` the result\n* You can use the %sql interpreter like in the previous cell and then use the settings tab of your graph to display the desired results.",
      "dateUpdated": "Feb 13, 2017 9:48:22 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 272.29998779296875,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112392026_-185455167",
      "id": "20170203-085952_1247149665",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eIII. Descriptive analysis\u003c/h2\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eProvide a summary statistics graph for some columns you deem interesting. Summary statistics is comprised (but not limited) of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emean, standard deviation and skewness for numeric columns.\u003c/li\u003e\n\u003cli\u003ecounts and percentage of each value for categorical columns.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you can, try to separate the two income groups and compare.\u003c/p\u003e\n\u003cp\u003eTwo ways of doing this:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou should be able to it using standard SQL queries on the DataFrame and \u003ccode\u003eshow()\u003c/code\u003e the result\u003c/li\u003e\n\u003cli\u003eYou can use the %sql interpreter like in the previous cell and then use the settings tab of your graph to display the desired results.\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:59:52 AM",
      "dateStarted": "Feb 8, 2017 6:53:34 AM",
      "dateFinished": "Feb 8, 2017 6:53:34 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Age moyen",
      "text": "%sql \n\nSELECT avg(age) AS Age_Moyen FROM dataset\n\n-- Quel est l\u0027âge moyen des individus de notre jeu de données ?",
      "dateUpdated": "Mar 10, 2017 11:35:19 AM",
      "config": {
        "colWidth": 2.0,
        "graph": {
          "mode": "table",
          "height": 94.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "Age_Moyen",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "Age_Moyen",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486579937459_-683291247",
      "id": "20170208-185217_1362656673",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "Age_Moyen\n38.58164675532078\n"
      },
      "dateCreated": "Feb 8, 2017 6:52:17 AM",
      "dateStarted": "Mar 10, 2017 11:35:16 AM",
      "dateFinished": "Mar 10, 2017 11:35:17 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\n\n SELECT std(hours_per_week) AS Ecart_Type_Heures_travaillees FROM dataset\n\n-- Quel est l\u0027écart type des heures travaillées par semaine ?",
      "dateUpdated": "Mar 5, 2017 6:06:50 AM",
      "config": {
        "colWidth": 2.0,
        "graph": {
          "mode": "table",
          "height": 102.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "Ecart_Type_Heures_travaillees",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "Ecart_Type_Heures_travaillees",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487019764419_-845965147",
      "id": "20170213-210244_1421315429",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "Ecart_Type_Heures_travaillees\n12.347428681731838\n"
      },
      "dateCreated": "Feb 13, 2017 9:02:44 AM",
      "dateStarted": "Mar 5, 2017 6:06:50 AM",
      "dateFinished": "Mar 5, 2017 6:06:54 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql \n\nselect workclass, CONCAT(ROUND(100. * count(*) / sum(count(*)) over (),2), \u0027%\u0027) as pourcentage\nfrom dataset\ngroup by workclass",
      "dateUpdated": "Mar 5, 2017 6:06:53 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 244.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "workclass",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "pourcentage",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "workclass",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487020447032_586280985",
      "id": "20170213-211407_1205436429",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "workclass\tpourcentage\n State-gov\t3.99%\n Federal-gov\t2.95%\n Self-emp-not-inc\t7.80%\n Local-gov\t6.43%\n Private\t69.70%\n ?\t5.64%\n Self-emp-inc\t3.43%\n Without-pay\t0.04%\n Never-worked\t0.02%\n"
      },
      "dateCreated": "Feb 13, 2017 9:14:07 AM",
      "dateStarted": "Mar 5, 2017 6:06:53 AM",
      "dateFinished": "Mar 5, 2017 6:07:04 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql \n\nselect sex, CONCAT(ROUND(100. * count(*) / sum(count(*)) over (),2), \u0027%\u0027) as pourcentage\nfrom dataset\ngroup by sex",
      "dateUpdated": "Mar 5, 2017 6:07:08 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 231.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "pourcentage",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "pourcentage",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487021232620_-933943473",
      "id": "20170213-212712_1708270409",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "sex\tpourcentage\n Male\t66.92%\n Female\t33.08%\n"
      },
      "dateCreated": "Feb 13, 2017 9:27:12 AM",
      "dateStarted": "Mar 5, 2017 6:07:09 AM",
      "dateFinished": "Mar 5, 2017 6:07:17 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql \n\nselect education, ROUND(100. * count(*) / sum(count(*)) over (),2) as pourcentage\nfrom dataset\ngroup by education\norder by pourcentage DESC",
      "dateUpdated": "Mar 5, 2017 6:07:18 AM",
      "config": {
        "colWidth": 2.0,
        "graph": {
          "mode": "table",
          "height": 207.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "pourcentage",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "pourcentage",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487264533439_-77820019",
      "id": "20170216-170213_371421860",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "education\tpourcentage\n HS-grad\t32.25\n Some-college\t22.39\n Bachelors\t16.45\n Masters\t5.29\n Assoc-voc\t4.24\n 11th\t3.61\n Assoc-acdm\t3.28\n 10th\t2.87\n 7th-8th\t1.98\n Prof-school\t1.77\n 9th\t1.58\n 12th\t1.33\n Doctorate\t1.27\n 5th-6th\t1.02\n 1st-4th\t0.52\n Preschool\t0.16\n"
      },
      "dateCreated": "Feb 16, 2017 5:02:13 AM",
      "dateStarted": "Mar 5, 2017 6:07:19 AM",
      "dateFinished": "Mar 5, 2017 6:07:28 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Pourcentage des personnes divorcées en fonction du parcours scolaire suivi.",
      "text": "%sql \nselect education, ROUND(100. * count(*) / sum(count(*)) over (),2) as pourcentage_DIVORCES_par_education \nfrom dataset\nwhere marital_status\u003d\u0027 Divorced\u0027\ngroup by education\norder by pourcentage_DIVORCES_par_education DESC",
      "dateUpdated": "Mar 10, 2017 11:36:31 AM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "stackedAreaChart",
          "height": 362.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "pourcentage_DIVORCES_par_education",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487021301115_-414870711",
      "id": "20170213-212821_1200738567",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "education\tpourcentage_DIVORCES_par_education\n HS-grad\t36.30\n Some-college\t24.06\n Bachelors\t12.29\n Assoc-voc\t5.27\n Masters\t5.24\n Assoc-acdm\t4.57\n 11th\t2.93\n 10th\t2.70\n 7th-8th\t1.64\n 9th\t1.44\n Prof-school\t1.24\n 12th\t0.88\n Doctorate\t0.74\n 5th-6th\t0.45\n 1st-4th\t0.23\n Preschool\t0.02\n"
      },
      "dateCreated": "Feb 13, 2017 9:28:21 AM",
      "dateStarted": "Mar 5, 2017 6:08:14 AM",
      "dateFinished": "Mar 5, 2017 6:08:24 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nNous remarquons que la plus grosse part de divorcés concerne les diplômés d\u0027école supérieure. Ce chiffre n\u0027est pas étonnant car il s\u0027agit de l\u0027éducation suivie par le plus grand nombre d\u0027individus (33.25%).",
      "dateUpdated": "Mar 5, 2017 6:08:12 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 59.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487023124288_-1246680864",
      "id": "20170213-215844_1050398938",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eNous remarquons que la plus grosse part de divorcés concernent les diplômés d\u0027école supérieure. Ce chiffre n\u0027est pas étonnant car il s\u0027agit de l\u0027éducation suivie par le plus grand nombre d\u0027individus (33.25%).\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 13, 2017 9:58:44 AM",
      "dateStarted": "Mar 5, 2017 6:07:52 AM",
      "dateFinished": "Mar 5, 2017 6:07:52 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md Dataset avec uniquement les personnes gagnant plus de 50K. Ces valeurs sont stockées dans une variable datasetGreatherThan50K comme TABLE TEMPORAIRE : ",
      "dateUpdated": "Feb 13, 2017 9:53:28 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487022566868_-451937945",
      "id": "20170213-214926_1984338944",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eDataset avec uniquement les personnes gagnant plus de 50K. Ces valeurs sont stockées dans une variable datasetGreatherThan50K comme TABLE TEMPORAIRE :\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 13, 2017 9:49:26 AM",
      "dateStarted": "Feb 13, 2017 9:53:27 AM",
      "dateFinished": "Feb 13, 2017 9:53:27 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Dataset des personnes gagnant plus de 50K - Play me !",
      "text": "val datasetGreatherThan50K \u003d dataset.filter($\"income\"\u003d\u003d\u003d\" \u003e50K\")\ndatasetGreatherThan50K.registerTempTable(\"datasetGreatherThan50K\")\ndatasetGreatherThan50K.show()",
      "dateUpdated": "Mar 10, 2017 11:39:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487021813840_-1891216826",
      "id": "20170213-213653_1805502090",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ndatasetGreatherThan50K: org.apache.spark.sql.Dataset[Adult] \u003d [age: double, workclass: string ... 13 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+----+-----------------+--------+-------------+-------------+-------------------+----------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n| age|        workclass|  fnlwgt|    education|education_num|     marital_status|      occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n+----+-----------------+--------+-------------+-------------+-------------------+----------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n|52.0| Self-emp-not-inc|209642.0|      HS-grad|          9.0| Married-civ-spouse| Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  \u003e50K|\n|31.0|          Private| 45781.0|      Masters|         14.0|      Never-married|  Prof-specialty| Not-in-family|              White| Female|     14084.0|         0.0|          50.0| United-States|  \u003e50K|\n|42.0|          Private|159449.0|    Bachelors|         13.0| Married-civ-spouse| Exec-managerial|       Husband|              White|   Male|      5178.0|         0.0|          40.0| United-States|  \u003e50K|\n|37.0|          Private|280464.0| Some-college|         10.0| Married-civ-spouse| Exec-managerial|       Husband|              Black|   Male|         0.0|         0.0|          80.0| United-States|  \u003e50K|\n|30.0|        State-gov|141297.0|    Bachelors|         13.0| Married-civ-spouse|  Prof-specialty|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|         India|  \u003e50K|\n|40.0|          Private|121772.0|    Assoc-voc|         11.0| Married-civ-spouse|    Craft-repair|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|             ?|  \u003e50K|\n|43.0| Self-emp-not-inc|292175.0|      Masters|         14.0|           Divorced| Exec-managerial|     Unmarried|              White| Female|         0.0|         0.0|          45.0| United-States|  \u003e50K|\n|40.0|          Private|193524.0|    Doctorate|         16.0| Married-civ-spouse|  Prof-specialty|       Husband|              White|   Male|         0.0|         0.0|          60.0| United-States|  \u003e50K|\n|56.0|        Local-gov|216851.0|    Bachelors|         13.0| Married-civ-spouse|    Tech-support|       Husband|              White|   Male|         0.0|         0.0|          40.0| United-States|  \u003e50K|\n|54.0|                ?|180211.0| Some-college|         10.0| Married-civ-spouse|               ?|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          60.0|         South|  \u003e50K|\n|31.0|          Private| 84154.0| Some-college|         10.0| Married-civ-spouse|           Sales|       Husband|              White|   Male|         0.0|         0.0|          38.0|             ?|  \u003e50K|\n|57.0|      Federal-gov|337895.0|    Bachelors|         13.0| Married-civ-spouse|  Prof-specialty|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States|  \u003e50K|\n|47.0|          Private| 51835.0|  Prof-school|         15.0| Married-civ-spouse|  Prof-specialty|          Wife|              White| Female|         0.0|      1902.0|          60.0|      Honduras|  \u003e50K|\n|50.0|      Federal-gov|251585.0|    Bachelors|         13.0|           Divorced| Exec-managerial| Not-in-family|              White|   Male|         0.0|         0.0|          55.0| United-States|  \u003e50K|\n|43.0|          Private|237993.0| Some-college|         10.0| Married-civ-spouse|    Tech-support|       Husband|              White|   Male|         0.0|         0.0|          40.0| United-States|  \u003e50K|\n|42.0|          Private|116632.0|    Doctorate|         16.0| Married-civ-spouse|  Prof-specialty|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  \u003e50K|\n|53.0|          Private|169846.0|      HS-grad|          9.0| Married-civ-spouse|    Adm-clerical|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States|  \u003e50K|\n|49.0|     Self-emp-inc|191681.0| Some-college|         10.0| Married-civ-spouse| Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States|  \u003e50K|\n|29.0| Self-emp-not-inc|162298.0|    Bachelors|         13.0| Married-civ-spouse|           Sales|       Husband|              White|   Male|         0.0|         0.0|          70.0| United-States|  \u003e50K|\n|44.0|          Private|343591.0|      HS-grad|          9.0|           Divorced|    Craft-repair| Not-in-family|              White| Female|     14344.0|         0.0|          40.0| United-States|  \u003e50K|\n+----+-----------------+--------+-------------+-------------+-------------------+----------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 13, 2017 9:36:53 AM",
      "dateStarted": "Mar 5, 2017 6:08:26 AM",
      "dateFinished": "Mar 5, 2017 6:08:33 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql select round(avg(age), 2) AS MOY_AGE_GT50K from datasetGreatherThan50K",
      "dateUpdated": "Mar 5, 2017 6:08:40 AM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "table",
          "height": 93.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487022706266_-619906293",
      "id": "20170213-215146_2001641306",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "MOY_AGE_GT50K\n44.25\n"
      },
      "dateCreated": "Feb 13, 2017 9:51:46 AM",
      "dateStarted": "Mar 5, 2017 6:08:40 AM",
      "dateFinished": "Mar 5, 2017 6:08:42 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nRemarques :\n\nNous obtenons bien la même valeur que lors de la question \"Check settings of graph. See how we average age by income.\" soit 44.25",
      "dateUpdated": "Feb 16, 2017 5:14:33 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487022916201_-1377570467",
      "id": "20170213-215516_375049382",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eRemarques :\u003c/p\u003e\n\u003cp\u003eNous obtenons bien la même valeur que lors de la question \u0026ldquo;Check settings of graph. See how we average age by income.\u0026rdquo; soit 44.25\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 13, 2017 9:55:16 AM",
      "dateStarted": "Feb 16, 2017 5:14:31 AM",
      "dateFinished": "Feb 16, 2017 5:14:31 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Répartition par âge des individus qui gagne + de 50K",
      "text": "%sql\nSELECT age, count(*) as nb from datasetGreatherThan50K group by age order by age",
      "dateUpdated": "Mar 5, 2017 6:08:55 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "nb",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487265416468_600719389",
      "id": "20170216-171656_558661842",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "age\tnb\n19.0\t2\n21.0\t3\n22.0\t13\n23.0\t12\n24.0\t31\n25.0\t53\n26.0\t63\n27.0\t81\n28.0\t119\n29.0\t134\n30.0\t171\n31.0\t183\n32.0\t189\n33.0\t191\n34.0\t243\n35.0\t217\n36.0\t263\n37.0\t292\n38.0\t282\n39.0\t278\n40.0\t268\n41.0\t279\n42.0\t270\n43.0\t273\n44.0\t281\n45.0\t288\n46.0\t292\n47.0\t288\n48.0\t217\n49.0\t206\n50.0\t261\n51.0\t242\n52.0\t192\n53.0\t189\n54.0\t173\n55.0\t146\n56.0\t118\n57.0\t131\n58.0\t122\n59.0\t133\n60.0\t101\n61.0\t96\n62.0\t67\n63.0\t59\n64.0\t53\n65.0\t43\n66.0\t35\n67.0\t37\n68.0\t27\n69.0\t21\n70.0\t19\n71.0\t16\n72.0\t9\n73.0\t10\n74.0\t12\n75.0\t7\n76.0\t5\n77.0\t5\n78.0\t5\n79.0\t9\n80.0\t2\n81.0\t3\n83.0\t2\n84.0\t1\n90.0\t8\n"
      },
      "dateCreated": "Feb 16, 2017 5:16:56 AM",
      "dateStarted": "Mar 5, 2017 6:08:55 AM",
      "dateFinished": "Mar 5, 2017 6:09:07 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md Dataset avec uniquement les personnes gagnant moins de 51K. Ces valeurs sont stockées dans une variable datasetLowerThan51K  comme TABLE TEMPORAIRE ",
      "dateUpdated": "Mar 10, 2017 11:40:48 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487022589603_936433656",
      "id": "20170213-214949_550643652",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eDataset avec uniquement les personnes gagnant moins de 51K. Ces valeurs sont stockées dans une variable datasetLowerThan51K  comme TABLE TEMPORAIRE\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 13, 2017 9:49:49 AM",
      "dateStarted": "Mar 10, 2017 11:40:48 AM",
      "dateFinished": "Mar 10, 2017 11:40:48 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Dataset des personnes gagnant moins de 51K - Play me !",
      "text": "val datasetLowerThan51K  \u003d dataset.filter($\"income\"\u003d\u003d\u003d\" \u003c\u003d50K\")\ndatasetLowerThan51K.registerTempTable(\"datasetLowerThan51K\")\ndatasetLowerThan51K.show()",
      "dateUpdated": "Mar 10, 2017 11:40:41 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487022388948_-303518459",
      "id": "20170213-214628_1330487947",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ndatasetLowerThan51K: org.apache.spark.sql.Dataset[Adult] \u003d [age: double, workclass: string ... 13 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+----+-----------------+--------+-----------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n| age|        workclass|  fnlwgt|  education|education_num|      marital_status|        occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n+----+-----------------+--------+-----------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n|39.0|        State-gov| 77516.0|  Bachelors|         13.0|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|50.0| Self-emp-not-inc| 83311.0|  Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          13.0| United-States| \u003c\u003d50K|\n|38.0|          Private|215646.0|    HS-grad|          9.0|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|53.0|          Private|234721.0|       11th|          7.0|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|28.0|          Private|338409.0|  Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|         0.0|         0.0|          40.0|          Cuba| \u003c\u003d50K|\n|37.0|          Private|284582.0|    Masters|         14.0|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|49.0|          Private|160187.0|        9th|          5.0| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|         0.0|         0.0|          16.0|       Jamaica| \u003c\u003d50K|\n|23.0|          Private|122272.0|  Bachelors|         13.0|       Never-married|      Adm-clerical|     Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| \u003c\u003d50K|\n|32.0|          Private|205019.0| Assoc-acdm|         12.0|       Never-married|             Sales| Not-in-family|              Black|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|\n|34.0|          Private|245487.0|    7th-8th|          4.0|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|         0.0|         0.0|          45.0|        Mexico| \u003c\u003d50K|\n|25.0| Self-emp-not-inc|176756.0|    HS-grad|          9.0|       Never-married|   Farming-fishing|     Own-child|              White|   Male|         0.0|         0.0|          35.0| United-States| \u003c\u003d50K|\n|32.0|          Private|186824.0|    HS-grad|          9.0|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|38.0|          Private| 28887.0|       11th|          7.0|  Married-civ-spouse|             Sales|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|\n|54.0|          Private|302146.0|    HS-grad|          9.0|           Separated|     Other-service|     Unmarried|              Black| Female|         0.0|         0.0|          20.0| United-States| \u003c\u003d50K|\n|35.0|      Federal-gov| 76845.0|        9th|          5.0|  Married-civ-spouse|   Farming-fishing|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|43.0|          Private|117037.0|       11th|          7.0|  Married-civ-spouse|  Transport-moving|       Husband|              White|   Male|         0.0|      2042.0|          40.0| United-States| \u003c\u003d50K|\n|59.0|          Private|109015.0|    HS-grad|          9.0|            Divorced|      Tech-support|     Unmarried|              White| Female|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|19.0|          Private|168294.0|    HS-grad|          9.0|       Never-married|      Craft-repair|     Own-child|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n|39.0|          Private|367260.0|    HS-grad|          9.0|            Divorced|   Exec-managerial| Not-in-family|              White|   Male|         0.0|         0.0|          80.0| United-States| \u003c\u003d50K|\n|49.0|          Private|193366.0|    HS-grad|          9.0|  Married-civ-spouse|      Craft-repair|       Husband|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|\n+----+-----------------+--------+-----------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 13, 2017 9:46:28 AM",
      "dateStarted": "Mar 5, 2017 6:09:14 AM",
      "dateFinished": "Mar 5, 2017 6:09:20 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql select round(avg(age), 2) AS MOY_AGE_LT51K from datasetLowerThan51K",
      "dateUpdated": "Feb 16, 2017 5:14:57 AM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "table",
          "height": 84.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "MOY_AGE_LT51K",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "MOY_AGE_LT51K",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487023018265_259490131",
      "id": "20170213-215658_127608318",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "MOY_AGE_LT51K\n36.78\n"
      },
      "dateCreated": "Feb 13, 2017 9:56:58 AM",
      "dateStarted": "Feb 13, 2017 9:57:22 AM",
      "dateFinished": "Feb 13, 2017 9:57:23 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nRemarques :\n\nNous obtenons bien la même valeur que lors de la question “Check settings of graph. See how we average age by income.” soit 36.78\n\n",
      "dateUpdated": "Feb 16, 2017 5:14:54 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487023060488_-124996614",
      "id": "20170213-215740_333585468",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eRemarques :\u003c/p\u003e\n\u003cp\u003eNous obtenons bien la même valeur que lors de la question “Check settings of graph. See how we average age by income.” soit 36.78\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 13, 2017 9:57:40 AM",
      "dateStarted": "Feb 16, 2017 5:14:53 AM",
      "dateFinished": "Feb 16, 2017 5:14:53 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Répartition par âge des individus qui gagne - de 51K",
      "text": "%sql\nSELECT age, count(*) as nb from datasetLowerThan51K group by age order by age",
      "dateUpdated": "Mar 5, 2017 6:09:26 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "nb",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "nb",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487265750609_-561534230",
      "id": "20170216-172230_1506605945",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "age\tnb\n17.0\t395\n18.0\t550\n19.0\t710\n20.0\t753\n21.0\t717\n22.0\t752\n23.0\t865\n24.0\t767\n25.0\t788\n26.0\t722\n27.0\t754\n28.0\t748\n29.0\t679\n30.0\t690\n31.0\t705\n32.0\t639\n33.0\t684\n34.0\t643\n35.0\t659\n36.0\t635\n37.0\t566\n38.0\t545\n39.0\t538\n40.0\t526\n41.0\t529\n42.0\t510\n43.0\t497\n44.0\t443\n45.0\t446\n46.0\t445\n47.0\t420\n48.0\t326\n49.0\t371\n50.0\t341\n51.0\t353\n52.0\t286\n53.0\t275\n54.0\t242\n55.0\t273\n56.0\t248\n57.0\t227\n58.0\t244\n59.0\t222\n60.0\t211\n61.0\t204\n62.0\t191\n63.0\t171\n64.0\t155\n65.0\t135\n66.0\t115\n67.0\t114\n68.0\t93\n69.0\t87\n70.0\t70\n71.0\t56\n72.0\t58\n73.0\t54\n74.0\t39\n75.0\t38\n76.0\t41\n77.0\t24\n78.0\t18\n79.0\t13\n80.0\t20\n81.0\t17\n82.0\t12\n83.0\t4\n84.0\t9\n85.0\t3\n86.0\t1\n87.0\t1\n88.0\t3\n90.0\t35\n"
      },
      "dateCreated": "Feb 16, 2017 5:22:30 AM",
      "dateStarted": "Mar 5, 2017 6:09:26 AM",
      "dateFinished": "Mar 5, 2017 6:09:37 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Répartition de l\u0027épargne en fonction du cursus scolaire",
      "text": "%sql SELECT education, education_num, avg(capital_gain) AS avgGain FROM dataset GROUP BY education, education_num ORDER BY education_num DESC ",
      "dateUpdated": "Mar 5, 2017 6:09:51 AM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "stackedAreaChart",
          "height": 294.5,
          "optionOpen": false,
          "keys": [
            {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "avgGain",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486580378006_1346286560",
      "id": "20170208-185938_1116989237",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "education\teducation_num\tavgGain\n Doctorate\t16.0\t4770.145278450364\n Prof-school\t15.0\t10414.416666666666\n Masters\t14.0\t2562.563551944283\n Bachelors\t13.0\t1756.299533146592\n Assoc-acdm\t12.0\t640.3992502343018\n Assoc-voc\t11.0\t715.0513748191028\n Some-college\t10.0\t598.8241667809629\n HS-grad\t9.0\t576.800114274831\n 12th\t8.0\t284.0877598152425\n 11th\t7.0\t215.09787234042554\n 10th\t6.0\t404.57449088960345\n 9th\t5.0\t342.08949416342415\n 7th-8th\t4.0\t233.93962848297213\n 5th-6th\t3.0\t176.02102102102103\n 1st-4th\t2.0\t125.875\n Preschool\t1.0\t898.3921568627451\n"
      },
      "dateCreated": "Feb 8, 2017 6:59:38 AM",
      "dateStarted": "Feb 13, 2017 10:00:03 AM",
      "dateFinished": "Feb 13, 2017 10:00:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \nExplications :\n\nVoyons désormais comment l\u0027épargne est répartie en fonction du cursus scolaire suivi par les individus. Nous notons que ce sont les professeurs d\u0027école qui épargnent le plus !",
      "dateUpdated": "Feb 16, 2017 5:15:36 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486581302073_-1023829082",
      "id": "20170208-191502_1148500300",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eVoyons désormais comment l\u0027épargne est répartie en fonction du cursus scolaire suivi par les individus. Nous notons que ce sont les professeurs d\u0027école qui épargnent le plus !\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 7:15:02 AM",
      "dateStarted": "Feb 16, 2017 5:15:35 AM",
      "dateFinished": "Feb 16, 2017 5:15:35 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Quels-sont les métiers qui engendrent le plus de séparation ?",
      "text": "%sql SELECT occupation, count(*) FROM dataset WHERE marital_status LIKE \"%Divorced%\" OR marital_status LIKE \"%Separated%\" GROUP BY occupation",
      "dateUpdated": "Mar 10, 2017 11:41:57 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "occupation",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(1)",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "occupation",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "count(1)",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486581501567_2020763941",
      "id": "20170208-191821_1247910689",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "occupation\tcount(1)\n Farming-fishing\t82\n Handlers-cleaners\t166\n Prof-specialty\t638\n Adm-clerical\t966\n Exec-managerial\t698\n Craft-repair\t567\n Sales\t527\n ?\t251\n Tech-support\t168\n Transport-moving\t218\n Protective-serv\t95\n Machine-op-inspct\t361\n Other-service\t691\n Priv-house-serv\t40\n"
      },
      "dateCreated": "Feb 8, 2017 7:18:21 AM",
      "dateStarted": "Mar 10, 2017 11:41:53 AM",
      "dateFinished": "Mar 10, 2017 11:41:56 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Répartition des revenus par type de relation",
      "text": "%sql\nselect income, relationship,count(*) from dataset\ngroup by income, relationship",
      "dateUpdated": "Mar 5, 2017 6:11:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "income",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(1)",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "relationship",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "income",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487265936846_617011303",
      "id": "20170216-172536_1518063683",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "income\trelationship\tcount(1)\n \u003e50K\t Other-relative\t37\n \u003e50K\t Unmarried\t218\n \u003e50K\t Wife\t745\n \u003c\u003d50K\t Unmarried\t3228\n \u003e50K\t Husband\t5918\n \u003e50K\t Own-child\t67\n \u003c\u003d50K\t Other-relative\t944\n \u003c\u003d50K\t Wife\t823\n \u003c\u003d50K\t Husband\t7275\n \u003c\u003d50K\t Not-in-family\t7449\n \u003c\u003d50K\t Own-child\t5001\n \u003e50K\t Not-in-family\t856\n"
      },
      "dateCreated": "Feb 16, 2017 5:25:36 AM",
      "dateStarted": "Mar 5, 2017 6:11:54 AM",
      "dateFinished": "Mar 5, 2017 6:12:05 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## IV. Data preprocessing\n\nSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\n\n- Category Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, ...numCategories-1}. This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\n- [One-Hot Encoding](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder). This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))",
      "dateUpdated": "Feb 7, 2017 12:55:41 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112592655_-113447470",
      "id": "20170203-090312_1355361868",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eIV. Data preprocessing\u003c/h2\u003e\n\u003cp\u003eSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCategory Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, \u0026hellip;numCategories-1}. This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#onehotencoder\"\u003eOne-Hot Encoding\u003c/a\u003e. This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:03:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:42 PM",
      "dateFinished": "Feb 7, 2017 12:55:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "One-hot encoding example",
      "text": "val names \u003d Seq(\"color\", \"index\", \"OHE_attr1\", \"OHE_attr2\", \"OHE_attr3\")\nsqlContext.createDataFrame(sc.parallelize(Seq((\"Blue\", 0, 1, 0, 0), (\"Green\", 1, 0, 1, 0), (\"Red\", 2, 0 , 0 , 1)))).toDF(names: _*).show()",
      "dateUpdated": "Feb 7, 2017 12:55:42 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112775316_925418888",
      "id": "20170203-090615_788237777",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nnames: Seq[String] \u003d List(color, index, OHE_attr1, OHE_attr2, OHE_attr3)\n+-----+-----+---------+---------+---------+\n|color|index|OHE_attr1|OHE_attr2|OHE_attr3|\n+-----+-----+---------+---------+---------+\n| Blue|    0|        1|        0|        0|\n|Green|    1|        0|        1|        0|\n|  Red|    2|        0|        0|        1|\n+-----+-----+---------+---------+---------+\n\n"
      },
      "dateCreated": "Feb 3, 2017 9:06:15 AM",
      "dateStarted": "Feb 7, 2017 12:55:53 PM",
      "dateFinished": "Feb 7, 2017 12:55:55 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nIn this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity\u0027s sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\n\nHere, we will use a combination of [StringIndexer](http://spark.apache.org/docs/latest/ml-features.html#stringindexer) and [OneHotEncoder](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder) on each string column to convert the categorical variables. The `OneHotEncoder` will return a SparseVector (which means, for `(8,[4],[1.0])` that the vector has size 8, one only the 4th column contains a value which is 1.0).\n\nSince we will have many stages of feature transformations, we use an [ML Pipeline](http://spark.apache.org/docs/latest/ml-pipeline.html) to tie the stages together.  This simplifies our code. You should especially try to use [the Pipeline example](http://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline).\n\n```scala\n// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// stages for column workclass\nval stringIndexer \u003d new StringIndexer()\n  .setInputCol(\"workclass\")\n  .setOutputCol(\"workclassIndex\")\nval oneHotEncoder \u003d new OneHotEncoder()\n  .setInputCol(stringIndexer.getOutputCol)\n  .setOutputCol(stringIndexer.getInputCol + \"ClassVec\")\n  \n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n  \nval stages \u003d  Seq(stringIndexer, oneHotEncoder) ++ Seq(label_stringIdx) // concatenate 2 sequences of stages\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n  \nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n```\n\nIt is also a good time to transform the income to a label of 0 and 1 for binary classification using the `StringIndexer`.\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\n1. For each categorical column, build a stage of StringIndexer and OneHotEncoder\n2. Add all those stages in a single pipeline\n3. Also add a StringIndexer of the `income` column and name the output column `label`\n3. Check the result by passing your dataset inside the pipeline. Comment \u0026 explain.\n\n_Hint: actually map your sequence of categorical columns to a sequence of stages through FP._",
      "dateUpdated": "Feb 8, 2017 7:42:01 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486113072470_-2067898551",
      "id": "20170203-091112_917554483",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eIn this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity\u0027s sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\u003c/p\u003e\n\u003cp\u003eHere, we will use a combination of \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#stringindexer\"\u003eStringIndexer\u003c/a\u003e and \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#onehotencoder\"\u003eOneHotEncoder\u003c/a\u003e on each string column to convert the categorical variables. The \u003ccode\u003eOneHotEncoder\u003c/code\u003e will return a SparseVector (which means, for \u003ccode\u003e(8,[4],[1.0])\u003c/code\u003e that the vector has size 8, one only the 4th column contains a value which is 1.0).\u003c/p\u003e\n\u003cp\u003eSince we will have many stages of feature transformations, we use an \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-pipeline.html\"\u003eML Pipeline\u003c/a\u003e to tie the stages together.  This simplifies our code. You should especially try to use \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline\"\u003ethe Pipeline example\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003e// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// stages for column workclass\nval stringIndexer \u003d new StringIndexer()\n  .setInputCol(\"workclass\")\n  .setOutputCol(\"workclassIndex\")\nval oneHotEncoder \u003d new OneHotEncoder()\n  .setInputCol(stringIndexer.getOutputCol)\n  .setOutputCol(stringIndexer.getInputCol + \"ClassVec\")\n\n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n\nval stages \u003d  Seq(stringIndexer, oneHotEncoder) ++ Seq(label_stringIdx) // concatenate 2 sequences of stages\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n\nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt is also a good time to transform the income to a label of 0 and 1 for binary classification using the \u003ccode\u003eStringIndexer\u003c/code\u003e.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eFor each categorical column, build a stage of StringIndexer and OneHotEncoder\u003c/li\u003e\n\u003cli\u003eAdd all those stages in a single pipeline\u003c/li\u003e\n\u003cli\u003eAlso add a StringIndexer of the \u003ccode\u003eincome\u003c/code\u003e column and name the output column \u003ccode\u003elabel\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eCheck the result by passing your dataset inside the pipeline. Comment \u0026amp; explain.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cem\u003eHint: actually map your sequence of categorical columns to a sequence of stages through FP.\u003c/em\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:11:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:42 PM",
      "dateFinished": "Feb 7, 2017 12:55:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// Fonction retournant une séquence de StringIndexer \u0026 OneHotEncoder pour un nom de catégorie donné\ndef makeSeq(w: String) \u003d {\n    \n    // w \u003d nom de la colonne à traiter\n    \n    // Construction de notre StringIndexer\n    // Le nom de colonne existante à mapper en entrée est indiqué via setInputCol\n    // Le nom de colonne en sortie est celui indiqué en entrée suffixé par \"Index\"\n    val stringIndexer \u003d new StringIndexer()\n      .setInputCol(w)\n      .setOutputCol(w+\"Index\")\n      \n    // Construction de notre OneHotEncoder\n    // Le nom de colonne à mapper en entrée est celui en sortie du StringIndexer précédemment créé.\n    // Le nom de colonne en sortie est celui de la colonne d\u0027origine suffixé par \"ClassVec\"\n    val oneHotEncoder \u003d new OneHotEncoder()\n      .setInputCol(stringIndexer.getOutputCol)\n      .setOutputCol(w + \"ClassVec\")\n    Seq(stringIndexer, oneHotEncoder)\n}\n\n// Séquence des variables catégorielles non-numériques pour lesquelles nous souhaitons transformer les différents états en vecteurs binaires.\nval nonNumericalColumns \u003d Seq(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\")\n\n// Création des étapes à destination de notre pipeline ML.\n// La méthode flatMap nous permet ici d\u0027appliquer une transformation sur chaque valeur/colonne de nonNumericalColumns\n// Pour chaque nom de colonne, nous obtenons une séquence Seq(stringIndexer, oneHotEncoder) représentant cette colonne.\nval stages \u003d nonNumericalColumns.flatMap(makeSeq)\n\n// Traitement du label. Il nous permettra de vérifier si nos prédictions sont bonnes par la suite.\n// Pour cela, nous devons transformer les différents états de la variable \"income\" en valeurs numériques (via StringIndexer).\n// Pas de transformation one-hot ici car inutile.\nval label_stringIdx \u003d new StringIndexer().setInputCol(\"income\").setOutputCol(\"label\")\n\n// Etape d\u0027assemblage des colonnes (suffixées par ClassVec) en un seul vecteur de colonnes appelé \"features\"\nval assemblerStage \u003d new VectorAssembler().setInputCols(nonNumericalColumns.map(w \u003d\u003e w + \"ClassVec\").toArray).setOutputCol(\"features\")\n\n// Regroupement des étapes à destinations du pipeline\nval finalStages \u003d stages ++ Seq(label_stringIdx) ++ Seq(assemblerStage)\n\n// Création du pipeline et ajout des étapes\nval pipeline \u003d new Pipeline().setStages(finalStages.toArray)\n\n// Applique les étapes du pipeline au jeu de données pour obtenir un model.\nval pipelineModel \u003d pipeline.fit(dataset)\n\n// Transformation des données à l\u0027aide du modèle.\n// Nous stockons les données transformées pour réutilisation.\nval datasetTransformed \u003d pipelineModel.transform(dataset)\n\n// Pour futures requêtes SQL\ndatasetTransformed.registerTempTable(\"datasetTransformed\")\n\ndatasetTransformed.show()\n",
      "dateUpdated": "Mar 10, 2017 9:27:39 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486583214040_-1646994249",
      "id": "20170208-194654_773278192",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\n\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\nmakeSeq: (w: String)Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable}}]\n\nnonNumericalColumns: Seq[String] \u003d List(workclass, education, marital_status, occupation, relationship, race, sex, native_country)\nstages: Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable}}] \u003d List(strIdx_49ae8b28792d, oneHot_f924c010d4cd, strIdx_1331f855aa15, oneHot_a344dc3fa1bc, strIdx_e4bfcce4954a, one...\nlabel_stringIdx: org.apache.spark.ml.feature.StringIndexer \u003d strIdx_cf978c090bbe\n\nassemblerStage: org.apache.spark.ml.feature.VectorAssembler \u003d vecAssembler_00a9e34f686d\nfinalStages: Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable}}] \u003d List(strIdx_49ae8b28792d, oneHot_f924c010d4cd, strIdx_1331f855aa15, oneHot_a344dc3fa1bc, strIdx_e4bfcce4954a, oneHot_4ccd5fce695e, strIdx_aaf31a5f5a8b, oneHot_06b6cdeeef6c, strIdx_90ebaee64c75, oneHot_c45eb5fd085c, strIdx_485f32735277, oneHot_71818ce89e1c, s...\npipeline: org.apache.spark.ml.Pipeline \u003d pipeline_8d81f0faa771\n\npipelineModel: org.apache.spark.ml.PipelineModel \u003d pipeline_8d81f0faa771\n\ndatasetTransformed: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 31 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt|    education|education_num|      marital_status|        occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0|    Bachelors|         13.0|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[4,10,24,32,4...|\n|50.0| Self-emp-not-inc| 83311.0|    Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          13.0| United-States| \u003c\u003d50K|           1.0|    (8,[1],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[1,10,23,31,4...|\n|38.0|          Private|215646.0|      HS-grad|          9.0|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           0.0|   (15,[0],[1.0])|                2.0|         (6,[2],[1.0])|            9.0|    (14,[9],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,8,25,38,44...|\n|53.0|          Private|234721.0|         11th|          7.0|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           5.0|   (15,[5],[1.0])|                0.0|         (6,[0],[1.0])|            9.0|    (14,[9],[1.0])|              0.0|       (5,[0],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,13,23,38,4...|\n|28.0|          Private|338409.0|    Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|         0.0|         0.0|          40.0|          Cuba| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            0.0|    (14,[0],[1.0])|              4.0|       (5,[4],[1.0])|      1.0|(4,[1],[1.0])|     1.0|    (1,[],[])|                9.0|        (41,[9],[1.0])|  0.0|(94,[0,10,23,29,4...|\n|37.0|          Private|284582.0|      Masters|         14.0|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           3.0|   (15,[3],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              4.0|       (5,[4],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,11,23,31,4...|\n|49.0|          Private|160187.0|          9th|          5.0| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|         0.0|         0.0|          16.0|       Jamaica| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|          10.0|  (15,[10],[1.0])|                5.0|         (6,[5],[1.0])|            5.0|    (14,[5],[1.0])|              1.0|       (5,[1],[1.0])|      1.0|(4,[1],[1.0])|     1.0|    (1,[],[])|               11.0|       (41,[11],[1.0])|  0.0|(94,[0,18,28,34,4...|\n|52.0| Self-emp-not-inc|209642.0|      HS-grad|          9.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  \u003e50K|           1.0|    (8,[1],[1.0])|           0.0|   (15,[0],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|(94,[1,8,23,31,43...|\n|31.0|          Private| 45781.0|      Masters|         14.0|       Never-married|    Prof-specialty| Not-in-family|              White| Female|     14084.0|         0.0|          50.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           3.0|   (15,[3],[1.0])|                1.0|         (6,[1],[1.0])|            0.0|    (14,[0],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  1.0|(94,[0,11,24,29,4...|\n|42.0|          Private|159449.0|    Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|      5178.0|         0.0|          40.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|(94,[0,10,23,31,4...|\n|37.0|          Private|280464.0| Some-college|         10.0|  Married-civ-spouse|   Exec-managerial|       Husband|              Black|   Male|         0.0|         0.0|          80.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           1.0|   (15,[1],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|(94,[0,9,23,31,43...|\n|30.0|        State-gov|141297.0|    Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|         India|  \u003e50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            0.0|    (14,[0],[1.0])|              0.0|       (5,[0],[1.0])|      2.0|(4,[2],[1.0])|     0.0|(1,[0],[1.0])|                8.0|        (41,[8],[1.0])|  1.0|(94,[4,10,23,29,4...|\n|23.0|          Private|122272.0|    Bachelors|         13.0|       Never-married|      Adm-clerical|     Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              2.0|       (5,[2],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,10,24,32,4...|\n|32.0|          Private|205019.0|   Assoc-acdm|         12.0|       Never-married|             Sales| Not-in-family|              Black|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           6.0|   (15,[6],[1.0])|                1.0|         (6,[1],[1.0])|            4.0|    (14,[4],[1.0])|              1.0|       (5,[1],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,14,24,33,4...|\n|40.0|          Private|121772.0|    Assoc-voc|         11.0|  Married-civ-spouse|      Craft-repair|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|             ?|  \u003e50K|           0.0|    (8,[0],[1.0])|           4.0|   (15,[4],[1.0])|                0.0|         (6,[0],[1.0])|            1.0|    (14,[1],[1.0])|              0.0|       (5,[0],[1.0])|      2.0|(4,[2],[1.0])|     0.0|(1,[0],[1.0])|                2.0|        (41,[2],[1.0])|  1.0|(94,[0,12,23,30,4...|\n|34.0|          Private|245487.0|      7th-8th|          4.0|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|         0.0|         0.0|          45.0|        Mexico| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           8.0|   (15,[8],[1.0])|                0.0|         (6,[0],[1.0])|            8.0|    (14,[8],[1.0])|              0.0|       (5,[0],[1.0])|      3.0|(4,[3],[1.0])|     0.0|(1,[0],[1.0])|                1.0|        (41,[1],[1.0])|  0.0|(94,[0,16,23,37,4...|\n|25.0| Self-emp-not-inc|176756.0|      HS-grad|          9.0|       Never-married|   Farming-fishing|     Own-child|              White|   Male|         0.0|         0.0|          35.0| United-States| \u003c\u003d50K|           1.0|    (8,[1],[1.0])|           0.0|   (15,[0],[1.0])|                1.0|         (6,[1],[1.0])|           10.0|   (14,[10],[1.0])|              2.0|       (5,[2],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[1,8,24,39,45...|\n|32.0|          Private|186824.0|      HS-grad|          9.0|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           0.0|   (15,[0],[1.0])|                1.0|         (6,[1],[1.0])|            6.0|    (14,[6],[1.0])|              3.0|       (5,[3],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,8,24,35,46...|\n|38.0|          Private| 28887.0|         11th|          7.0|  Married-civ-spouse|             Sales|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           5.0|   (15,[5],[1.0])|                0.0|         (6,[0],[1.0])|            4.0|    (14,[4],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(94,[0,13,23,33,4...|\n|43.0| Self-emp-not-inc|292175.0|      Masters|         14.0|            Divorced|   Exec-managerial|     Unmarried|              White| Female|         0.0|         0.0|          45.0| United-States|  \u003e50K|           1.0|    (8,[1],[1.0])|           3.0|   (15,[3],[1.0])|                2.0|         (6,[2],[1.0])|            2.0|    (14,[2],[1.0])|              3.0|       (5,[3],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  1.0|(94,[1,11,25,31,4...|\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 8, 2017 7:46:54 AM",
      "dateStarted": "Mar 10, 2017 9:27:39 PM",
      "dateFinished": "Mar 10, 2017 9:28:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nQuelques explications :\n\nSpark ML fournit des outils permettant d\u0027enchainer des traitements sur des données dans un seul pipeline ou \"workflow\". Dans un contexte machine-learning, il est très facile de transformer des données, y appliquer des algorithmes et obtenir un modèle de prédiction qui pourra être validé sur un jeux de données \"Test\" (évaluation du taux d\u0027erreur de prédiction). Pour cela, il va nous falloir appliquer des transformations sur nos colonnes catégorielles (qui donneront lieu à de nouvelles colonnes).\n\nDans un premier temps nous allons transformer nos variables catégorielles en indices numériques. Ces indices sont affectés par fréquence d\u0027occurence, les états les plus fréquents auront une valeur d\u0027indice faible, les moins fréquents auront une valeur plus élevée (valeurs évidemment identiques pour un même état). Ces informations serviront à alimenter le système de transformation one-hot que nous allons voir juste après. Elles nous serviront également à la fin de ce NoteBook où nous aurons besoin de faire des calculs sur des valeurs numériques [Double]. \n-\u003e StringIndexer permet de convertir des variables catégorielles en indices catégoriels.\n\nUn encodage one-hot appliqué sur une variable catégorielle non numérique permet de représenter ses différents états de manière binaire. Dans notre cas d\u0027étude spark il s\u0027agit de vecteurs binaires. \nImaginons une variable à trois états \"Wife\", \"Husband\", \"Own-child\". \nLa représentation one-hot des états de cette variable serait :\n001, 010, 100 ou (3,[3],[1.0]), (3,[2],[1.0]), (3,[1],[1.0]). \nCe dispositif n\u0027est pertinent que si le nombre d\u0027états n\u0027est pas trop important, dans notre cas il convient très bien pour notre jeu de données !\n-\u003e OneHotEncoder associe une colonne d\u0027indices catégoriels à une colonne de vecteur binaire. Nous nous basons ici sur StringIndexer.\n\n--\u003e VectorAssembler permet de combiner une liste donnée de colonnes en un simple vecteur de colonnes (expliqué plus en détail par la suite). Il donnera lieu à la fameuse colonne \"features\".\n\nREMARQUE :\nInutile de représenter la variable income (notre label) en vecteur binaire car il n\u0027y a que 2 états possibles (\u003e50K ou \u003c\u003d50K), ce qui équivaut à 0 ou 1. StringIndexer suffit dans notre cas.\n\n-\u003e datasetTransformed.show() \u003c-\nNous pouvons visualiser le résultat de la transformation via la méthode show(). Nous retrouvons les colonnes numériques de notre dataset (ex : age, fnlwgt, capital_gain, etc ...) sur lesquelles nous n\u0027avons effectué aucun traitement.\nNous retrouvons également les colonnes non-numériques du dataset (ex : workclass, education, occupation, etc ...) sur lesquelles nous avons effectué une transformation vectorielle. Le résultat de cette transformation est stocké dans une colonne du même nom + le suffix \"ClassVec\". Notons également la présence de la colonne d\u0027index suffixées par \"Index\"\n\nPrenons par exemple la variable non-numérique \"native_country\", une fois le model (pipelineModel) appliqué sur notre dataset, nous obtenons les 3 colonnes suivantes :\nnative_country | native_countryIndex | native_countryClassVec\nCuba           | 9.0                 | (41,[9],[1.0])\n\nLa valeur brute de la variable native_country est \"Cuba\", sa représentation vectorielle \u003d (41,[9],[1.0]) est stockées dans la colonne native_countryClassVec. Nous voyons ici que le vecteur a une longueur de 41 et que l\u0027état \"Cuba\" est représenté par une valeur logique 1 à la 9ième position (les autres valeurs étant à 0). Cet index est également stocké dans la colonne native_countryIndex. \n\nPour finir, nous voyons également la colonne \"label\" avec comme valeurs 0 ou 1, et la colonne \"features\" (expliquée plus bas).\n\nCes informations seront par la suite utilisées par nos algorithmes de prédiction dont les calculs se basent sur des informations numériques.\n",
      "dateUpdated": "Mar 10, 2017 12:48:42 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487193454026_-563043559",
      "id": "20170215-211734_1891637465",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eQuelques explications :\u003c/p\u003e\n\u003cp\u003eSpark ML fournit des outils permettant d\u0027enchainer des traitements sur des données dans un seul pipeline ou \u0026ldquo;workflow\u0026rdquo;. Dans un contexte machine-learning, il est très facile de transformer des données, y appliquer des algorithmes et obtenir un modèle de prédiction qui pourra être validé sur un jeux de données \u0026ldquo;Test\u0026rdquo; (évaluation du taux d\u0027erreur de prédiction). Pour cela, il va nous falloir appliquer des transformations sur nos colonnes catégorielles (qui donneront lieu à de nouvelles colonnes).\u003c/p\u003e\n\u003cp\u003eDans un premier temps nous allons transformer nos variables catégorielles en indices numériques. Ces indices sont affectés par fréquence d\u0027occurence, les états les plus fréquents auront une valeur d\u0027indice faible, les moins fréquents auront une valeur plus élevée (valeurs évidemment identiques pour un même état). Ces informations serviront à alimenter le système de transformation one-hot que nous allons voir juste après. Elles nous serviront également à la fin de ce NoteBook où nous aurons besoin de faire des calculs sur des valeurs numériques [Double].\n\u003cbr  /\u003e-\u003e StringIndexer permet de convertir des variables catégorielles en indices catégoriels.\u003c/p\u003e\n\u003cp\u003eUn encodage one-hot appliqué sur une variable catégorielle non numérique permet de représenter ses différents états de manière binaire. Dans notre cas d\u0027étude spark il s\u0027agit de vecteurs binaires.\n\u003cbr  /\u003eImaginons une variable à trois états \u0026ldquo;Wife\u0026rdquo;, \u0026ldquo;Husband\u0026rdquo;, \u0026ldquo;Own-child\u0026rdquo;.\n\u003cbr  /\u003eLa représentation one-hot des états de cette variable serait :\n\u003cbr  /\u003e001, 010, 100 ou (3,[3],[1.0]), (3,[2],[1.0]), (3,[1],[1.0]).\n\u003cbr  /\u003eCe dispositif n\u0027est pertinent que si le nombre d\u0027états n\u0027est pas trop important, dans notre cas il convient très bien pour notre jeu de données !\n\u003cbr  /\u003e-\u003e OneHotEncoder associe une colonne d\u0027indices catégoriels à une colonne de vecteur binaire. Nous nous basons ici sur StringIndexer.\u003c/p\u003e\n\u003cp\u003e\u0026ndash;\u003e VectorAssembler permet de combiner une liste donnée de colonnes en un simple vecteur de colonnes (expliqué plus en détail par la suite). Il donnera lieu à la fameuse colonne \u0026ldquo;features\u0026rdquo;.\u003c/p\u003e\n\u003cp\u003eREMARQUE :\n\u003cbr  /\u003eInutile de représenter la variable income (notre label) en vecteur binaire car il n\u0027y a que 2 états possibles (\u003e50K ou \u0026lt;\u003d50K), ce qui équivaut à 0 ou 1. StringIndexer suffit dans notre cas.\u003c/p\u003e\n\u003cp\u003e-\u003e datasetTransformed.show() \u003c-\n\u003cbr  /\u003eNous pouvons visualiser le résultat de la transformation via la méthode show(). Nous retrouvons les colonnes numériques de notre dataset (ex : age, fnlwgt, capital_gain, etc \u0026hellip;) sur lesquelles nous n\u0027avons effectué aucun traitement.\n\u003cbr  /\u003eNous retrouvons également les colonnes non-numériques du dataset (ex : workclass, education, occupation, etc \u0026hellip;) sur lesquelles nous avons effectué une transformation vectorielle. Le résultat de cette transformation est stocké dans une colonne du même nom + le suffix \u0026ldquo;ClassVec\u0026rdquo;. Notons également la présence de la colonne d\u0027index suffixées par \u0026ldquo;Index\u0026rdquo;\u003c/p\u003e\n\u003cp\u003ePrenons par exemple la variable non-numérique \u0026ldquo;native_country\u0026rdquo;, une fois le model (pipelineModel) appliqué sur notre dataset, nous obtenons les 3 colonnes suivantes :\n\u003cbr  /\u003enative_country | native_countryIndex | native_countryClassVec\n\u003cbr  /\u003eCuba           | 9.0                 | (41,[9],[1.0])\u003c/p\u003e\n\u003cp\u003eLa valeur brute de la variable native_country est \u0026ldquo;Cuba\u0026rdquo;, sa représentation vectorielle \u003d (41,[9],[1.0]) est stockées dans la colonne native_countryClassVec. Nous voyons ici que le vecteur a une longueur de 41 et que l\u0027état \u0026ldquo;Cuba\u0026rdquo; est représenté par une valeur logique 1 à la 9ième position (les autres valeurs étant à 0). Cet index est également stocké dans la colonne native_countryIndex.\u003c/p\u003e\n\u003cp\u003ePour finir, nous voyons également la colonne \u0026ldquo;label\u0026rdquo; avec comme valeurs 0 ou 1, et la colonne \u0026ldquo;features\u0026rdquo; (expliquée plus bas).\u003c/p\u003e\n\u003cp\u003eCes informations seront par la suite utilisées par nos algorithmes de prédiction dont les calculs se basent sur des informations numériques.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 15, 2017 9:17:34 AM",
      "dateStarted": "Mar 10, 2017 12:48:39 PM",
      "dateFinished": "Mar 10, 2017 12:48:39 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Detail columns to deal with",
      "text": "val categoricalCols \u003d Seq(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\")\nval numericCols \u003d Seq(\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\")",
      "dateUpdated": "Mar 10, 2017 9:28:20 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486391484536_-1333067431",
      "id": "20170206-143124_969747353",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ncategoricalCols: Seq[String] \u003d List(workclass, education, marital_status, occupation, relationship, race, sex, native_country)\n\nnumericCols: Seq[String] \u003d List(age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week)\n"
      },
      "dateCreated": "Feb 6, 2017 2:31:24 AM",
      "dateStarted": "Mar 10, 2017 9:28:20 PM",
      "dateFinished": "Mar 10, 2017 9:28:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nNous voyons ici les variables catégorielles non-numériques stockées dans categoricalCols et les variables numériques stockées dans numericCols",
      "dateUpdated": "Feb 24, 2017 11:09:22 AM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487934447941_-1588502435",
      "id": "20170224-110727_1641269178",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eNous voyons ici les variables catégorielles non-numériques stockées dans categoricalCols et les variables numériques stockées dans numericCols\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 24, 2017 11:07:27 AM",
      "dateStarted": "Feb 24, 2017 11:09:21 AM",
      "dateFinished": "Feb 24, 2017 11:09:21 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nTo run machine learning on a dataset, you need a column which contains a vector of all the features, and a column with the label.\n\nWe use the [VectorAssembler](http://spark.apache.org/docs/latest/ml-features.html#vectorassembler) to assemble all of our numeric columns and one-hot encoded categorical columns into one.\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nAdd the `VectorAssembler` stage, which takes as input all numeric columns and one hot encoded categorical columns. The `features` column will then be created. You can comment on it.",
      "dateUpdated": "Mar 9, 2017 11:16:46 AM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486113356892_-128377178",
      "id": "20170203-091556_1786454475",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eTo run machine learning on a dataset, you need a column which contains a vector of all the features, and a column with the label.\u003c/p\u003e\n\u003cp\u003eWe use the \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#vectorassembler\"\u003eVectorAssembler\u003c/a\u003e to assemble all of our numeric columns and one-hot encoded categorical columns into one.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eAdd the \u003ccode\u003eVectorAssembler\u003c/code\u003e stage, which takes as input all numeric columns and one hot encoded categorical columns. The \u003ccode\u003efeatures\u003c/code\u003e column will then be created. You can comment on it.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:15:56 AM",
      "dateStarted": "Feb 7, 2017 12:55:43 PM",
      "dateFinished": "Feb 7, 2017 12:55:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nColonne \"features\" :\n\nNous avons précédemment appliqué notre pipeline au jeu de données.\nL\u0027étape assemblerStage a permis de combiner des valeurs de colonnes d\u0027un individu (row) en un simple vecteur appelé \"features\" grâce à la ligne suivante :\nval assemblerStage \u003d new VectorAssembler().setInputCols(nonNumericalColumns.map(w \u003d\u003e w + \"ClassVec\").toArray).setOutputCol(\"features\")\n\nNous avons combiné ici toutes les colonnes vectorielles représentant les variables non-numériques en un seul vecteur de sorti appelé \"features\", et ce pour chaque individu.\nNous remarquons que la longeur de ce vecteur features est égal à la somme de la longeur des vecteurs binaires : 8, 15, 6, 14, 5, 4, 1, 41 \u003d 94",
      "dateUpdated": "Mar 9, 2017 11:17:09 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487938873021_946627434",
      "id": "20170224-122113_1891949278",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eColonne \u0026ldquo;features\u0026rdquo; :\u003c/p\u003e\n\u003cp\u003eNous avons précédemment appliqué notre pipeline au jeu de données.\n\u003cbr  /\u003eL\u0027étape assemblerStage a permis de combiner des valeurs de colonnes d\u0027un individu (row) en un simple vecteur appelé \u0026ldquo;features\u0026rdquo; grâce à la ligne suivante :\n\u003cbr  /\u003eval assemblerStage \u003d new VectorAssembler().setInputCols(nonNumericalColumns.map(w \u003d\u003e w + \u0026ldquo;ClassVec\u0026rdquo;).toArray).setOutputCol(\u0026ldquo;features\u0026rdquo;)\u003c/p\u003e\n\u003cp\u003eNous avons combiné ici toutes les colonnes vectorielles représentant les variables non-numériques en un seul vecteur de sorti appelé \u0026ldquo;features\u0026rdquo;, et ce pour chaque individu.\n\u003cbr  /\u003eNous remarquons que la longeur de ce vecteur features est égal à la somme de la longeur des vecteurs binaires : 8, 15, 6, 14, 5, 4, 1, 41 \u003d 94\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 24, 2017 12:21:13 PM",
      "dateStarted": "Mar 9, 2017 11:17:08 AM",
      "dateFinished": "Mar 9, 2017 11:17:08 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Que donnent les colonnes label et features ?",
      "text": "%sql SELECT label, income, features FROM datasetTransformed LIMIT 10",
      "dateUpdated": "Mar 5, 2017 6:15:25 AM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 296.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "label",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "label",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487943915252_26109898",
      "id": "20170224-134515_713795839",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "label\tincome\tfeatures\n0.0\t \u003c\u003d50K\t(94,[4,10,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n0.0\t \u003c\u003d50K\t(94,[1,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n0.0\t \u003c\u003d50K\t(94,[0,8,25,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n0.0\t \u003c\u003d50K\t(94,[0,13,23,38,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n0.0\t \u003c\u003d50K\t(94,[0,10,23,29,47,49,62],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n0.0\t \u003c\u003d50K\t(94,[0,11,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n0.0\t \u003c\u003d50K\t(94,[0,18,28,34,44,49,64],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n1.0\t \u003e50K\t(94,[1,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n1.0\t \u003e50K\t(94,[0,11,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n1.0\t \u003e50K\t(94,[0,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n"
      },
      "dateCreated": "Feb 24, 2017 1:45:15 AM",
      "dateStarted": "Mar 5, 2017 6:15:26 AM",
      "dateFinished": "Mar 5, 2017 6:15:28 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nRequêtons notre dataset transformé.\nLa colonne label contient 0 si l\u0027individu gagne moins de 50K\nElle contient 1 si l\u0027individu gagne plus de 50K.\nLa colonne features contient la combinaison des variables non-numériques sous forme de vecteur binaire.",
      "dateUpdated": "Feb 24, 2017 1:54:36 AM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 129.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487944155955_-569726062",
      "id": "20170224-134915_910401250",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eRequêtons notre dataset transformé.\n\u003cbr  /\u003eLa colonne label contient 0 si l\u0027individu gagne moins de 50K\n\u003cbr  /\u003eElle contient 1 si l\u0027individu gagne plus de 50K.\n\u003cbr  /\u003eLa colonne features contient la combinaison des variables non-numériques sous forme de vecteur binaire.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 24, 2017 1:49:15 AM",
      "dateStarted": "Feb 24, 2017 1:54:34 AM",
      "dateFinished": "Feb 24, 2017 1:54:34 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Y a-t-il des individus qui partagent les mêmes variables non-numériques ?",
      "text": "%sql select features, count(*) as nb_individus_similaires from datasetTransformed group by features order by count(*) DESC",
      "dateUpdated": "Feb 24, 2017 8:09:28 AM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 158.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "features",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "nb_individus_similaires",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "features",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487944493674_-1400892600",
      "id": "20170224-135453_648999441",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "features\tnb_individus_similaires\n(94,[0,8,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t803\n(94,[0,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t448\n(94,[0,8,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t368\n(94,[0,9,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t345\n(94,[0,8,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t332\n(94,[0,10,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t309\n(94,[0,10,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t274\n(94,[0,8,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t274\n(94,[0,9,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t237\n(94,[0,9,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t216\n(94,[0,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t196\n(94,[0,11,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t171\n(94,[3,8,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t150\n(94,[0,11,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t145\n(94,[0,8,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t143\n(94,[1,8,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t139\n(94,[1,8,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t130\n(94,[0,9,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t126\n(94,[0,9,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t123\n(94,[0,9,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t121\n(94,[0,8,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t119\n(94,[3,9,24,36,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t117\n(94,[0,9,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t116\n(94,[0,8,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t115\n(94,[3,9,24,36,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t115\n(94,[0,8,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t113\n(94,[0,12,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t113\n(94,[0,8,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t104\n(94,[0,9,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t103\n(94,[0,9,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t102\n(94,[0,10,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t101\n(94,[0,8,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t99\n(94,[0,9,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t98\n(94,[0,10,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t96\n(94,[0,8,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t96\n(94,[0,17,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t95\n(94,[0,8,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t94\n(94,[0,9,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t94\n(94,[0,8,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t92\n(94,[0,8,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t90\n(94,[0,8,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t90\n(94,[0,10,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t89\n(94,[2,11,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t87\n(94,[0,10,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t87\n(94,[0,9,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t86\n(94,[5,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t83\n(94,[0,9,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t83\n(94,[1,17,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t80\n(94,[0,8,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t79\n(94,[0,10,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t79\n(94,[0,10,24,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t77\n(94,[0,8,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t76\n(94,[0,8,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t76\n(94,[1,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t76\n(94,[2,10,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t74\n(94,[0,9,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t73\n(94,[0,8,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t72\n(94,[1,8,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t70\n(94,[5,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t69\n(94,[0,13,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t69\n(94,[0,9,24,32,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t69\n(94,[0,9,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t68\n(94,[0,20,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t66\n(94,[0,9,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t65\n(94,[5,9,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t65\n(94,[0,10,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t64\n(94,[0,8,24,35,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t64\n(94,[0,8,25,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t63\n(94,[3,10,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t63\n(94,[0,9,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t62\n(94,[0,8,24,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t62\n(94,[0,8,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t62\n(94,[0,15,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t62\n(94,[2,9,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t60\n(94,[0,8,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t60\n(94,[3,9,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t60\n(94,[1,9,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t60\n(94,[0,8,25,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t60\n(94,[0,8,24,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t59\n(94,[0,8,24,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t59\n(94,[0,10,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t59\n(94,[0,9,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t59\n(94,[0,9,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t58\n(94,[0,10,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t57\n(94,[5,17,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t57\n(94,[0,9,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t57\n(94,[0,8,24,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t56\n(94,[0,8,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t55\n(94,[0,9,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t55\n(94,[0,9,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t54\n(94,[0,9,24,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t54\n(94,[0,10,24,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t53\n(94,[5,10,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t53\n(94,[0,8,25,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t52\n(94,[1,9,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t52\n(94,[0,9,24,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t51\n(94,[1,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t51\n(94,[1,10,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t51\n(94,[0,8,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t50\n(94,[2,8,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t49\n(94,[5,9,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t48\n(94,[0,11,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t48\n(94,[2,8,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t47\n(94,[0,10,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t47\n(94,[1,9,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t46\n(94,[0,13,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t45\n(94,[0,10,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t45\n(94,[0,16,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t45\n(94,[0,8,24,37,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t44\n(94,[0,13,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t44\n(94,[1,8,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t43\n(94,[0,12,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t43\n(94,[0,9,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t43\n(94,[0,8,24,32,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t42\n(94,[1,10,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t42\n(94,[0,8,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t42\n(94,[0,14,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t41\n(94,[1,9,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t41\n(94,[0,10,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t40\n(94,[0,9,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t40\n(94,[0,8,24,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t40\n(94,[4,11,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t40\n(94,[0,9,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t39\n(94,[0,8,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t39\n(94,[2,10,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t39\n(94,[2,10,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[0,12,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[0,8,23,35,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[0,8,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[0,11,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[6,8,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[0,8,23,33,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t38\n(94,[0,14,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t37\n(94,[0,11,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t37\n(94,[0,9,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t37\n(94,[0,8,25,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t37\n(94,[0,14,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t37\n(94,[0,8,25,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t37\n(94,[2,11,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[0,9,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[5,8,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[0,10,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[3,8,27,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[0,15,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[0,13,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t36\n(94,[4,20,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t35\n(94,[0,8,25,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t35\n(94,[4,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t34\n(94,[0,9,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t34\n(94,[0,13,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t34\n(94,[0,12,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t34\n(94,[5,8,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t34\n(94,[0,15,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t34\n(94,[0,8,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t33\n(94,[0,8,27,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t33\n(94,[0,8,23,30,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t33\n(94,[0,10,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t32\n(94,[0,10,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t32\n(94,[0,12,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t32\n(94,[0,8,25,30,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t32\n(94,[0,15,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t31\n(94,[0,8,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t31\n(94,[0,13,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t31\n(94,[0,9,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t31\n(94,[0,10,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t31\n(94,[4,10,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t30\n(94,[0,9,24,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t30\n(94,[0,13,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t30\n(94,[2,8,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t30\n(94,[0,8,25,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t30\n(94,[0,10,24,31,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t30\n(94,[0,12,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t29\n(94,[0,18,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t29\n(94,[0,8,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t29\n(94,[0,8,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t29\n(94,[4,8,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[1,10,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[3,8,24,36,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[2,11,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[0,10,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[0,10,24,31,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[0,9,25,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[0,14,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t28\n(94,[3,8,23,36,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t27\n(94,[0,8,23,35,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t27\n(94,[0,8,24,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t27\n(94,[2,11,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t27\n(94,[0,9,24,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t27\n(94,[2,10,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t27\n(94,[1,12,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t26\n(94,[0,10,24,40,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t26\n(94,[0,8,24,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t26\n(94,[0,8,23,37,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t26\n(94,[3,16,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t26\n(94,[6,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t26\n(94,[0,10,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[0,14,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[6,10,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[0,8,24,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[0,15,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[3,9,23,36,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[0,8,25,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t25\n(94,[0,9,25,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[3,8,24,36,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[0,12,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[0,8,24,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[0,13,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[3,11,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[0,8,25,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t24\n(94,[0,14,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,13,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,16,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,8,24,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,8,26,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,8,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[2,10,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[1,10,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[1,16,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,9,25,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t23\n(94,[0,11,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[6,9,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[0,10,24,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[0,9,24,37,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[0,9,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[3,15,24,36,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[0,8,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[4,10,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[0,9,25,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t22\n(94,[0,8,27,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,8,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,8,24,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[5,11,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,9,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,19,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,10,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[2,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,8,24,38,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,9,24,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[2,9,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,10,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,11,24,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,8,23,38,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,19,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,9,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[2,11,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[1,20,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t21\n(94,[0,10,25,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,8,24,34,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,9,25,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,8,24,35,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,10,25,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,12,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,10,24,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[2,11,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,16,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,9,24,31,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,9,24,32,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,9,24,35,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,12,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,9,24,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[0,9,24,40,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[4,8,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t20\n(94,[2,9,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[3,13,24,36,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[3,9,24,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,9,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[5,11,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,9,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,9,23,33,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[2,8,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,8,27,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,9,24,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,8,25,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,17,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,8,23,34,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,17,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,10,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t19\n(94,[0,12,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[2,10,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,8,24,38,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,10,24,32,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[1,8,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,10,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,19,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,10,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,8,27,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,9,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[5,10,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[4,9,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t18\n(94,[0,8,25,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[1,11,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,12,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[4,11,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,8,27,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[3,9,24,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,18,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,10,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,8,25,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[2,10,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,8,24,30,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[2,10,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,8,24,30,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[3,10,23,36,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,10,23,31,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,9,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[1,8,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,11,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[3,13,24,36,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t17\n(94,[0,15,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[2,8,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,10,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,20,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,9,25,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,15,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,19,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[4,10,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[5,20,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,8,24,38,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[3,8,24,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,9,25,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,9,24,31,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,8,24,35,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,12,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[3,8,25,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[2,11,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[4,9,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,10,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,9,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t16\n(94,[0,13,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,8,25,30,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[3,13,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[3,8,24,36,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,9,25,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[3,8,24,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,14,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,9,24,40,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,9,23,30,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,12,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,8,24,30,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[3,9,25,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,8,26,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,18,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[6,9,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[1,16,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,8,24,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,10,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,14,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,9,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,13,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t15\n(94,[0,9,24,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,8,24,34,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[1,18,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[6,8,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,12,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,20,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[2,9,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,9,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,10,25,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,12,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[6,8,23,32,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,9,24,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,9,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[1,15,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,9,24,33,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,8,24,32,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,13,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,9,27,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[1,11,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t14\n(94,[0,8,26,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,18,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,8,24,31,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,9,25,30,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,8,25,35,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,13,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,13,24,37,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[3,15,24,36,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[1,11,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,11,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,9,25,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[4,11,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,11,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,19,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[5,9,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,18,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,10,23,33,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t13\n(94,[0,9,27,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,14,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,12,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,10,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,10,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,8,24,33,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,9,26,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,11,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,8,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[4,10,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,8,24,33,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[3,8,23,36,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,8,25,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,15,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[1,8,24,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,10,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[4,9,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,17,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,10,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[6,17,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[2,12,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[6,11,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[1,8,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,15,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,9,23,35,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,15,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,9,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[6,9,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,12,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[2,8,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,9,25,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[3,15,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,8,24,32,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t12\n(94,[0,8,25,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,8,24,30,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[1,8,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,13,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[2,14,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,14,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,9,24,30,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,8,25,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,9,24,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,16,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,9,23,37,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[3,10,24,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,12,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,8,23,34,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,10,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[3,17,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,11,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[1,12,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[1,9,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,9,25,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,12,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,10,23,31,43,48,52,55],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,8,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[5,14,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[1,8,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[5,8,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[1,9,24,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[1,10,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,14,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[2,8,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[0,21,23,35,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t11\n(94,[2,10,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,11,23,29,43,50,52,61],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[2,17,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,23,34,47,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,9,24,34,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[4,8,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,24,35,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,25,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,12,24,40,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,15,24,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,12,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,13,25,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[5,9,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,14,24,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,9,25,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,24,34,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,9,23,33,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,16,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[3,20,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,25,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[3,18,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,24,37,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[4,17,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,11,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[3,12,27,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,24,35,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,9,24,33,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[4,10,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,21,23,34,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[2,9,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,25,34,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,9,24,33,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,9,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[6,10,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[6,8,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,26,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[6,10,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[3,12,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,8,26,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[2,9,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,12,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t10\n(94,[0,14,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,27,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,10,23,40,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,9,27,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[6,8,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,27,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,14,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,21,23,39,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[4,9,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,9,24,34,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,23,32,47,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[4,9,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,9,23,32,47,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[6,11,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,26,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,38,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[1,8,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,23,32,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,35,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[2,10,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,9,26,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,21,23,38,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,23,33,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,9,23,32,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,25,35,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,25,33,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[3,21,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[3,8,25,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[6,8,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,11,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[1,9,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,34,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,38,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,14,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,14,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,33,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,10,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,25,30,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,11,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,11,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[4,9,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[3,8,27,36,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[5,12,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,30,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[1,9,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[1,13,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,9,24,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,15,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[5,10,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,15,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,10,23,33,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,17,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,10,24,40,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[2,9,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,13,24,34,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[1,9,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[3,8,25,36,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,24,40,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,14,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,14,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,23,30,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[1,8,23,33,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,12,23,40,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,14,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,12,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,23,30,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,19,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,8,25,40,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[3,10,24,36,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t9\n(94,[0,11,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[3,8,24,36,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[6,9,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,13,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,21,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,25,40,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,14,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,24,31,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,22,23,35,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[6,10,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,26,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,10,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[3,10,25,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,24,33,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[4,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,17,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,25,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,24,32,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,10,23,32,43,50,52,56],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,23,37,43,51,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,13,24,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,25,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,25,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,10,24,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[2,9,24,41,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,12,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,24,30,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,13,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,24,34,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[2,8,23,37,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[1,9,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,24,38,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,24,40,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[4,8,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,24,35,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,24,38,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,13,24,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,10,24,29,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,25,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,23,40,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,10,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,25,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,26,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,12,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,8,26,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,14,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[1,15,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[1,9,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[1,8,25,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[1,8,25,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,14,24,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,27,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,11,23,29,43,48,52,55],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[4,9,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,9,24,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[0,12,24,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[3,9,24,36,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t8\n(94,[6,8,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,38,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[3,8,24,36,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,10,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,14,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,9,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[3,9,24,36,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,13,24,33,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,10,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,12,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,10,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,10,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,25,32,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,35,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,21,23,30,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[2,12,24,41,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[3,10,24,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,11,25,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,33,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,26,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,8,23,40,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,14,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[6,14,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[6,9,23,32,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[2,10,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,25,40,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,15,25,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,13,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,34,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,16,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,10,24,40,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,25,30,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,32,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,32,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[6,9,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,13,25,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,11,25,31,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[2,9,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,11,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,33,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[3,9,25,36,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,11,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,25,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[5,14,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,33,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,17,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,11,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,30,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,13,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,9,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,13,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,34,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,26,33,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,8,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,14,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,19,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,37,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,11,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,10,23,29,43,48,52,55],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,12,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,9,24,32,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[2,10,24,29,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[6,8,25,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,10,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[3,14,23,36,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[1,9,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,24,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,26,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[4,12,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,12,24,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,8,24,32,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t7\n(94,[0,9,25,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,18,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,19,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,10,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,26,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,26,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,10,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,10,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,9,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,11,27,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,27,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,23,30,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,11,25,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,24,34,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,24,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,23,35,47,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,16,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,10,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,30,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,23,35,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,38,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,21,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,25,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,24,34,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[3,15,24,36,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,24,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,25,35,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,25,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,25,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,10,25,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,25,40,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,8,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,8,23,35,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,26,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,11,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,25,34,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,24,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,26,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,20,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,16,27,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[3,21,23,36,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,41,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,9,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,23,37,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,26,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,9,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,10,24,38,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,9,24,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[6,10,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,24,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,21,24,38,44,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,24,40,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,16,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,18,24,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,13,24,34,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,8,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[3,8,27,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[5,9,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[3,12,23,36,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,24,41,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,12,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,24,39,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,37,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,13,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,25,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,14,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,8,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,14,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,25,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,10,25,31,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,26,35,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,24,31,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,27,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,25,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,9,24,32,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,23,40,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,35,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,14,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,23,30,43,51,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,11,23,29,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,10,25,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,8,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,23,30,43,48,52,55],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,9,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,24,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,10,23,41,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,10,24,29,44,48,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,16,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,20,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,15,24,30,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[6,8,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,20,24,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,13,24,42,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,26,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,24,35,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,13,24,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,10,23,31,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,8,25,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,9,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,23,31,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[5,8,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,12,24,40,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,16,23,38,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,24,37,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[5,8,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,24,30,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,24,32,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,9,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[3,16,27,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[1,12,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[4,10,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,27,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,14,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,20,23,31,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,8,28,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,13,25,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,13,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,22,23,30,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,9,26,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,22,23,39,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[2,10,25,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t6\n(94,[0,10,24,32,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,23,41,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,13,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,25,32,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,25,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,10,24,29,45,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,8,24,41,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,10,24,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,15,25,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,24,38,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,20,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,23,30,43,48,52,72],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,9,23,31,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,9,24,36,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,13,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,11,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,26,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,13,24,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,33,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,25,38,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,27,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,8,26,36,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,39,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,9,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,9,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,9,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,25,33,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,23,38,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,15,23,30,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,8,25,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,9,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,27,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,23,38,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,27,35,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[5,10,23,39,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,23,30,43,48,52,57],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,18,25,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,9,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,16,23,37,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,15,23,30,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,24,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,11,24,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,9,27,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,24,35,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,14,24,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,27,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,25,30,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,8,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,8,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,9,24,36,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,11,27,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,24,39,44,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,9,24,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,9,24,41,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,18,24,34,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,8,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,11,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,25,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,17,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,27,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,14,24,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,25,34,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,14,23,33,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,14,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,18,23,35,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,13,24,36,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,13,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,14,25,33,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,24,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,11,23,31,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,25,35,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,9,25,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,11,25,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,8,25,36,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,8,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,8,24,34,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[5,9,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,26,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,24,34,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,9,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,14,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,18,24,35,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,9,27,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,26,29,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,24,35,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,25,33,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,25,40,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,16,23,34,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,10,24,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,23,32,47,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,26,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,10,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,29,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,19,24,33,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,19,24,35,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,8,24,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,8,27,36,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,24,34,49,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,24,33,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,24,37,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,24,31,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,25,38,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,18,23,34,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,12,24,39,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,23,29,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,27,29,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,19,24,36,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,25,34,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,27,37,46,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[4,8,25,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,18,24,34,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,33,49,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,31,44,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,41,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,8,26,36,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,23,30,43,48,52,55],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,13,24,34,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,16,23,35,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,16,23,37,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,32,45,50,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,26,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,23,34,43,50,52,66],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,25,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,23,37,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,12,25,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,8,25,32,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,8,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,8,27,34,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,11,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,10,24,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,24,30,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,9,24,38,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,13,25,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,10,23,31,43,50,52,71],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[5,12,23,33,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[1,9,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[2,9,24,32,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[3,15,25,36,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,14,23,38,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,15,23,32,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,15,24,34,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[6,8,25,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t5\n(94,[0,8,25,35,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,22,23,38,43,48,52,54],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,14,25,31,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[4,14,23,41,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,8,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[4,9,24,31,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[4,20,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,9,24,32,45,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,9,24,33,45,48,52,55],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,8,27,34,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,16,25,35,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,8,24,37,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,12,25,31,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,8,24,33,44,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,15,23,35,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[2,11,24,29,45,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,16,24,35,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,9,23,29,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,10,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,9,24,39,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[4,8,26,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,10,24,31,48,53],[1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[2,11,24,29,45,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[6,8,24,32,46,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,8,23,39,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[5,8,23,32,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[5,8,23,33,47,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[6,20,23,29,43,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,8,24,38,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,8,24,38,45,51,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,14,25,33,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[2,9,25,32,46,49,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[2,10,23,31,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[3,19,24,36,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[1,10,24,29,44,48,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[2,10,23,29,43,49,52,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n(94,[0,14,24,33,44,48,53],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])\t4\n\n\u003cfont color\u003dred\u003eResults are limited by 1000.\u003c/font\u003e"
      },
      "dateCreated": "Feb 24, 2017 1:54:53 AM",
      "dateStarted": "Feb 24, 2017 8:01:23 AM",
      "dateFinished": "Feb 24, 2017 8:01:26 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nNous remarquons que bon nombre d\u0027individus partagent les mêmes variables non-numériques.\n\nLa requête ci contre est équivalente d\u0027un point de vue SQL à un regroupement sur les colonnes workclass, education, marital_status, occupation, relationship, race, sex, native_country :\n\nselect count( * ) as nb_individus_similaires from datasetTransformed group by workclass, education, marital_status, occupation, relationship, race, sex, native_country order by count( * ) DESC",
      "dateUpdated": "Feb 24, 2017 8:09:06 AM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487944925770_498039147",
      "id": "20170224-140205_1901415894",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eNous remarquons que bon nombre d\u0027individus partagent les mêmes variables non-numériques.\u003c/p\u003e\n\u003cp\u003eLa requête ci contre est équivalente d\u0027un point de vue SQL à un regroupement sur les colonnes workclass, education, marital_status, occupation, relationship, race, sex, native_country :\u003c/p\u003e\n\u003cp\u003eselect count( * ) as nb_individus_similaires from datasetTransformed group by workclass, education, marital_status, occupation, relationship, race, sex, native_country order by count( * ) DESC\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 24, 2017 2:02:05 AM",
      "dateStarted": "Feb 24, 2017 8:09:03 AM",
      "dateFinished": "Feb 24, 2017 8:09:03 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nAt this point, you should have a dataframe with a column _features_ which consists of a vector of all features in numerical form, and a column _label_ with the Income as a binary value. \n\nIt looks like this for example:\n\n```\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[4,10,24,32,...|\n```\n\n\u003chr\u003e\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nRandomly split your dataset into a 70% training set and 30% test set using a Dataframe\u0027s `randomSplit` function.",
      "dateUpdated": "Feb 7, 2017 12:55:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114019412_590451428",
      "id": "20170203-092659_1906384110",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eAt this point, you should have a dataframe with a column \u003cem\u003efeatures\u003c/em\u003e which consists of a vector of all features in numerical form, and a column \u003cem\u003elabel\u003c/em\u003e with the Income as a binary value.\u003c/p\u003e\n\u003cp\u003eIt looks like this for example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| \u0026lt;\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[4,10,24,32,...|\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eRandomly split your dataset into a 70% training set and 30% test set using a Dataframe\u0027s \u003ccode\u003erandomSplit\u003c/code\u003e function.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:26:59 AM",
      "dateStarted": "Feb 7, 2017 12:55:44 PM",
      "dateFinished": "Feb 7, 2017 12:55:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val splits \u003d datasetTransformed.randomSplit(Array(0.7, 0.3))\nval (training, test) \u003d (splits(0), splits(1))",
      "dateUpdated": "Mar 10, 2017 9:28:28 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 104.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486586435634_1409226607",
      "id": "20170208-204035_1111625467",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nsplits: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] \u003d Array([age: double, workclass: string ... 31 more fields], [age: double, workclass: string ... 31 more fields])\n\n\ntraining: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [age: double, workclass: string ... 31 more fields]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [age: double, workclass: string ... 31 more fields]\n"
      },
      "dateCreated": "Feb 8, 2017 8:40:35 AM",
      "dateStarted": "Mar 10, 2017 9:28:28 PM",
      "dateFinished": "Mar 10, 2017 9:28:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nLa fonction randomSplit permet de découper un dataset en plusieurs \"morceaux\" dans lesquels sont réparties les données de manière aléatoire. La fonction demande un tableau dont la longeur correspond au nombre de splits (ici 2) et les valeurs la taille en pourcentage de chacun d\u0027eux (ici 70% et 30%).\n\nNous récupérons le split de 70% dans une variable \"training\". Ce dataset sera utilisé pour déterminer les prédictions \u003d\u003e APPRENTISSAGE\n\nLe split de 30% est stocké dans une variable \"test\" qui permettra de tester les prédictions calculées sur le jeu de données training \u003d\u003e TEST",
      "dateUpdated": "Feb 25, 2017 7:18:40 AM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 159.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487945087000_-429010301",
      "id": "20170224-140447_793759198",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eLa fonction randomSplit permet de découper un dataset en plusieurs \u0026ldquo;morceaux\u0026rdquo; dans lesquels sont réparties les données de manière aléatoire. La fonction demande un tableau dont la longeur correspond au nombre de splits (ici 2) et les valeurs la taille en pourcentage de chacun d\u0027eux (ici 70% et 30%).\u003c/p\u003e\n\u003cp\u003eNous récupérons le split de 70% dans une variable \u0026ldquo;training\u0026rdquo;. Ce dataset sera utilisé pour déterminer les prédictions \u003d\u003e APPRENTISSAGE\u003c/p\u003e\n\u003cp\u003eLe split de 30% est stocké dans une variable \u0026ldquo;test\u0026rdquo; qui permettra de tester les prédictions calculées sur le jeu de données training \u003d\u003e TEST\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 24, 2017 2:04:47 AM",
      "dateStarted": "Feb 25, 2017 7:18:38 AM",
      "dateFinished": "Feb 25, 2017 7:18:38 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## V. Creation of models\n\nWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\n\nWe have the choice between:\n- [Binomial Logistic regression](http://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression)\n- [Decision trees](http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees)\n- [Random forest](http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests)\n\nThese are the general steps we will take to build our models:\n- Create the initial model on the training set\n- Use your model to make predictions on your testing set\n- Evaluate the quality of your predictions\n\nWe will be using the `BinaryClassificationEvaluator` to evaluate our models. The default metric used here is [areaUnderROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve).\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\n1. Fit your data on one of the three Machine Learning models on the training dataset. This should create an Estimator.\n2. Run the estimator on the testing dataset to create a prediction column\n3. Use `BinaryClassificationEvaluator.evaluate()` to evaluate your predictions.",
      "dateUpdated": "Feb 8, 2017 8:35:27 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114303097_-616679895",
      "id": "20170203-093143_100322687",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eV. Creation of models\u003c/h2\u003e\n\u003cp\u003eWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\u003c/p\u003e\n\u003cp\u003eWe have the choice between:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\"\u003eBinomial Logistic regression\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees\"\u003eDecision trees\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests\"\u003eRandom forest\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese are the general steps we will take to build our models:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreate the initial model on the training set\u003c/li\u003e\n\u003cli\u003eUse your model to make predictions on your testing set\u003c/li\u003e\n\u003cli\u003eEvaluate the quality of your predictions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe will be using the \u003ccode\u003eBinaryClassificationEvaluator\u003c/code\u003e to evaluate our models. The default metric used here is \u003ca href\u003d\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\"\u003eareaUnderROC\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eFit your data on one of the three Machine Learning models on the training dataset. This should create an Estimator.\u003c/li\u003e\n\u003cli\u003eRun the estimator on the testing dataset to create a prediction column\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003eBinaryClassificationEvaluator.evaluate()\u003c/code\u003e to evaluate your predictions.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:31:43 AM",
      "dateStarted": "Feb 7, 2017 12:55:44 PM",
      "dateFinished": "Feb 7, 2017 12:55:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Binomial Logistic Regression  (estimation 87.85%)",
      "text": "import org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\n// Implémentation du model de machine learning LogisticRegression\nval lr \u003d new LogisticRegression().setMaxIter(10).setRegParam(0.01)\n\n// Création d\u0027un estimateur en adaptant le modèle de régression logistique sur les données training issues du dataset\nval lrModel \u003d lr.fit(training)\n\n// Exécution de l\u0027estimateur sur les données test issues du dataset\nval datasetEstimated \u003d lrModel.transform(test);\n\n// Evaluation des prédictions grâce à BinaryClassificationEvaluator\nval bce \u003d new BinaryClassificationEvaluator()\n\n// Nous obtenons une estimation juste à 87.85%\nbce.evaluate(datasetEstimated)\n\n// Affichage des erreurs d\u0027estimation\ndatasetEstimated.filter($\"label\" !\u003d\u003d $\"prediction\").select(\"workclass\", \"education\", \"sex\", \"label\",\"prediction\").show()\n",
      "dateUpdated": "Mar 10, 2017 9:38:43 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 168.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486585864968_-2038717368",
      "id": "20170208-203104_804651775",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.classification.LogisticRegression\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\nlr: org.apache.spark.ml.classification.LogisticRegression \u003d logreg_96c7b684e32d\n\nlrModel: org.apache.spark.ml.classification.LogisticRegressionModel \u003d logreg_96c7b684e32d\n\ndatasetEstimated: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 34 more fields]\n\nbce: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator \u003d binEval_d035e3496980\n\nres21: Double \u003d 0.8782780529841435\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+-----------------+-------------+-------+-----+----------+\n|        workclass|    education|    sex|label|prediction|\n+-----------------+-------------+-------+-----+----------+\n|          Private|      7th-8th|   Male|  1.0|       0.0|\n|          Private|   Assoc-acdm| Female|  1.0|       0.0|\n|          Private|      HS-grad|   Male|  1.0|       0.0|\n|          Private|   Assoc-acdm|   Male|  0.0|       1.0|\n|          Private|    Bachelors|   Male|  1.0|       0.0|\n|          Private| Some-college| Female|  0.0|       1.0|\n|          Private|    Bachelors| Female|  1.0|       0.0|\n|          Private| Some-college| Female|  1.0|       0.0|\n|          Private| Some-college|   Male|  1.0|       0.0|\n|          Private| Some-college| Female|  0.0|       1.0|\n| Self-emp-not-inc| Some-college|   Male|  1.0|       0.0|\n|        State-gov|    Bachelors|   Male|  0.0|       1.0|\n|          Private|    Bachelors|   Male|  0.0|       1.0|\n|          Private|   Assoc-acdm| Female|  0.0|       1.0|\n|          Private|      HS-grad|   Male|  0.0|       1.0|\n| Self-emp-not-inc|    Bachelors|   Male|  1.0|       0.0|\n| Self-emp-not-inc|         11th|   Male|  1.0|       0.0|\n|                ?| Some-college|   Male|  1.0|       0.0|\n|        Local-gov|    Bachelors|   Male|  0.0|       1.0|\n|          Private|    Assoc-voc|   Male|  1.0|       0.0|\n+-----------------+-------------+-------+-----+----------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 8, 2017 8:31:04 AM",
      "dateStarted": "Mar 10, 2017 9:38:43 PM",
      "dateFinished": "Mar 10, 2017 9:38:55 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nNous implémentons ci-contre un model de régression logistique binomial avec un nombre d\u0027itération maximum fixé à 10 et un paramètre de régularisation fixé à 0.01.\n\nNous pouvons enuite adapter le modèle à notre jeu de données training (70% du dataset initial). Le but est de créer un estimateur sur un jeu de données assez large afin d\u0027obtenir des prédictions justes. \n\nUne fois l\u0027estimateur créé, nous pouvons le tester en l\u0027appliquant sur le jeu de données test.\n\nBinaryClassificationEvaluator nous permet de voir si l\u0027estimateur déduit du jeu de données training est juste si on l\u0027applique sur le jeu de données test. Nous obtenons un taux d\u0027estimation juste à 87.85%. OUaou !\n\nRemarque :\nEn observant le dataFrame datasetEstimated, nous remarquons l\u0027apparition de 3 nouvelles colonnes :\nrawPrediction | probability | prediction\n[5.29605336427181...|[0.99501365539711...|       0.0|\n\nLa colonne qui nous intéresse le plus est \"prediction\" qui représente la tranche salariale estimée de l\u0027individu (0.0 : \u003c\u003d50K | 1.0 : \u003e50K)\nLa méthode fit du model LogisticRegression recherche deux colonnes dans le dataset passé en paramètre : \"label\" et \"features\"\nDans notre cas, label est bien la représentation binaire de la variable \"income\".\n",
      "dateUpdated": "Mar 9, 2017 11:15:35 AM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 519.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486587158918_-1179673765",
      "id": "20170208-205238_904602592",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eNous implémentons ci-contre un model de régression logistique binomial avec un nombre d\u0027itération maximum fixé à 10 et un paramètre de régularisation fixé à 0.01.\u003c/p\u003e\n\u003cp\u003eNous pouvons enuite adapter le modèle à notre jeu de données training (70% du dataset initial). Le but est de créer un estimateur sur un jeu de données assez large afin d\u0027obtenir des prédictions justes.\u003c/p\u003e\n\u003cp\u003eUne fois l\u0027estimateur créé, nous pouvons le tester en l\u0027appliquant sur le jeu de données test.\u003c/p\u003e\n\u003cp\u003eBinaryClassificationEvaluator nous permet de voir si l\u0027estimateur déduit du jeu de données training est juste si on l\u0027applique sur le jeu de données test. Nous obtenons un taux d\u0027estimation juste à 87.85%. OUaou !\u003c/p\u003e\n\u003cp\u003eRemarque :\n\u003cbr  /\u003eEn observant le dataFrame datasetEstimated, nous remarquons l\u0027apparition de 3 nouvelles colonnes :\n\u003cbr  /\u003erawPrediction | probability | prediction\n\u003cbr  /\u003e[5.29605336427181\u0026hellip;|[0.99501365539711\u0026hellip;|       0.0|\u003c/p\u003e\n\u003cp\u003eLa colonne qui nous intéresse le plus est \u0026ldquo;prediction\u0026rdquo; qui représente la tranche salariale estimée de l\u0027individu (0.0 : \u003c\u003d50K | 1.0 : \u003e50K)\n\u003cbr  /\u003eLa méthode fit du model LogisticRegression recherche deux colonnes dans le dataset passé en paramètre : \u0026ldquo;label\u0026rdquo; et \u0026ldquo;features\u0026rdquo;\n\u003cbr  /\u003eDans notre cas, label est bien la représentation binaire de la variable \u0026ldquo;income\u0026rdquo;.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 8:52:38 AM",
      "dateStarted": "Mar 9, 2017 11:15:34 AM",
      "dateFinished": "Mar 9, 2017 11:15:34 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Decision Trees (estimation 61.33%)",
      "text": "import org.apache.spark.ml.classification.DecisionTreeClassifier\r\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\r\n\r\n// Implémentation du model de machine learning DecisionTreeClassifier\r\nval dt \u003d new DecisionTreeClassifier()\r\n  \r\n// Création d\u0027un estimateur en adaptant le modèle arbre de décision sur les données training issues du dataset\r\nval dtModel \u003d dt.fit(training)\r\n\r\n// Exécution de l\u0027estimateur sur les données test issues du dataset\r\nval datasetEstimated \u003d dtModel.transform(test);\r\n\r\n// Evaluation des prédictions grâce à BinaryClassificationEvaluator\r\nval bce \u003d new BinaryClassificationEvaluator()\r\n\r\n// Nous obtenons une estimation juste à 61.33%\r\nbce.evaluate(datasetEstimated)\r\n\r\n// Affichage des erreurs d\u0027estimation\r\ndatasetEstimated.filter($\"label\" !\u003d\u003d $\"prediction\").select(\"workclass\", \"education\", \"sex\", \"label\",\"prediction\").show()\r\n",
      "dateUpdated": "Mar 10, 2017 9:39:45 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487973619306_-310162580",
      "id": "20170224-220019_1657356938",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\ndt: org.apache.spark.ml.classification.DecisionTreeClassifier \u003d dtc_3748fccf7150\n\ndtModel: org.apache.spark.ml.classification.DecisionTreeClassificationModel \u003d DecisionTreeClassificationModel (uid\u003ddtc_3748fccf7150) of depth 5 with 63 nodes\n\ndatasetEstimated: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 34 more fields]\n\nbce: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator \u003d binEval_5d79ebaa67eb\n\nres27: Double \u003d 0.609343586173194\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+-----------------+-------------+-------+-----+----------+\n|        workclass|    education|    sex|label|prediction|\n+-----------------+-------------+-------+-----+----------+\n|          Private|      7th-8th|   Male|  1.0|       0.0|\n|          Private|      HS-grad| Female|  0.0|       1.0|\n|          Private|   Assoc-acdm| Female|  1.0|       0.0|\n|          Private|    Bachelors| Female|  0.0|       1.0|\n|          Private|   Assoc-acdm|   Male|  0.0|       1.0|\n|          Private|    Bachelors|   Male|  1.0|       0.0|\n|          Private|    Bachelors| Female|  1.0|       0.0|\n|          Private| Some-college| Female|  1.0|       0.0|\n|          Private| Some-college|   Male|  1.0|       0.0|\n|          Private| Some-college| Female|  0.0|       1.0|\n| Self-emp-not-inc| Some-college|   Male|  1.0|       0.0|\n|        State-gov|    Bachelors|   Male|  0.0|       1.0|\n|          Private|    Bachelors|   Male|  0.0|       1.0|\n|          Private|    Bachelors| Female|  0.0|       1.0|\n|          Private|      HS-grad|   Male|  0.0|       1.0|\n| Self-emp-not-inc|    Bachelors|   Male|  1.0|       0.0|\n| Self-emp-not-inc|         11th|   Male|  1.0|       0.0|\n|        State-gov| Some-college|   Male|  0.0|       1.0|\n|                ?| Some-college|   Male|  1.0|       0.0|\n|        Local-gov|    Bachelors|   Male|  0.0|       1.0|\n+-----------------+-------------+-------+-----+----------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 24, 2017 10:00:19 AM",
      "dateStarted": "Mar 10, 2017 9:39:45 PM",
      "dateFinished": "Mar 10, 2017 9:40:02 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplications :\n\nLes étapes avec le modèle decision tree sont les mêmes qu\u0027avec le modèle binomial logistic regression.\n\nNous observons une estimation juste à 61.33%\n\nNous remarquons dans les logs que les calculs DecisionTreeClassifier a utilisé une profondeur de 5 et 63 noeuds pour ses calculs.",
      "dateUpdated": "Mar 10, 2017 9:31:19 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487978724867_1349517172",
      "id": "20170224-232524_1758309852",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eLes étapes avec le modèle decision tree sont les mêmes qu\u0027avec le modèle binomial logistic regression.\u003c/p\u003e\n\u003cp\u003eNous observons une estimation juste à 61.33%\u003c/p\u003e\n\u003cp\u003eNous remarquons dans les logs que les calculs DecisionTreeClassifier a utilisé une profondeur de 5 et 63 noeuds pour ses calculs.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 24, 2017 11:25:24 AM",
      "dateStarted": "Mar 10, 2017 9:31:18 PM",
      "dateFinished": "Mar 10, 2017 9:31:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Random Forest  (estimation 86.07%)",
      "text": "import org.apache.spark.ml.classification.RandomForestClassifier\r\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\r\n\r\n// Implémentation du model de machine learning RandomForestClassifier\r\nval dt \u003d new RandomForestClassifier()\r\n\r\n// Création d\u0027un estimateur en adaptant le modèle Random forest sur les données training issues du dataset\r\nval rfModel \u003d dt.fit(training)\r\n\r\n// Exécution de l\u0027estimateur sur les données test issues du dataset\r\nval datasetEstimated \u003d rfModel.transform(test);\r\n\r\n// Evaluation des prédictions grâce à BinaryClassificationEvaluator\r\nval bce \u003d new BinaryClassificationEvaluator()\r\n\r\n// Nous obtenons une estimation juste à 86.07%\r\nbce.evaluate(datasetEstimated)\r\n\r\n// Affichage des erreurs d\u0027estimation\r\ndatasetEstimated.filter($\"label\" !\u003d\u003d $\"prediction\").select(\"workclass\", \"education\", \"sex\", \"label\",\"prediction\").show()",
      "dateUpdated": "Mar 10, 2017 9:40:11 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487978965473_407988997",
      "id": "20170224-232925_1666782405",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.classification.RandomForestClassifier\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\ndt: org.apache.spark.ml.classification.RandomForestClassifier \u003d rfc_e029fb2b1b85\n\nrfModel: org.apache.spark.ml.classification.RandomForestClassificationModel \u003d RandomForestClassificationModel (uid\u003drfc_d5023babd6bb) with 20 trees\n\ndatasetEstimated: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 34 more fields]\n\nbce: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator \u003d binEval_6c88d958cb2a\n\nres30: Double \u003d 0.8602418966910703\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+-----------------+-------------+-------+-----+----------+\n|        workclass|    education|    sex|label|prediction|\n+-----------------+-------------+-------+-----+----------+\n|          Private|      7th-8th|   Male|  1.0|       0.0|\n|          Private|   Assoc-acdm| Female|  1.0|       0.0|\n|          Private|      HS-grad|   Male|  1.0|       0.0|\n|          Private|    Bachelors|   Male|  1.0|       0.0|\n|          Private|    Bachelors| Female|  1.0|       0.0|\n|          Private| Some-college| Female|  1.0|       0.0|\n|          Private| Some-college|   Male|  1.0|       0.0|\n| Self-emp-not-inc| Some-college|   Male|  1.0|       0.0|\n|        State-gov|    Bachelors|   Male|  0.0|       1.0|\n|          Private|    Bachelors|   Male|  0.0|       1.0|\n| Self-emp-not-inc|    Bachelors|   Male|  1.0|       0.0|\n| Self-emp-not-inc|         11th|   Male|  1.0|       0.0|\n|        State-gov| Some-college|   Male|  0.0|       1.0|\n|                ?| Some-college|   Male|  1.0|       0.0|\n|        Local-gov|    Bachelors|   Male|  0.0|       1.0|\n|        Local-gov| Some-college|   Male|  1.0|       0.0|\n|          Private|    Assoc-voc|   Male|  1.0|       0.0|\n|          Private| Some-college|   Male|  1.0|       0.0|\n|          Private|    Bachelors|   Male|  0.0|       1.0|\n|          Private|    Bachelors| Female|  1.0|       0.0|\n+-----------------+-------------+-------+-----+----------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 24, 2017 11:29:25 AM",
      "dateStarted": "Mar 10, 2017 9:40:11 PM",
      "dateFinished": "Mar 10, 2017 9:40:30 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nNous remarquons que RandomForestClassifier a construit 20 arbres pour effectuer ses calculs.",
      "dateUpdated": "Mar 10, 2017 9:33:01 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1489181526783_-507454868",
      "id": "20170310-213206_1139740538",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eNous remarquons que RandomForestClassifier a construit 20 arbres pour effectuer ses calculs.\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 10, 2017 9:32:06 PM",
      "dateStarted": "Mar 10, 2017 9:33:00 PM",
      "dateFinished": "Mar 10, 2017 9:33:00 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\nUse [cross-validation](http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation) to select the best hyperparameters for your model",
      "dateUpdated": "Feb 7, 2017 12:55:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486412170872_-693891339",
      "id": "20170206-201610_429327674",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\u003cp\u003eUse \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation\"\u003ecross-validation\u003c/a\u003e to select the best hyperparameters for your model\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 6, 2017 8:16:10 AM",
      "dateStarted": "Feb 7, 2017 12:55:45 PM",
      "dateFinished": "Feb 7, 2017 12:55:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Tuning : Cross-validator (estimation 87.91%)",
      "text": "import org.apache.spark.ml.Pipeline\r\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\r\nimport org.apache.spark.ml.classification.LogisticRegression\r\nimport org.apache.spark.ml.classification.LogisticRegressionModel\r\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\r\n\r\n// Nomble de splits (plus la valeur est élevée, plus le modèle obtenu sera fiable)\r\nval nFolds: Int \u003d 2\r\n\r\n// Instanciation de l\u0027estimateur\r\nval lr \u003d new LogisticRegression()\r\n\r\n// Création de la grille de paramètres pour l\u0027algorythme de cross-validation\r\nval paramGrid \u003d new ParamGridBuilder()\r\n  .addGrid(lr.regParam, Array(0.1, 0.01))\r\n  .build()\r\n\r\n// Instanciation du modèle de prédiction\r\nval cv \u003d new CrossValidator()\r\n  .setEstimator(lr) // affectation de l\u0027estimateur\r\n  .setEvaluator(new BinaryClassificationEvaluator()) // l\u0027évaluateur utilisé\r\n  .setEstimatorParamMaps(paramGrid) // Les paramètres en entrée\r\n  .setNumFolds(nFolds)\r\n\r\nval cvModel \u003d cv.fit(training)\r\n\r\nval eval \u003d new BinaryClassificationEvaluator().evaluate(cvModel.transform(test))\r\n",
      "dateUpdated": "Mar 10, 2017 9:37:02 PM",
      "config": {
        "colWidth": 8.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487979372471_-619106677",
      "id": "20170224-233612_831292856",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.Pipeline\n\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n\nimport org.apache.spark.ml.classification.LogisticRegression\n\nimport org.apache.spark.ml.classification.LogisticRegressionModel\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\nnFolds: Int \u003d 2\n\nlr: org.apache.spark.ml.classification.LogisticRegression \u003d logreg_3ef8ea2de695\n\n\n\n\n\n\nparamGrid: Array[org.apache.spark.ml.param.ParamMap] \u003d\nArray({\n\tlogreg_3ef8ea2de695-regParam: 0.1\n}, {\n\tlogreg_3ef8ea2de695-regParam: 0.01\n})\n\ncv: org.apache.spark.ml.tuning.CrossValidator \u003d cv_bdd7ee184dab\n\ncvModel: org.apache.spark.ml.tuning.CrossValidatorModel \u003d cv_bdd7ee184dab\n\neval: Double \u003d 0.878887918031873\n"
      },
      "dateCreated": "Feb 24, 2017 11:36:12 AM",
      "dateStarted": "Mar 10, 2017 9:37:03 PM",
      "dateFinished": "Mar 10, 2017 9:37:34 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Cross-validation",
      "text": "%md\nExplications :\n\nFaisons encore un peu de tuning !\nEssayons maintenant d\u0027obtenir le meilleur modèle de prédiction pour notre jeu de données via l\u0027outil CrossValidator fournit par Spark ML.\n\nPour l\u0027implémenter nous allons avoir besoin :\n- d\u0027un \"estimator\" : nous pouvons utiliser l\u0027algorithme LogisticRegression qui a fait ses preuves précédemment.\n- un jeu de paramètres à analyser : nous prendrons tous les paramètres déjà aggrégés dans la colonne features. Nous pourons constituer une \"grille de paramètres\".\n- un \"evaluator\" : pour évaluer la qualité des prédictions durant les calculs. Nous pouvons utiliser BinaryClassificationEvaluator\n\nLe fonctionnement de CrossValidator est plutôt simple, les données en entrée sont découpées et séparées en morceaux (paramètre \"folds\") de données \"training\" et morceaux de données \"test\".\nPour chaque paire (train + test), l\u0027algorithme va itérer sur la grille de paramètres. Un modèle de prédiction va être créé pour chaque paramètre et confronté aux données test, l\u0027estimateur se chargeant d\u0027évaluer la qualité de la prédiction. A la fin du traitement, le modèle retourné correspond à la combinaison des meilleures prédictions déduites des jeux de paramètres.\n\nL\u0027utilisation de CrossValidator peut conduire à des temps de traitement très longs et des consommations CPU élevées mais fourni en contrepartie des statistiques de qualité.",
      "dateUpdated": "Mar 10, 2017 9:36:02 PM",
      "config": {
        "colWidth": 4.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": false,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488721367458_-528157141",
      "id": "20170305-134247_205769108",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eFaisons encore un peu de tuning !\n\u003cbr  /\u003eEssayons maintenant d\u0027obtenir le meilleur modèle de prédiction pour notre jeu de données via l\u0027outil CrossValidator fournit par Spark ML.\u003c/p\u003e\n\u003cp\u003ePour l\u0027implémenter nous allons avoir besoin :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ed\u0027un \u0026ldquo;estimator\u0026rdquo; : nous pouvons utiliser l\u0027algorithme LogisticRegression qui a fait ses preuves précédemment.\u003c/li\u003e\n\u003cli\u003eun jeu de paramètres à analyser : nous prendrons tous les paramètres déjà aggrégés dans la colonne features. Nous pourons constituer une \u0026ldquo;grille de paramètres\u0026rdquo;.\u003c/li\u003e\n\u003cli\u003eun \u0026ldquo;evaluator\u0026rdquo; : pour évaluer la qualité des prédictions durant les calculs. Nous pouvons utiliser BinaryClassificationEvaluator\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLe fonctionnement de CrossValidator est plutôt simple, les données en entrée sont découpées et séparées en morceaux (paramètre \u0026ldquo;folds\u0026rdquo;) de données \u0026ldquo;training\u0026rdquo; et morceaux de données \u0026ldquo;test\u0026rdquo;.\n\u003cbr  /\u003ePour chaque paire (train + test), l\u0027algorithme va itérer sur la grille de paramètres. Un modèle de prédiction va être créé pour chaque paramètre et confronté aux données test, l\u0027estimateur se chargeant d\u0027évaluer la qualité de la prédiction. A la fin du traitement, le modèle retourné correspond à la combinaison des meilleures prédictions déduites des jeux de paramètres.\u003c/p\u003e\n\u003cp\u003eL\u0027utilisation de CrossValidator peut conduire à des temps de traitement très longs et des consommations CPU élevées mais fourni en contrepartie des statistiques de qualité.\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 5, 2017 1:42:47 AM",
      "dateStarted": "Mar 10, 2017 9:36:01 PM",
      "dateFinished": "Mar 10, 2017 9:36:01 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\nThe column `features` is a Vector, and Spark MLlib has specific functions to analyse it. You can `collect()` the column into an array then `map` each `Row` into a `Vector`.\n\n```\nimport org.apache.spark.mllib.linalg.Vector\n\ndf.select(\"features\").rdd.map(t \u003d\u003e t.getAs[Vector](0))\n```\n\n1. Run [basic statistics](http://spark.apache.org/docs/latest/mllib-statistics.html) on the column which contains your features vector.\n2. Check for the columns that are the most [correlated](http://spark.apache.org/docs/latest/mllib-statistics.html#correlations) to your label column.\n3. Conclude on the interesting columns to use if you had to do manual feature selection. Don\u0027t forget the nature of the data you are dealing with.",
      "dateUpdated": "Feb 7, 2017 12:55:45 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114332673_-1809154654",
      "id": "20170203-093212_958935340",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\u003cp\u003eThe column \u003ccode\u003efeatures\u003c/code\u003e is a Vector, and Spark MLlib has specific functions to analyse it. You can \u003ccode\u003ecollect()\u003c/code\u003e the column into an array then \u003ccode\u003emap\u003c/code\u003e each \u003ccode\u003eRow\u003c/code\u003e into a \u003ccode\u003eVector\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport org.apache.spark.mllib.linalg.Vector\n\ndf.select(\"features\").rdd.map(t \u003d\u0026gt; t.getAs[Vector](0))\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eRun \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html\"\u003ebasic statistics\u003c/a\u003e on the column which contains your features vector.\u003c/li\u003e\n\u003cli\u003eCheck for the columns that are the most \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html#correlations\"\u003ecorrelated\u003c/a\u003e to your label column.\u003c/li\u003e\n\u003cli\u003eConclude on the interesting columns to use if you had to do manual feature selection. Don\u0027t forget the nature of the data you are dealing with.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:32:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:45 PM",
      "dateFinished": "Feb 7, 2017 12:55:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Basic Statistics",
      "text": "import org.apache.spark.mllib.linalg.Vectors\r\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\r\n\r\n// Transformation en org.apache.spark.mllib.linalg.Vector pour être compatible avec Statistics.colStats\r\nval features \u003d datasetTransformed.select(\"features\").rdd.map(row \u003d\u003e Vectors.fromML(row.getAs[org.apache.spark.ml.linalg.Vector](\"features\")))\r\n\r\n// Calculs de statistiques sur la colonne feature.\r\nval summary: MultivariateStatisticalSummary \u003d Statistics.colStats(features)\r\nprintln(summary.count) // Nombre total\r\nprintln(summary.mean)  // Vecteur contenant la valeur moyenne\r\nprintln(summary.variance)  // Variance\r\nprintln(summary.numNonzeros)  // Nombre de non zéro",
      "dateUpdated": "Mar 8, 2017 8:42:56 AM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488919556626_517043058",
      "id": "20170307-204556_379895804",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.mllib.linalg.Vectors\n\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\n\nfeatures: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] \u003d MapPartitionsRDD[218] at map at \u003cconsole\u003e:121\n\nsummary: org.apache.spark.mllib.stat.MultivariateStatisticalSummary \u003d org.apache.spark.mllib.stat.MultivariateOnlineSummarizer@25f49244\n32561\n[0.6970301894904948,0.0780381437916526,0.06427935259973588,0.05638647461687295,0.039863640551580114,0.034274131629863945,0.029483123982678664,4.2996222474739717E-4,0.32250238014802984,0.22391818433094807,0.16446055096587942,0.05291606523141181,0.042443413900064494,0.03608611529129941,0.032769263843248055,0.02865391112066583,0.019839685513344186,0.0176898743896072,0.01578575596572587,0.013298117379687356,0.012683885630048217,0.010226958631491662,0.005159546696968767,0.4599367341297872,0.328091889069746,0.1364515831823347,0.03147937716900587,0.030496606369583245,0.012837443567458001,0.12714597217530174,0.1258867970885415,0.12487331470163693,0.11578268480697768,0.11209729430914284,0.10119468075304812,0.0614845981388778,0.056601455729246644,0.04904640520868524,0.04207487485028101,0.0305273179570652,0.02850035318325604,0.019931820275790057,0.004576026534811584,0.40517797364945796,0.2550597340376524,0.1556463253585578,0.10583213046282362,0.04815576917170849,0.8542735173981143,0.0959429992936335,0.03190933939375326,0.009551303706888609,0.6692054912318418,0.895857006848684,0.019747550750898315,0.0179048555019809,0.006080894321427475,0.004207487485028101,0.00371610208531679,0.0035011209729430915,0.003255428273087436,0.0030711587481956942,0.0029176008107859096,0.002764042873376125,0.0024876385860385123,0.0024569269985565555,0.002303369061146771,0.0022419458861828567,0.002149811123736986,0.002057676361291115,0.001965541598845244,0.0019041184238813304,0.0018426952489174165,0.0018119836614354597,0.001566290961579804,0.0013513098492061054,0.0013205982617241485,0.001136328736832407,0.001044193974386536,9.520592119406652E-4,8.906360369767513E-4,8.906360369767513E-4,8.599244494947943E-4,7.370780995669666E-4,6.142317496391389E-4,5.835201621571819E-4,5.835201621571819E-4,5.52808574675225E-4,5.52808574675225E-4,4.91385399711311E-4,4.2996222474739717E-4,3.9925063726544026E-4,3.9925063726544026E-4,3.685390497834833E-4]\n[0.21118559027407036,0.07195040161625954,0.06014936471157103,0.053208674220006795,0.03827570622125458,0.033100432097698765,0.02861474818724289,4.29790556782971E-4,0.21850130546884333,0.17378416824456563,0.13741749845140405,0.05011749445965226,0.040643218734340014,0.03478497587631214,0.031696412637569234,0.02783371931586053,0.019446669630171366,0.017377476423574515,0.015537043041573,0.013121680441480202,0.012523389288537778,0.010122678832177927,0.005133083419991071,0.2484025635648743,0.22045437190011988,0.1178361675651378,0.030489362358776688,0.02956747143350749,0.012673032819066418,0.11098328240768583,0.11004269099306106,0.10928332624149706,0.10238019896430264,0.09953454778168393,0.09095711077760155,0.05770601457389332,0.05339937091802821,0.04664228780349293,0.04030581761225783,0.02959630976506994,0.027688933422786808,0.01953514277152986,0.0045552264141988045,0.24101618530843677,0.19001010162215284,0.13142458301851442,0.09463459700322818,0.04583819883104303,0.12449409828175836,0.08674060412182706,0.030892082198092453,0.009460366847271426,0.22137630055461205,0.09330009552284667,0.019358179510662543,0.017584811708917233,0.0060441026696669954,0.004189913212977615,0.0037024063773856467,0.003488970276691784,0.0032449301168013737,0.0030618207655153692,0.002909177761762142,0.0027564875964802256,0.0024815264519204815,0.002450965781330328,0.002298134131462346,0.0022369882662871205,0.002145255320065676,0.0020535053956939036,0.001961738493171803,0.0019005511258513316,0.0018393562126862702,0.001808755926412018,0.00156388572361669,0.0013495252569605321,0.0013188947873079195,0.001135072353708145,0.0010431356696827658,9.51182007507059E-4,8.8987013375085E-4,8.8987013375085E-4,8.592113671810241E-4,7.365574362902455E-4,6.138733220211062E-4,5.831975773009525E-4,5.831975773009525E-4,5.525199461196513E-4,5.525199461196513E-4,4.911590243736062E-4,4.29790556782971E-4,3.991034932959321E-4,3.991034932959321E-4,3.684145433477456E-4]\n[22696.0,2541.0,2093.0,1836.0,1298.0,1116.0,960.0,14.0,10501.0,7291.0,5355.0,1723.0,1382.0,1175.0,1067.0,933.0,646.0,576.0,514.0,433.0,413.0,333.0,168.0,14976.0,10683.0,4443.0,1025.0,993.0,418.0,4140.0,4099.0,4066.0,3770.0,3650.0,3295.0,2002.0,1843.0,1597.0,1370.0,994.0,928.0,649.0,149.0,13193.0,8305.0,5068.0,3446.0,1568.0,27816.0,3124.0,1039.0,311.0,21790.0,29170.0,643.0,583.0,198.0,137.0,121.0,114.0,106.0,100.0,95.0,90.0,81.0,80.0,75.0,73.0,70.0,67.0,64.0,62.0,60.0,59.0,51.0,44.0,43.0,37.0,34.0,31.0,29.0,29.0,28.0,24.0,20.0,19.0,19.0,18.0,18.0,16.0,14.0,13.0,13.0,12.0]\n"
      },
      "dateCreated": "Mar 7, 2017 8:45:56 AM",
      "dateStarted": "Mar 8, 2017 8:42:56 AM",
      "dateFinished": "Mar 8, 2017 8:42:59 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nExplications :\n\n/!\\ Depuis la version 2.0.0 de Spark ML, les transformers ne génèrent plus d\u0027objets de type\norg.apache.spark.mllib.linalg.*\nmais des \norg.apache.spark.ml.linalg.*\n\nHors, les anciennes API MLLib comme Statistics.colStats manipulent encore des objets de type org.apache.spark.mllib.linalg.*\n\nNous devons donc effectuer une transformation à l\u0027aide de Vectors.fromML().\n\nStatistics.colStats fournit des statistiques sur une colonne donnée :\n\ncolumn-wise max, min, mean, variance, nombre de valeurs différentes de 0, et le nombre de lignes.",
      "dateUpdated": "Mar 10, 2017 9:43:11 PM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488924750611_26684659",
      "id": "20170307-221230_404235526",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003e/!\\ Depuis la version 2.0.0 de Spark ML, les transformers ne génèrent plus d\u0027objets de type\n\u003cbr  /\u003eorg.apache.spark.mllib.linalg.\u003cem\u003e\n\u003cbr  /\u003emais des\n\u003cbr  /\u003eorg.apache.spark.ml.linalg.\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eHors, les anciennes API MLLib comme Statistics.colStats manipulent encore des objets de type org.apache.spark.mllib.linalg.*\u003c/p\u003e\n\u003cp\u003eNous devons donc effectuer une transformation à l\u0027aide de Vectors.fromML().\u003c/p\u003e\n\u003cp\u003eStatistics.colStats fournit des statistiques sur une colonne donnée :\u003c/p\u003e\n\u003cp\u003ecolumn-wise max, min, mean, variance, nombre de valeurs différentes de 0, et le nombre de lignes.\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 7, 2017 10:12:30 AM",
      "dateStarted": "Mar 10, 2017 9:43:10 PM",
      "dateFinished": "Mar 10, 2017 9:43:10 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Matrice de correlation - Variables catégorielles",
      "text": "import org.apache.spark.mllib.linalg._\r\nimport org.apache.spark.rdd.RDD\r\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\r\n\r\n// Transformation des variables numériques en lignes de vecteurs [Double, Double, Double, ...]\r\ndef transform(row: org.apache.spark.sql.Row) \u003d {\r\n    Vectors.dense(\r\n        row.getAs[Double](\"workclassIndex\"), \r\n        row.getAs[Double](\"educationIndex\"), \r\n        row.getAs[Double](\"marital_statusIndex\"),\r\n        row.getAs[Double](\"occupationIndex\"),\r\n        row.getAs[Double](\"relationshipIndex\"),\r\n        row.getAs[Double](\"raceIndex\"),\r\n        row.getAs[Double](\"sexIndex\"),\r\n        row.getAs[Double](\"native_countryIndex\"),\r\n        row.getAs[Double](\"label\"))\r\n}\r\n\r\n// Récupération des valeurs d\u0027index de nos variables catégorielles et création d\u0027une matrice.\r\nval data \u003d datasetTransformed.select(\"workclassIndex\", \"educationIndex\", \"marital_statusIndex\", \"occupationIndex\",\"relationshipIndex\",\"raceIndex\",\"sexIndex\",\r\n\"native_countryIndex\",\"label\").rdd.map(transform)\r\n\r\n// Corrélation des données en suivant la méthode \"pearson\"\r\nval correlMatrix: Matrix \u003d Statistics.corr(data, \"pearson\")\r\n\r\n// Affichage de la dernière colonne de notre matrice de corrélation (l\u0027affichage total de la matrice étant tronqué par Zeppelin).\r\nprintln(\"Correlation des variables catégorielles avec label\")\r\n// Nous itérons sur les 9 lignes de la matrice\r\nfor( r \u003c- 0 to 8){\r\n   println(correlMatrix.apply(r,8)) // nous prenons la dernière colonne de la matrice, soit la colonne label.\r\n   // Cela nous donne uniquement les valeurs de corrélation de label avec les autres variables.\r\n}\r\n\r\n",
      "dateUpdated": "Mar 10, 2017 9:46:52 PM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "table",
          "height": 464.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "lineNumbers": false,
        "editorHide": false,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1488926898275_-1394127920",
      "id": "20170307-224818_1768956173",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.mllib.linalg._\n\nimport org.apache.spark.rdd.RDD\n\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\n\ntransform: (row: org.apache.spark.sql.Row)org.apache.spark.mllib.linalg.Vector\n\ndata: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] \u003d MapPartitionsRDD[1220] at map at \u003cconsole\u003e:90\n\n\n\n\n\n\n\n\n\n\ncorrelMatrix: org.apache.spark.mllib.linalg.Matrix \u003d\n1.0                    0.025058793314385285   ... (9 total)\n0.025058793314385285   1.0                    ...\n-0.02094776445756036   -0.005434625195892772  ...\n0.004221821727380694   -0.016488230236019898  ...\n-0.04529256641662074   -0.0140352217794821    ...\n0.01899582646261035    0.032037811932174566   ...\n-0.016413012724471605  -0.040215818430723936  ...\n-0.021414486846229108  0.08295283848746762    ...\n0.10222928987988947    0.042448952120948354   ...\nCorrelation des variables catégorielles avec label\n0.10222928987988947\n0.042448952120948354\n-0.3112877621172519\n-0.18563604587187174\n-0.2542920971961014\n-0.06771307197620637\n-0.21598015058403647\n-0.018498437602558336\n1.0\n"
      },
      "dateCreated": "Mar 7, 2017 10:48:18 AM",
      "dateStarted": "Mar 10, 2017 9:46:52 PM",
      "dateFinished": "Mar 10, 2017 9:46:58 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nExplications :\n\nNous allons tenter de déterminer les colonnes qui ont la meilleure corrélation avec le label (colonne \"income\") grâce à la méthode Statistics.corr() fournie par Spark ML. Celle-ci permet d\u0027obtenir une matrice de corrélation qui permettra d\u0027évaluer les dépendences entre toutes nos variables.\n\nCes calculs sont possibles uniquement sur des données de type numérique (Double), c\u0027est pourquoi nous allons utiliser les colonnes générées précédemment via \"stringIndexer\". Pour rappel, ces colonnes indiquent la position (Double) du bit à \"1\" du vecteur binaire représentant la variable catégorielle. Cette valeur décrit de manière fiable et précise chacun des états de la variable.\n\nLa méthode Vectors.dense() permet de constituer un vecteur numérique (Double) à partir des valeurs d\u0027index de nos variables non-numériques. Nous obtenons une matrice dont le nombre de colonnes correspond au nombre de variables et le nombre de lignes au nombre d\u0027individus du Dataset. \n\nLes valeurs obtenues dans la matrice de correlation (d\u0027une taille de nb_variables * nb_variables) sont comprises entre -1 et 1. Les meilleures dépendences sont les valeurs absolues les plus proches de 1. Notons d\u0027ailleurs qu\u0027une valeur correlée avec elle même donne 1.\n\nVoici les valeurs obtenues :\nworkclassIndex -\u003e 0.10222928987988947\neducationIndex -\u003e 0.042448952120948354\nmarital_statusIndex -\u003e -0.3112877621172519\noccupationIndex -\u003e -0.18563604587187174\nrelationshipIndex -\u003e -0.2542920971961014\nraceIndex -\u003e -0.06771307197620637\nsexIndex -\u003e -0.21598015058403647\nnative_countryIndex-\u003e -0.018498437602558336\nlabel-\u003e 1.0\n\nLes variables catégorielles qui ont la meilleure correlation avec la variable \"label\" sont :\n- marital_statusIndex\n- relationshipIndex\n- sexIndex\n\n",
      "dateUpdated": "Mar 9, 2017 11:14:04 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1489097837847_-83787217",
      "id": "20170309-221717_1165006039",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eExplications :\u003c/p\u003e\n\u003cp\u003eNous allons tenter de déterminer les colonnes qui ont la meilleure corrélation avec le label (colonne \u0026ldquo;income\u0026rdquo;) grâce à la méthode Statistics.corr() fournie par Spark ML. Celle-ci permet d\u0027obtenir une matrice de corrélation qui permettra d\u0027évaluer les dépendences entre toutes nos variables.\u003c/p\u003e\n\u003cp\u003eCes calculs sont possibles uniquement sur des données de type numérique (Double), c\u0027est pourquoi nous allons utiliser les colonnes générées précédemment via \u0026ldquo;stringIndexer\u0026rdquo;. Pour rappel, ces colonnes indiquent la position (Double) du bit à \u0026ldquo;1\u0026rdquo; du vecteur binaire représentant la variable catégorielle. Cette valeur décrit de manière fiable et précise chacun des états de la variable.\u003c/p\u003e\n\u003cp\u003eLa méthode Vectors.dense() permet de constituer un vecteur numérique (Double) à partir des valeurs d\u0027index de nos variables non-numériques. Nous obtenons une matrice dont le nombre de colonnes correspond au nombre de variables et le nombre de lignes au nombre d\u0027individus du Dataset.\u003c/p\u003e\n\u003cp\u003eLes valeurs obtenues dans la matrice de correlation (d\u0027une taille de nb_variables * nb_variables) sont comprises entre -1 et 1. Les meilleures dépendences sont les valeurs absolues les plus proches de 1. Notons d\u0027ailleurs qu\u0027une valeur correlée avec elle même donne 1.\u003c/p\u003e\n\u003cp\u003eVoici les valeurs obtenues :\n\u003cbr  /\u003eworkclassIndex -\u003e 0.10222928987988947\n\u003cbr  /\u003eeducationIndex -\u003e 0.042448952120948354\n\u003cbr  /\u003emarital_statusIndex -\u003e -0.3112877621172519\n\u003cbr  /\u003eoccupationIndex -\u003e -0.18563604587187174\n\u003cbr  /\u003erelationshipIndex -\u003e -0.2542920971961014\n\u003cbr  /\u003eraceIndex -\u003e -0.06771307197620637\n\u003cbr  /\u003esexIndex -\u003e -0.21598015058403647\n\u003cbr  /\u003enative_countryIndex-\u003e -0.018498437602558336\n\u003cbr  /\u003elabel-\u003e 1.0\u003c/p\u003e\n\u003cp\u003eLes variables catégorielles qui ont la meilleure correlation avec la variable \u0026ldquo;label\u0026rdquo; sont :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emarital_statusIndex\u003c/li\u003e\n\u003cli\u003erelationshipIndex\u003c/li\u003e\n\u003cli\u003esexIndex\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Mar 9, 2017 10:17:17 AM",
      "dateStarted": "Mar 9, 2017 11:14:03 AM",
      "dateFinished": "Mar 9, 2017 11:14:03 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Matrice de correlation - Variables numériques",
      "text": "import org.apache.spark.mllib.linalg._\r\nimport org.apache.spark.rdd.RDD\r\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\r\n\r\n// Transformation des variables numériques en vecteurs\r\ndef transform(row: org.apache.spark.sql.Row) \u003d {\r\n    Vectors.dense(\r\n        row.getAs[Double](\"age\"), \r\n        row.getAs[Double](\"fnlwgt\"), \r\n        row.getAs[Double](\"education_num\"),\r\n        row.getAs[Double](\"capital_gain\"),\r\n        row.getAs[Double](\"capital_loss\"),\r\n        row.getAs[Double](\"hours_per_week\"),\r\n        row.getAs[Double](\"label\"))\r\n}\r\n\r\n// Récupération des valeurs d\u0027index de nos variables numériques et création d\u0027une matrice.\r\nval data \u003d datasetTransformed.select(\"age\",\"fnlwgt\",\"education_num\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\"label\").rdd.map(transform)\r\n\r\n// Corrélation des données en suivant la méthode \"pearson\"\r\nval correlMatrix: Matrix \u003d Statistics.corr(data, \"pearson\")\r\n\r\n// Affichage de la dernière colonne de notre matrice de corrélation.\r\n// L\u0027affichage de la matrice étant tronquée dans Zeppelin.\r\nprintln(\"Correlation des variables numériques avec label\")\r\nfor( r \u003c- 0 to 6){\r\n   println(correlMatrix.apply(r,6))\r\n}",
      "dateUpdated": "Mar 10, 2017 9:47:12 PM",
      "config": {
        "colWidth": 9.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1489097245354_-909889602",
      "id": "20170309-220725_1132796116",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.mllib.linalg._\n\nimport org.apache.spark.rdd.RDD\n\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\n\ntransform: (row: org.apache.spark.sql.Row)org.apache.spark.mllib.linalg.Vector\n\ndata: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] \u003d MapPartitionsRDD[1227] at map at \u003cconsole\u003e:94\n\n\n\n\n\n\n\n\ncorrelMatrix: org.apache.spark.mllib.linalg.Matrix \u003d\n1.0                   -0.07664586787512112   ... (7 total)\n-0.07664586787512112  1.0                    ...\n0.036527189463887326  -0.043194632733143924  ...\n0.07767449816599513   4.318857918850918E-4   ...\n0.05777453947897402   -0.010251711675332767  ...\n0.06875570750946958   -0.018768490610778656  ...\n0.23403710264886027   -0.009462557247534543  ...\nCorrelation des variables numériques avec label\n0.23403710264886027\n-0.009462557247534543\n0.3351539526909747\n0.2233288181953826\n0.1505263117703537\n0.22968906567081035\n1.0\n"
      },
      "dateCreated": "Mar 9, 2017 10:07:25 AM",
      "dateStarted": "Mar 10, 2017 9:47:12 PM",
      "dateFinished": "Mar 10, 2017 9:47:16 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nPour finir :\n\nPar curiosité, voyons ce que donne la matrice de correlation sur les données numériques de notre dataset :\n\nage -\u003e 0.23403710264886027\nfnlwgt -\u003e -0.009462557247534543\neducation_num -\u003e 0.3351539526909747\ncapital_gain -\u003e 0.2233288181953826\ncapital_loss -\u003e 0.1505263117703537\nhours_per_week -\u003e 0.22968906567081035\nlabel -\u003e 1.0\n\nLes valeurs de corrélation sont globalement meilleures que celles obtenues précédemment.\n",
      "dateUpdated": "Mar 9, 2017 11:15:00 AM",
      "config": {
        "colWidth": 3.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1489100427162_211022909",
      "id": "20170309-230027_263661976",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003ePour finir :\u003c/p\u003e\n\u003cp\u003ePar curiosité, voyons ce que donne la matrice de correlation sur les données numériques de notre dataset :\u003c/p\u003e\n\u003cp\u003eage -\u003e 0.23403710264886027\n\u003cbr  /\u003efnlwgt -\u003e -0.009462557247534543\n\u003cbr  /\u003eeducation_num -\u003e 0.3351539526909747\n\u003cbr  /\u003ecapital_gain -\u003e 0.2233288181953826\n\u003cbr  /\u003ecapital_loss -\u003e 0.1505263117703537\n\u003cbr  /\u003ehours_per_week -\u003e 0.22968906567081035\n\u003cbr  /\u003elabel -\u003e 1.0\u003c/p\u003e\n\u003cp\u003eLes valeurs de corrélation sont globalement meilleures que celles obtenues précédemment.\u003c/p\u003e\n"
      },
      "dateCreated": "Mar 9, 2017 11:00:27 AM",
      "dateStarted": "Mar 9, 2017 11:14:52 AM",
      "dateFinished": "Mar 9, 2017 11:14:52 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Mar 9, 2017 10:58:56 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1489100325618_927704485",
      "id": "20170309-225845_882631276",
      "dateCreated": "Mar 9, 2017 10:58:45 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "BinaryClassification",
  "id": "2C76YWXDZ",
  "angularObjects": {
    "2CAC6Y4FB:shared_process": [],
    "2CASNQJ8V:shared_process": [],
    "2CAXG2EGZ:shared_process": [],
    "2CCVZ3W9D:shared_process": [],
    "2CABRFYUY:shared_process": [],
    "2CC7PM2CU:shared_process": [],
    "2CCWW4ZHA:shared_process": [],
    "2CC55X12H:shared_process": [],
    "2CAY5KJWU:shared_process": [],
    "2CAU1H4XM:shared_process": [],
    "2CDKENY9A:shared_process": [],
    "2C9TP93ZB:shared_process": [],
    "2CCFZUF9Q:shared_process": [],
    "2C9VSN4NR:shared_process": [],
    "2CDK2ZAGA:shared_process": [],
    "2CCWPSBAH:shared_process": [],
    "2CCZ6WZS8:shared_process": [],
    "2CBNDF4TP:shared_process": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}