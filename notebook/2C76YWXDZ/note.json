{
  "paragraphs": [
    {
      "text": "%md\n\n# Binary Classification Algorithms with Pipelines API\n\nName(s): MARTINS Jean-Marc\nClass: BIBD G2\n\n\u003chr\u003e\n\nIn this notebook, we will test out the Binary Classification algorithms available in the ML Pipelines API using the Adult dataset. The Pipelines API provides higher-level API built on top of DataFrames for constructing ML pipelines. You can read more about the ML Pipelines API in the [programming guide](http://spark.apache.org/docs/2.0.1/ml-guide.html).\n\n**Binary Classification** is the task of predicting a binary 0 or 1 label.  E.g., is an email spam or not spam?  Should I show this ad to this user or not?  Will it rain tomorrow or not?  This notebook demonstrates several algorithms for making these types of predictions.\n\n\u003chr\u003e\n\nThis notebook will act as your written assignment. As such, it should contain your code and all necessary explanations, like why did you use that or why do you think this happens. When I read it at the end, I should understand all of your reasoning.\n\nDon\u0027t forget to __frequently__ commit your code and push it back to Github. A good advice would be that anytime your answer a question with code and explanation, you should commit a message referencing the question and push it to Github. By versioning frequently, you keep a good history of your work and can eventually return back. At the end of the assignment, you will notify me of your work via a pull request.\n\nYour mark will be based on:\n- your commit activity\n- completing the full analysis of the dataset, from describing it to predicting the income value and evaluating that\n\nThe questions I have put serve as a guideline, but you are totally free to change the text and put your own descriptions (which is absolutely appreciated because it shows you have fully comprehended the problem)\n\n\u003chr\u003e\n\n####Table of Contents\n\n* Dataset Review\n* Load Data\n* Descriptive analysis\n* Data Preprocessing\n* Creation of models\n* Conclusion",
      "dateUpdated": "Feb 8, 2017 6:49:12 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110006257_-279747651",
      "id": "20170203-082006_1849162249",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch1\u003eBinary Classification Algorithms with Pipelines API\u003c/h1\u003e\n\u003cp\u003eName(s): MARTINS Jean-Marc\n\u003cbr  /\u003eClass: BIBD G2\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIn this notebook, we will test out the Binary Classification algorithms available in the ML Pipelines API using the Adult dataset. The Pipelines API provides higher-level API built on top of DataFrames for constructing ML pipelines. You can read more about the ML Pipelines API in the \u003ca href\u003d\"http://spark.apache.org/docs/2.0.1/ml-guide.html\"\u003eprogramming guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eBinary Classification\u003c/strong\u003e is the task of predicting a binary 0 or 1 label.  E.g., is an email spam or not spam?  Should I show this ad to this user or not?  Will it rain tomorrow or not?  This notebook demonstrates several algorithms for making these types of predictions.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eThis notebook will act as your written assignment. As such, it should contain your code and all necessary explanations, like why did you use that or why do you think this happens. When I read it at the end, I should understand all of your reasoning.\u003c/p\u003e\n\u003cp\u003eDon\u0027t forget to \u003cstrong\u003efrequently\u003c/strong\u003e commit your code and push it back to Github. A good advice would be that anytime your answer a question with code and explanation, you should commit a message referencing the question and push it to Github. By versioning frequently, you keep a good history of your work and can eventually return back. At the end of the assignment, you will notify me of your work via a pull request.\u003c/p\u003e\n\u003cp\u003eYour mark will be based on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eyour commit activity\u003c/li\u003e\n\u003cli\u003ecompleting the full analysis of the dataset, from describing it to predicting the income value and evaluating that\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe questions I have put serve as a guideline, but you are totally free to change the text and put your own descriptions (which is absolutely appreciated because it shows you have fully comprehended the problem)\u003c/p\u003e\n\u003chr\u003e\n\u003ch4\u003eTable of Contents\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eDataset Review\u003c/li\u003e\n\u003cli\u003eLoad Data\u003c/li\u003e\n\u003cli\u003eDescriptive analysis\u003c/li\u003e\n\u003cli\u003eData Preprocessing\u003c/li\u003e\n\u003cli\u003eCreation of models\u003c/li\u003e\n\u003cli\u003eConclusion\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:20:06 AM",
      "dateStarted": "Feb 8, 2017 6:49:12 AM",
      "dateFinished": "Feb 8, 2017 6:49:12 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## I. Dataset review\n\nThe Adult dataset is publicly available at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult). This data was obtained from the Census, and consists of information about 48842 individuals and their annual income. We will use this information to predict if an individual earns \u003e50k a year or \u003c\u003d50K a year. The dataset is rather clean, and consists of both numeric and categorical variables.\n\nAttribute Information:\n- age: continuous\n- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n- fnlwgt: continuous\n- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc...\n- education-num: continuous\n- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent...\n- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners...\n- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n- sex: Female, Male. \n- capital-gain: continuous\n- capital-loss: continuous\n- hours-per-week: continuous\n- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany...\n\n\nDetailed Information:\n\n- age – The age of the individual\n- workclass – The type of employer the individual has. Whether they are government, military, private, an d so on.\n- fnlwgt – The \\# of people the census takers believe that observation represents. We will be ignoring this variable\n- education – The highest level of education achieved for that individual\n- education_num – Highest level of education in numerical form\n- marital_status – Marital status of the individual\n- occupation – The occupation of the individual\n- relationship – A bit more difficult to explain. Contains family relationship values like husband, father, and so on, but only contains one per observation. I’m not sure what this is supposed to represent\n- race – descriptions of the individuals race. Black, White, Eskimo, and so on\n- sex – Biological Sex\n- capital_gain – Capital gains recorded\n- capital_loss – Capital Losses recorded\n- hours-per-week – Hours worked per week\n- native-country – Country of origin for person\n\n\n\nTarget/Label:\n- \u003c\u003d50K, \u003e50K",
      "dateUpdated": "Feb 20, 2017 9:21:12 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110092601_361345828",
      "id": "20170203-082132_1615989350",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eI. Dataset review\u003c/h2\u003e\n\u003cp\u003eThe Adult dataset is publicly available at the \u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/Adult\"\u003eUCI Machine Learning Repository\u003c/a\u003e. This data was obtained from the Census, and consists of information about 48842 individuals and their annual income. We will use this information to predict if an individual earns \u003e50k a year or \u0026lt;\u003d50K a year. The dataset is rather clean, and consists of both numeric and categorical variables.\u003c/p\u003e\n\u003cp\u003eAttribute Information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eage: continuous\u003c/li\u003e\n\u003cli\u003eworkclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\u003c/li\u003e\n\u003cli\u003efnlwgt: continuous\u003c/li\u003e\n\u003cli\u003eeducation: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc\u0026hellip;\u003c/li\u003e\n\u003cli\u003eeducation-num: continuous\u003c/li\u003e\n\u003cli\u003emarital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent\u0026hellip;\u003c/li\u003e\n\u003cli\u003eoccupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners\u0026hellip;\u003c/li\u003e\n\u003cli\u003erelationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\u003c/li\u003e\n\u003cli\u003erace: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\u003c/li\u003e\n\u003cli\u003esex: Female, Male.\u003c/li\u003e\n\u003cli\u003ecapital-gain: continuous\u003c/li\u003e\n\u003cli\u003ecapital-loss: continuous\u003c/li\u003e\n\u003cli\u003ehours-per-week: continuous\u003c/li\u003e\n\u003cli\u003enative-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDetailed Information:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eage – The age of the individual\u003c/li\u003e\n\u003cli\u003eworkclass – The type of employer the individual has. Whether they are government, military, private, an d so on.\u003c/li\u003e\n\u003cli\u003efnlwgt – The # of people the census takers believe that observation represents. We will be ignoring this variable\u003c/li\u003e\n\u003cli\u003eeducation – The highest level of education achieved for that individual\u003c/li\u003e\n\u003cli\u003eeducation_num – Highest level of education in numerical form\u003c/li\u003e\n\u003cli\u003emarital_status – Marital status of the individual\u003c/li\u003e\n\u003cli\u003eoccupation – The occupation of the individual\u003c/li\u003e\n\u003cli\u003erelationship – A bit more difficult to explain. Contains family relationship values like husband, father, and so on, but only contains one per observation. I’m not sure what this is supposed to represent\u003c/li\u003e\n\u003cli\u003erace – descriptions of the individuals race. Black, White, Eskimo, and so on\u003c/li\u003e\n\u003cli\u003esex – Biological Sex\u003c/li\u003e\n\u003cli\u003ecapital_gain – Capital gains recorded\u003c/li\u003e\n\u003cli\u003ecapital_loss – Capital Losses recorded\u003c/li\u003e\n\u003cli\u003ehours-per-week – Hours worked per week\u003c/li\u003e\n\u003cli\u003enative-country – Country of origin for person\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTarget/Label:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003c\u003d50K, \u003e50K\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:21:32 AM",
      "dateStarted": "Feb 8, 2017 7:30:09 AM",
      "dateFinished": "Feb 8, 2017 7:30:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## II. Load data\n\nI have downloaded adult.data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult) and put it into the `data/` folder of your project.\n\nThe following cells will do the necessary to load the data into a DataFrame.",
      "dateUpdated": "Feb 7, 2017 12:55:38 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486110944465_2111795148",
      "id": "20170203-083544_2073974112",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eII. Load data\u003c/h2\u003e\n\u003cp\u003eI have downloaded adult.data from the \u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/Adult\"\u003eUCI Machine Learning Repository\u003c/a\u003e and put it into the \u003ccode\u003edata/\u003c/code\u003e folder of your project.\u003c/p\u003e\n\u003cp\u003eThe following cells will do the necessary to load the data into a DataFrame.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:35:44 AM",
      "dateStarted": "Feb 7, 2017 12:55:40 PM",
      "dateFinished": "Feb 7, 2017 12:55:40 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Load data (run the cell)",
      "text": "import org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField}\n\nval schema \u003d StructType(Seq(\n    StructField(\"age\", DoubleType),\n    StructField(\"workclass\", StringType),\n    StructField(\"fnlwgt\", DoubleType),\n    StructField(\"education\", StringType),\n    StructField(\"education_num\", DoubleType),\n    StructField(\"marital_status\", StringType),\n    StructField(\"occupation\", StringType),\n    StructField(\"relationship\", StringType),\n    StructField(\"race\", StringType),\n    StructField(\"sex\", StringType),\n    StructField(\"capital_gain\", DoubleType),\n    StructField(\"capital_loss\", DoubleType),\n    StructField(\"hours_per_week\", DoubleType),\n    StructField(\"native_country\", StringType),\n    StructField(\"income\", StringType)\n    ))\n\ncase class Adult(\n    age: Double, \n    workclass: String, \n    fnlwgt: Double, \n    education: String, \n    education_num: Double, \n    marital_status: String, \n    occupation: String, \n    relationship: String, \n    race: String, \n    sex: String, \n    capital_gain: Double, \n    capital_loss: Double, \n    hours_per_week: Double, \n    native_country: String, \n    income: String\n    )\n    \nval dataset \u003d spark.read.schema(schema).csv(\"/opt/dataset/adult.data.csv\").as[Adult]\ndataset.registerTempTable(\"dataset\")  // register it so we can use it inside %sql interpreter",
      "dateUpdated": "Feb 20, 2017 9:26:58 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": false,
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486111413898_843508411",
      "id": "20170203-084333_2125853520",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.sql.types.{StringType, DoubleType, StructType, StructField}\n\nschema: org.apache.spark.sql.types.StructType \u003d StructType(StructField(age,DoubleType,true), StructField(workclass,StringType,true), StructField(fnlwgt,DoubleType,true), StructField(education,StringType,true), StructField(education_num,DoubleType,true), StructField(marital_status,StringType,true), StructField(occupation,StringType,true), StructField(relationship,StringType,true), StructField(race,StringType,true), StructField(sex,StringType,true), StructField(capital_gain,DoubleType,true), StructField(capital_loss,DoubleType,true), StructField(hours_per_week,DoubleType,true), StructField(native_country,StringType,true), StructField(income,StringType,true))\n\ndefined class Adult\n\ndataset: org.apache.spark.sql.Dataset[Adult] \u003d [age: double, workclass: string ... 13 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"
      },
      "dateCreated": "Feb 3, 2017 8:43:33 AM",
      "dateStarted": "Feb 20, 2017 9:26:59 AM",
      "dateFinished": "Feb 20, 2017 9:27:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nThe above cell imports the dataset into our environment.\nFirst it will parse the csv inferring the csv schema using the specified structure and then convert the RDD to a dataset.\nThe dataset API brings the best of both worlds (RDD and dataframe).\nAs seen previously the variable will then be available throughout the notebook",
      "dateUpdated": "Feb 8, 2017 6:49:27 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486577194793_1370305975",
      "id": "20170208-180634_1968090769",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eThe above cell imports the dataset into our environment.\n\u003cbr  /\u003eFirst it will parse the csv inferring the csv schema using the specified structure and then convert the RDD to a dataset.\n\u003cbr  /\u003eThe dataset API brings the best of both worlds (RDD and dataframe).\n\u003cbr  /\u003eAs seen previously the variable will then be available throughout the notebook\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 6:06:34 AM",
      "dateStarted": "Feb 8, 2017 6:20:45 AM",
      "dateFinished": "Feb 8, 2017 6:20:45 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "dataset.printSchema() // This statement shows information (attributes) about the dataframe\ndataset // This statement prints info about the variable + its value",
      "dateUpdated": "Feb 8, 2017 6:49:32 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486388735078_22636095",
      "id": "20170206-134535_81642944",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- age: double (nullable \u003d true)\n |-- workclass: string (nullable \u003d true)\n |-- fnlwgt: double (nullable \u003d true)\n |-- education: string (nullable \u003d true)\n |-- education_num: double (nullable \u003d true)\n |-- marital_status: string (nullable \u003d true)\n |-- occupation: string (nullable \u003d true)\n |-- relationship: string (nullable \u003d true)\n |-- race: string (nullable \u003d true)\n |-- sex: string (nullable \u003d true)\n |-- capital_gain: double (nullable \u003d true)\n |-- capital_loss: double (nullable \u003d true)\n |-- hours_per_week: double (nullable \u003d true)\n |-- native_country: string (nullable \u003d true)\n |-- income: string (nullable \u003d true)\n\n\nres20: org.apache.spark.sql.Dataset[Adult] \u003d [age: double, workclass: string ... 13 more fields]\n"
      },
      "dateCreated": "Feb 6, 2017 1:45:35 AM",
      "dateStarted": "Feb 8, 2017 6:21:51 AM",
      "dateFinished": "Feb 8, 2017 6:21:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nAs we can see the dataset is indeed a dataset and we can see the structure of it using printSchema",
      "dateUpdated": "Feb 8, 2017 6:49:34 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486578125271_-1078506927",
      "id": "20170208-182205_827478738",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eAs we can see the dataset is indeed a dataset and we can see the structure of it using printSchema\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 6:22:05 AM",
      "dateStarted": "Feb 8, 2017 6:22:58 AM",
      "dateFinished": "Feb 8, 2017 6:22:58 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql \nSELECT * FROM dataset LIMIT 10",
      "dateUpdated": "Feb 8, 2017 6:26:42 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486111269173_-275508312",
      "id": "20170203-084109_2027837333",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "age\tworkclass\tfnlwgt\teducation\teducation_num\tmarital_status\toccupation\trelationship\trace\tsex\tcapital_gain\tcapital_loss\thours_per_week\tnative_country\tincome\n39.0\t State-gov\t77516.0\t Bachelors\t13.0\t Never-married\t Adm-clerical\t Not-in-family\t White\t Male\t2174.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n50.0\t Self-emp-not-inc\t83311.0\t Bachelors\t13.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t0.0\t0.0\t13.0\t United-States\t \u003c\u003d50K\n38.0\t Private\t215646.0\t HS-grad\t9.0\t Divorced\t Handlers-cleaners\t Not-in-family\t White\t Male\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n53.0\t Private\t234721.0\t 11th\t7.0\t Married-civ-spouse\t Handlers-cleaners\t Husband\t Black\t Male\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n28.0\t Private\t338409.0\t Bachelors\t13.0\t Married-civ-spouse\t Prof-specialty\t Wife\t Black\t Female\t0.0\t0.0\t40.0\t Cuba\t \u003c\u003d50K\n37.0\t Private\t284582.0\t Masters\t14.0\t Married-civ-spouse\t Exec-managerial\t Wife\t White\t Female\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n49.0\t Private\t160187.0\t 9th\t5.0\t Married-spouse-absent\t Other-service\t Not-in-family\t Black\t Female\t0.0\t0.0\t16.0\t Jamaica\t \u003c\u003d50K\n52.0\t Self-emp-not-inc\t209642.0\t HS-grad\t9.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t0.0\t0.0\t45.0\t United-States\t \u003e50K\n31.0\t Private\t45781.0\t Masters\t14.0\t Never-married\t Prof-specialty\t Not-in-family\t White\t Female\t14084.0\t0.0\t50.0\t United-States\t \u003e50K\n42.0\t Private\t159449.0\t Bachelors\t13.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t5178.0\t0.0\t40.0\t United-States\t \u003e50K\n"
      },
      "dateCreated": "Feb 3, 2017 8:41:09 AM",
      "dateStarted": "Feb 8, 2017 6:26:42 AM",
      "dateFinished": "Feb 8, 2017 6:26:42 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nThe above cell shows the first ten rows from the dataset. It proves that the dataset was successfully populated using the csv.\nI like to make sure that all the data was imported therefore let’s add another simple request to count the results.",
      "dateUpdated": "Feb 8, 2017 6:49:38 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486578234541_84943098",
      "id": "20170208-182354_286011222",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eThe above cell shows the first ten rows from the dataset. It proves that the dataset was successfully populated using the csv.\n\u003cbr  /\u003eI like to make sure that all the data was imported therefore let’s add another simple request to count the results.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 6:23:54 AM",
      "dateStarted": "Feb 8, 2017 6:27:48 AM",
      "dateFinished": "Feb 8, 2017 6:27:48 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql SELECT count(*) FROM dataset",
      "dateUpdated": "Feb 8, 2017 6:49:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": true,
          "keys": [
            {
              "name": "count(1)",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "count(1)",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486578475395_-1047420532",
      "id": "20170208-182755_1604584431",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "count(1)\n32561\n"
      },
      "dateCreated": "Feb 8, 2017 6:27:55 AM",
      "dateStarted": "Feb 8, 2017 6:28:11 AM",
      "dateFinished": "Feb 8, 2017 6:28:13 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nHere we’re expecting 48842 lines and the output of the previous cell is 32 561.\nLet’s check the original file…\nAccording to the VagrantFile the synced folder on the VM should be located at /opt/dataset",
      "dateUpdated": "Feb 8, 2017 6:49:47 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486578566621_1553386799",
      "id": "20170208-182926_1777531620",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eHere we’re expecting 48842 lines and the output of the previous cell is 32 561.\n\u003cbr  /\u003eLet’s check the original file…\n\u003cbr  /\u003eAccording to the VagrantFile the synced folder on the VM should be located at /opt/dataset\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 6:29:26 AM",
      "dateStarted": "Feb 8, 2017 6:33:14 AM",
      "dateFinished": "Feb 8, 2017 6:33:14 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nls /opt/dataset # lists the directory structure\nwc -l /opt/dataset/adult.data.csv # count lines of a file",
      "dateUpdated": "Feb 8, 2017 6:49:49 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/sh",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486578665777_1315766865",
      "id": "20170208-183105_1602327075",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "adult.data.csv\ndon-quijote.txt.gz\nhttp_access_200304.log.gz\nhttp_access_200305.log.gz\nhttp_access_200306.log.gz\nhttp_access_200307.log.gz\nhttp_access_200308.log.gz\nhttp_access_200309.log.gz\nhttp_access_200310.log.gz\nhttp_access_200311.log.gz\nipligence-lite.csv\nREADME.md\n32562 /opt/dataset/adult.data.csv\n"
      },
      "dateCreated": "Feb 8, 2017 6:31:05 AM",
      "dateStarted": "Feb 8, 2017 6:34:09 AM",
      "dateFinished": "Feb 8, 2017 6:34:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nNow that everything looks normal we can now continue.",
      "dateUpdated": "Feb 8, 2017 6:49:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486578863953_-871947380",
      "id": "20170208-183423_1396750355",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eNow that everything looks normal we can now continue.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 6:34:23 AM",
      "dateStarted": "Feb 8, 2017 6:36:51 AM",
      "dateFinished": "Feb 8, 2017 6:36:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Check settings of graph. See how we average age by income.",
      "text": "%sql SELECT * FROM dataset LIMIT 10",
      "dateUpdated": "Feb 8, 2017 7:30:29 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": true,
          "keys": [
            {
              "name": "income",
              "index": 14.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "age",
              "index": 0.0,
              "aggr": "avg"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "age",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486412404414_-1397675343",
      "id": "20170206-202004_49344056",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "age\tworkclass\tfnlwgt\teducation\teducation_num\tmarital_status\toccupation\trelationship\trace\tsex\tcapital_gain\tcapital_loss\thours_per_week\tnative_country\tincome\n39.0\t State-gov\t77516.0\t Bachelors\t13.0\t Never-married\t Adm-clerical\t Not-in-family\t White\t Male\t2174.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n50.0\t Self-emp-not-inc\t83311.0\t Bachelors\t13.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t0.0\t0.0\t13.0\t United-States\t \u003c\u003d50K\n38.0\t Private\t215646.0\t HS-grad\t9.0\t Divorced\t Handlers-cleaners\t Not-in-family\t White\t Male\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n53.0\t Private\t234721.0\t 11th\t7.0\t Married-civ-spouse\t Handlers-cleaners\t Husband\t Black\t Male\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n28.0\t Private\t338409.0\t Bachelors\t13.0\t Married-civ-spouse\t Prof-specialty\t Wife\t Black\t Female\t0.0\t0.0\t40.0\t Cuba\t \u003c\u003d50K\n37.0\t Private\t284582.0\t Masters\t14.0\t Married-civ-spouse\t Exec-managerial\t Wife\t White\t Female\t0.0\t0.0\t40.0\t United-States\t \u003c\u003d50K\n49.0\t Private\t160187.0\t 9th\t5.0\t Married-spouse-absent\t Other-service\t Not-in-family\t Black\t Female\t0.0\t0.0\t16.0\t Jamaica\t \u003c\u003d50K\n52.0\t Self-emp-not-inc\t209642.0\t HS-grad\t9.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t0.0\t0.0\t45.0\t United-States\t \u003e50K\n31.0\t Private\t45781.0\t Masters\t14.0\t Never-married\t Prof-specialty\t Not-in-family\t White\t Female\t14084.0\t0.0\t50.0\t United-States\t \u003e50K\n42.0\t Private\t159449.0\t Bachelors\t13.0\t Married-civ-spouse\t Exec-managerial\t Husband\t White\t Male\t5178.0\t0.0\t40.0\t United-States\t \u003e50K\n"
      },
      "dateCreated": "Feb 6, 2017 8:20:04 AM",
      "dateStarted": "Feb 7, 2017 12:55:48 PM",
      "dateFinished": "Feb 7, 2017 12:55:53 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nBy clicking any but the first item in the menu and then «**settings**» we can assign the different fields to boxes (Keys, Groups, Values).\nBy clicking the «**age**» field we can affect the aggregate function used by the interpreter.\nHere we want the average, hence the selected AVG option.\nSo we define the aggregate functions by assigning the fields to the «**Values**» box and we group elements using the «**Keys**» box.",
      "dateUpdated": "Feb 8, 2017 7:05:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486579172611_-2065193281",
      "id": "20170208-183932_1166456304",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eBy clicking any but the first item in the menu and then «\u003cstrong\u003esettings\u003c/strong\u003e» we can assign the different fields to boxes (Keys, Groups, Values).\n\u003cbr  /\u003eBy clicking the «\u003cstrong\u003eage\u003c/strong\u003e» field we can affect the aggregate function used by the interpreter.\n\u003cbr  /\u003eHere we want the average, hence the selected AVG option.\n\u003cbr  /\u003eSo we define the aggregate functions by assigning the fields to the «\u003cstrong\u003eValues\u003c/strong\u003e» box and we group elements using the «\u003cstrong\u003eKeys\u003c/strong\u003e» box.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 6:39:32 AM",
      "dateStarted": "Feb 8, 2017 7:04:54 AM",
      "dateFinished": "Feb 8, 2017 7:04:54 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## III. Descriptive analysis\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nProvide a summary statistics graph for some columns you deem interesting. Summary statistics is comprised (but not limited) of:\n* mean, standard deviation and skewness for numeric columns.\n* counts and percentage of each value for categorical columns.\n\nIf you can, try to separate the two income groups and compare.\n\nTwo ways of doing this:\n* You should be able to it using standard SQL queries on the DataFrame and `show()` the result\n* You can use the %sql interpreter like in the previous cell and then use the settings tab of your graph to display the desired results.",
      "dateUpdated": "Feb 8, 2017 9:00:52 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112392026_-185455167",
      "id": "20170203-085952_1247149665",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eIII. Descriptive analysis\u003c/h2\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eProvide a summary statistics graph for some columns you deem interesting. Summary statistics is comprised (but not limited) of:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emean, standard deviation and skewness for numeric columns.\u003c/li\u003e\n\u003cli\u003ecounts and percentage of each value for categorical columns.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIf you can, try to separate the two income groups and compare.\u003c/p\u003e\n\u003cp\u003eTwo ways of doing this:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou should be able to it using standard SQL queries on the DataFrame and \u003ccode\u003eshow()\u003c/code\u003e the result\u003c/li\u003e\n\u003cli\u003eYou can use the %sql interpreter like in the previous cell and then use the settings tab of your graph to display the desired results.\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 8:59:52 AM",
      "dateStarted": "Feb 8, 2017 9:00:52 AM",
      "dateFinished": "Feb 8, 2017 9:00:52 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nTips\n----\nThere are many useful functions provided by Hive that we can use (stddev_pop for the population standard deviation for instance)",
      "dateUpdated": "Feb 20, 2017 9:29:00 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486587599756_-1169870629",
      "id": "20170208-205959_1460024013",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eTips\u003c/h2\u003e\n\u003cp\u003eThere are many useful functions provided by Hive that we can use (stddev_pop for the population standard deviation for instance)\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 8:59:59 AM",
      "dateStarted": "Feb 20, 2017 9:29:00 AM",
      "dateFinished": "Feb 20, 2017 9:29:00 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nTop ten countries by capital_gain",
      "dateUpdated": "Feb 8, 2017 7:27:40 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486581848202_-369405140",
      "id": "20170208-192408_655610682",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eTop ten countries by capital_gain\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 7:24:08 AM",
      "dateStarted": "Feb 8, 2017 7:27:22 AM",
      "dateFinished": "Feb 8, 2017 7:27:22 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nBig differences for capital gains but small differences for capital losses",
      "dateUpdated": "Feb 8, 2017 7:37:30 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486582087335_1536790340",
      "id": "20170208-192807_277870299",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eBig differences for capital gains but small differences for capital losses\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 8, 2017 7:28:07 AM",
      "dateStarted": "Feb 8, 2017 7:37:30 AM",
      "dateFinished": "Feb 8, 2017 7:37:30 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT DISTINCT native_country, MAX(capital_gain) AS max FROM dataset GROUP BY native_country ORDER BY max DESC LIMIT 10",
      "dateUpdated": "Feb 20, 2017 9:46:06 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "pieChart",
          "height": 238.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "native_country",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "max",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "native_country",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "max",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486580854748_-727017993",
      "id": "20170208-190734_1390041233",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "native_country\tmax\n ?\t99999.0\n India\t99999.0\n Canada\t99999.0\n South\t99999.0\n Philippines\t99999.0\n Japan\t99999.0\n Taiwan\t99999.0\n United-States\t99999.0\n Dominican-Republic\t99999.0\n Mexico\t99999.0\n"
      },
      "dateCreated": "Feb 8, 2017 7:07:34 AM",
      "dateStarted": "Feb 8, 2017 7:26:11 AM",
      "dateFinished": "Feb 8, 2017 7:26:12 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT stddev_pop(capital_gain), stddev_pop(capital_loss) FROM dataset",
      "dateUpdated": "Feb 20, 2017 10:02:51 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [
            {
              "name": "stddev_pop(capital_loss)",
              "index": 1.0,
              "aggr": "sum"
            },
            {
              "name": "stddev_pop(capital_gain)",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "stddev_pop(capital_gain)",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "stddev_pop(capital_loss)",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486582112090_713073593",
      "id": "20170208-192832_814643488",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "stddev_pop(capital_gain)\tstddev_pop(capital_loss)\n7385.178676947641\t402.9540308274888\n"
      },
      "dateCreated": "Feb 8, 2017 7:28:32 AM",
      "dateStarted": "Feb 20, 2017 10:02:42 AM",
      "dateFinished": "Feb 20, 2017 10:02:43 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT sex, COUNT(sex), skewness(capital_gain), skewness(hours_per_week), corr(capital_gain, hours_per_week) FROM dataset GROUP BY sex",
      "dateUpdated": "Feb 20, 2017 10:08:01 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": true,
          "keys": [
            {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            },
            {
              "name": "count(sex)",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "skewness(hours_per_week)",
              "index": 3.0,
              "aggr": "sum"
            },
            {
              "name": "corr(capital_gain, hours_per_week)",
              "index": 4.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "yAxis": {
              "name": "count(sex)",
              "index": 1.0,
              "aggr": "sum"
            },
            "xAxis": {
              "name": "sex",
              "index": 0.0,
              "aggr": "sum"
            }
          },
          "forceY": false,
          "lineWithFocus": false
        },
        "enabled": true,
        "editorMode": "ace/mode/sql",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486587574749_-126077511",
      "id": "20170208-205934_464763353",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "sex\tcount(sex)\tskewness(capital_gain)\tskewness(hours_per_week)\tcorr(capital_gain, hours_per_week)\n Male\t21790\t10.63460070662389\t0.3714151037819286\t0.08272504292346826\n Female\t10771\t17.323854468939622\t-0.04984328289126136\t0.028580199456725647\n"
      },
      "dateCreated": "Feb 8, 2017 8:59:34 AM",
      "dateStarted": "Feb 20, 2017 10:07:31 AM",
      "dateFinished": "Feb 20, 2017 10:07:32 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT DISTINCT education, workclass, income,  SUM(capital_gain) as CG FROM dataset GROUP BY education, workclass, income ORDER BY CG DESC LIMIT 5",
      "dateUpdated": "Feb 20, 2017 10:06:32 AM",
      "config": {
        "colWidth": 6.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": true,
          "keys": [
            {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            },
            {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            },
            {
              "name": "income",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "CG",
              "index": 3.0,
              "aggr": "sum"
            }
          ],
          "groups": [
            {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            },
            {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            },
            {
              "name": "income",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "scatter": {
            "xAxis": {
              "name": "education",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "workclass",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487584288837_-128778229",
      "id": "20170220-095128_596907079",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "education\tworkclass\tincome\tCG\n Bachelors\t Private\t \u003e50K\t5677061.0\n HS-grad\t Private\t \u003e50K\t2557481.0\n Masters\t Private\t \u003e50K\t2498267.0\n Prof-school\t Private\t \u003e50K\t2447245.0\n Some-college\t Private\t \u003e50K\t2117661.0\n"
      },
      "dateCreated": "Feb 20, 2017 9:51:28 AM",
      "dateStarted": "Feb 20, 2017 10:03:08 AM",
      "dateFinished": "Feb 20, 2017 10:03:09 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sql\nSELECT DISTINCT COUNT(native_country), income FROM dataset GROUP BY income",
      "dateUpdated": "Feb 20, 2017 10:06:28 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": true,
          "keys": [
            {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(native_country)",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "yAxis": {
              "name": "income",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true,
        "editorMode": "ace/mode/sql"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487585046733_-1293343631",
      "id": "20170220-100406_227986441",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "count(native_country)\tincome\n7841\t \u003e50K\n24720\t \u003c\u003d50K\n"
      },
      "dateCreated": "Feb 20, 2017 10:04:06 AM",
      "dateStarted": "Feb 20, 2017 10:05:20 AM",
      "dateFinished": "Feb 20, 2017 10:05:21 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## IV. Data preprocessing\n\nSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\n\n- Category Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, ...numCategories-1}. This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\n- [One-Hot Encoding](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder). This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))",
      "dateUpdated": "Feb 7, 2017 12:55:41 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112592655_-113447470",
      "id": "20170203-090312_1355361868",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eIV. Data preprocessing\u003c/h2\u003e\n\u003cp\u003eSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCategory Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, \u0026hellip;numCategories-1}. This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#onehotencoder\"\u003eOne-Hot Encoding\u003c/a\u003e. This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))\u003c/li\u003e\n\u003c/ul\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:03:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:42 PM",
      "dateFinished": "Feb 7, 2017 12:55:42 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "One-hot encoding example",
      "text": "val names \u003d Seq(\"color\", \"index\", \"OHE_attr1\", \"OHE_attr2\", \"OHE_attr3\")\nsqlContext.createDataFrame(sc.parallelize(Seq((\"Blue\", 0, 1, 0, 0), (\"Green\", 1, 0, 1, 0), (\"Red\", 2, 0 , 0 , 1)))).toDF(names: _*).show()",
      "dateUpdated": "Feb 7, 2017 12:55:42 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486112775316_925418888",
      "id": "20170203-090615_788237777",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nnames: Seq[String] \u003d List(color, index, OHE_attr1, OHE_attr2, OHE_attr3)\n+-----+-----+---------+---------+---------+\n|color|index|OHE_attr1|OHE_attr2|OHE_attr3|\n+-----+-----+---------+---------+---------+\n| Blue|    0|        1|        0|        0|\n|Green|    1|        0|        1|        0|\n|  Red|    2|        0|        0|        1|\n+-----+-----+---------+---------+---------+\n\n"
      },
      "dateCreated": "Feb 3, 2017 9:06:15 AM",
      "dateStarted": "Feb 7, 2017 12:55:53 PM",
      "dateFinished": "Feb 7, 2017 12:55:55 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nIn this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity\u0027s sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\n\nHere, we will use a combination of [StringIndexer](http://spark.apache.org/docs/latest/ml-features.html#stringindexer) and [OneHotEncoder](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder) on each string column to convert the categorical variables. The `OneHotEncoder` will return a SparseVector (which means, for `(8,[4],[1.0])` that the vector has size 8, one only the 4th column contains a value which is 1.0).\n\nSince we will have many stages of feature transformations, we use an [ML Pipeline](http://spark.apache.org/docs/latest/ml-pipeline.html) to tie the stages together.  This simplifies our code. You should especially try to use [the Pipeline example](http://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline).\n\n```scala\n// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// stages for column workclass\nval stringIndexer \u003d new StringIndexer()\n  .setInputCol(\"workclass\")\n  .setOutputCol(\"workclassIndex\")\nval oneHotEncoder \u003d new OneHotEncoder()\n  .setInputCol(stringIndexer.getOutputCol)\n  .setOutputCol(stringIndexer.getInputCol + \"ClassVec\")\n  \n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n  \nval stages \u003d  Seq(stringIndexer, oneHotEncoder) ++ Seq(label_stringIdx) // concatenate 2 sequences of stages\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n  \nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n```\n\nIt is also a good time to transform the income to a label of 0 and 1 for binary classification using the `StringIndexer`.\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\n1. For each categorical column, build a stage of StringIndexer and OneHotEncoder\n2. Add all those stages in a single pipeline\n3. Also add a StringIndexer of the `income` column and name the output column `label`\n3. Check the result by passing your dataset inside the pipeline. Comment \u0026 explain.\n\n_Hint: actually map your sequence of categorical columns to a sequence of stages through FP._",
      "dateUpdated": "Feb 8, 2017 7:41:22 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486113072470_-2067898551",
      "id": "20170203-091112_917554483",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eIn this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity\u0027s sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\u003c/p\u003e\n\u003cp\u003eHere, we will use a combination of \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#stringindexer\"\u003eStringIndexer\u003c/a\u003e and \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#onehotencoder\"\u003eOneHotEncoder\u003c/a\u003e on each string column to convert the categorical variables. The \u003ccode\u003eOneHotEncoder\u003c/code\u003e will return a SparseVector (which means, for \u003ccode\u003e(8,[4],[1.0])\u003c/code\u003e that the vector has size 8, one only the 4th column contains a value which is 1.0).\u003c/p\u003e\n\u003cp\u003eSince we will have many stages of feature transformations, we use an \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-pipeline.html\"\u003eML Pipeline\u003c/a\u003e to tie the stages together.  This simplifies our code. You should especially try to use \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-pipeline.html#example-pipeline\"\u003ethe Pipeline example\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003e// Configure an ML pipeline, which consists of two stages on one column: a StringIndexer and a OneHotEncoder.\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\n// stages for column workclass\nval stringIndexer \u003d new StringIndexer()\n  .setInputCol(\"workclass\")\n  .setOutputCol(\"workclassIndex\")\nval oneHotEncoder \u003d new OneHotEncoder()\n  .setInputCol(stringIndexer.getOutputCol)\n  .setOutputCol(stringIndexer.getInputCol + \"ClassVec\")\n\n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n\nval stages \u003d  Seq(stringIndexer, oneHotEncoder) ++ Seq(label_stringIdx) // concatenate 2 sequences of stages\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n\nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIt is also a good time to transform the income to a label of 0 and 1 for binary classification using the \u003ccode\u003eStringIndexer\u003c/code\u003e.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eFor each categorical column, build a stage of StringIndexer and OneHotEncoder\u003c/li\u003e\n\u003cli\u003eAdd all those stages in a single pipeline\u003c/li\u003e\n\u003cli\u003eAlso add a StringIndexer of the \u003ccode\u003eincome\u003c/code\u003e column and name the output column \u003ccode\u003elabel\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eCheck the result by passing your dataset inside the pipeline. Comment \u0026amp; explain.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cem\u003eHint: actually map your sequence of categorical columns to a sequence of stages through FP.\u003c/em\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:11:12 AM",
      "dateStarted": "Feb 8, 2017 7:40:20 AM",
      "dateFinished": "Feb 8, 2017 7:40:20 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Detail columns to deal with",
      "text": "\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\nval categoricalCols \u003d Seq(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\")\nval numericCols \u003d Seq(\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\")\n\n// stage for columns\nval string_indexers \u003d categoricalCols.map(item \u003d\u003e new StringIndexer().setInputCol(item).setOutputCol(item + \"Index\"))\nval ohencoders \u003d string_indexers.map(string_indexer \u003d\u003e new OneHotEncoder().setInputCol(string_indexer.getOutputCol).setOutputCol(string_indexer.getInputCol + \"ClassVec\"))\n\n// Zip values together\nval siohstages \u003d string_indexers zip ohencoders\n\n// Recreate sequences and flatten the result\nval flattened_siohstages \u003d siohstages.map{case (item1, item2) \u003d\u003e Seq(item1, item2)}.flatten\n\n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n\nval stages \u003d flattened_siohstages ++ Seq(label_stringIdx)\n\nval pipeline \u003d new Pipeline()\n  .setStages(stages.toArray)\n\nval pipelineModel \u003d pipeline.fit(dataset)\npipelineModel.transform(dataset).show()\n",
      "dateUpdated": "Feb 20, 2017 10:09:44 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486391484536_-1333067431",
      "id": "20170206-143124_969747353",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\n\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\ncategoricalCols: Seq[String] \u003d List(workclass, education, marital_status, occupation, relationship, race, sex, native_country)\n\nnumericCols: Seq[String] \u003d List(age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week)\n\nstring_indexers: Seq[org.apache.spark.ml.feature.StringIndexer] \u003d List(strIdx_d7868386d1ce, strIdx_19030d67eee5, strIdx_6ec0afe068e4, strIdx_9eb0aad4b5ad, strIdx_4a85397f0dc4, strIdx_b01049ad525b, strIdx_3ccd91b80667, strIdx_9dff44884118)\n\nohencoders: Seq[org.apache.spark.ml.feature.OneHotEncoder] \u003d List(oneHot_28c8bb7424cb, oneHot_70b0aeb0a4b2, oneHot_37df14e01a85, oneHot_93aeb364a91d, oneHot_fcce8b1699d4, oneHot_0d4e76b13eed, oneHot_38ed0e03e10d, oneHot_2ed70936bf1d)\n\nsiohstages: Seq[(org.apache.spark.ml.feature.StringIndexer, org.apache.spark.ml.feature.OneHotEncoder)] \u003d List((strIdx_d7868386d1ce,oneHot_28c8bb7424cb), (strIdx_19030d67eee5,oneHot_70b0aeb0a4b2), (strIdx_6ec0afe068e4,oneHot_37df14e01a85), (strIdx_9eb0aad4b5ad,oneHot_93aeb364a91d), (strIdx_4a85397f0dc4,oneHot_fcce8b1699d4), (strIdx_b01049ad525b,oneHot_0d4e76b13eed), (strIdx_3ccd91b80667,oneHot_38ed0e03e10d), (strIdx_9dff44884118,oneHot_2ed70936bf1d))\nflattened_siohstages: Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable}}] \u003d List(strIdx_d7868386d1ce, oneHot_28c8bb7424cb, strIdx_19030d67eee5, oneHot_70b0aeb0a4b2, strIdx_6ec...\nlabel_stringIdx: org.apache.spark.ml.feature.StringIndexer \u003d strIdx_3e01b3756176\nstages: Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable}}] \u003d List(strIdx_d7868386d1ce, oneHot_28c8bb7424cb, strIdx_19030d67eee5, oneHot_70b0aeb0a4b2, strIdx_6ec0afe068e4, one...\npipeline: org.apache.spark.ml.Pipeline \u003d pipeline_590ed0561b05\n\npipelineModel: org.apache.spark.ml.PipelineModel \u003d pipeline_590ed0561b05\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+\n| age|        workclass|  fnlwgt|    education|education_num|      marital_status|        occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+\n|39.0|        State-gov| 77516.0|    Bachelors|         13.0|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|50.0| Self-emp-not-inc| 83311.0|    Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          13.0| United-States| \u003c\u003d50K|           1.0|    (8,[1],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|38.0|          Private|215646.0|      HS-grad|          9.0|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           0.0|   (15,[0],[1.0])|                2.0|         (6,[2],[1.0])|            9.0|    (14,[9],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|53.0|          Private|234721.0|         11th|          7.0|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           5.0|   (15,[5],[1.0])|                0.0|         (6,[0],[1.0])|            9.0|    (14,[9],[1.0])|              0.0|       (5,[0],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|28.0|          Private|338409.0|    Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|         0.0|         0.0|          40.0|          Cuba| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            0.0|    (14,[0],[1.0])|              4.0|       (5,[4],[1.0])|      1.0|(4,[1],[1.0])|     1.0|    (1,[],[])|                9.0|        (41,[9],[1.0])|  0.0|\n|37.0|          Private|284582.0|      Masters|         14.0|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           3.0|   (15,[3],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              4.0|       (5,[4],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  0.0|\n|49.0|          Private|160187.0|          9th|          5.0| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|         0.0|         0.0|          16.0|       Jamaica| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|          10.0|  (15,[10],[1.0])|                5.0|         (6,[5],[1.0])|            5.0|    (14,[5],[1.0])|              1.0|       (5,[1],[1.0])|      1.0|(4,[1],[1.0])|     1.0|    (1,[],[])|               11.0|       (41,[11],[1.0])|  0.0|\n|52.0| Self-emp-not-inc|209642.0|      HS-grad|          9.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  \u003e50K|           1.0|    (8,[1],[1.0])|           0.0|   (15,[0],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|\n|31.0|          Private| 45781.0|      Masters|         14.0|       Never-married|    Prof-specialty| Not-in-family|              White| Female|     14084.0|         0.0|          50.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           3.0|   (15,[3],[1.0])|                1.0|         (6,[1],[1.0])|            0.0|    (14,[0],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  1.0|\n|42.0|          Private|159449.0|    Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|      5178.0|         0.0|          40.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|\n|37.0|          Private|280464.0| Some-college|         10.0|  Married-civ-spouse|   Exec-managerial|       Husband|              Black|   Male|         0.0|         0.0|          80.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           1.0|   (15,[1],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|\n|30.0|        State-gov|141297.0|    Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|         India|  \u003e50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            0.0|    (14,[0],[1.0])|              0.0|       (5,[0],[1.0])|      2.0|(4,[2],[1.0])|     0.0|(1,[0],[1.0])|                8.0|        (41,[8],[1.0])|  1.0|\n|23.0|          Private|122272.0|    Bachelors|         13.0|       Never-married|      Adm-clerical|     Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              2.0|       (5,[2],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  0.0|\n|32.0|          Private|205019.0|   Assoc-acdm|         12.0|       Never-married|             Sales| Not-in-family|              Black|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           6.0|   (15,[6],[1.0])|                1.0|         (6,[1],[1.0])|            4.0|    (14,[4],[1.0])|              1.0|       (5,[1],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|40.0|          Private|121772.0|    Assoc-voc|         11.0|  Married-civ-spouse|      Craft-repair|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|             ?|  \u003e50K|           0.0|    (8,[0],[1.0])|           4.0|   (15,[4],[1.0])|                0.0|         (6,[0],[1.0])|            1.0|    (14,[1],[1.0])|              0.0|       (5,[0],[1.0])|      2.0|(4,[2],[1.0])|     0.0|(1,[0],[1.0])|                2.0|        (41,[2],[1.0])|  1.0|\n|34.0|          Private|245487.0|      7th-8th|          4.0|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|         0.0|         0.0|          45.0|        Mexico| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           8.0|   (15,[8],[1.0])|                0.0|         (6,[0],[1.0])|            8.0|    (14,[8],[1.0])|              0.0|       (5,[0],[1.0])|      3.0|(4,[3],[1.0])|     0.0|(1,[0],[1.0])|                1.0|        (41,[1],[1.0])|  0.0|\n|25.0| Self-emp-not-inc|176756.0|      HS-grad|          9.0|       Never-married|   Farming-fishing|     Own-child|              White|   Male|         0.0|         0.0|          35.0| United-States| \u003c\u003d50K|           1.0|    (8,[1],[1.0])|           0.0|   (15,[0],[1.0])|                1.0|         (6,[1],[1.0])|           10.0|   (14,[10],[1.0])|              2.0|       (5,[2],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|32.0|          Private|186824.0|      HS-grad|          9.0|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           0.0|   (15,[0],[1.0])|                1.0|         (6,[1],[1.0])|            6.0|    (14,[6],[1.0])|              3.0|       (5,[3],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|38.0|          Private| 28887.0|         11th|          7.0|  Married-civ-spouse|             Sales|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           5.0|   (15,[5],[1.0])|                0.0|         (6,[0],[1.0])|            4.0|    (14,[4],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|\n|43.0| Self-emp-not-inc|292175.0|      Masters|         14.0|            Divorced|   Exec-managerial|     Unmarried|              White| Female|         0.0|         0.0|          45.0| United-States|  \u003e50K|           1.0|    (8,[1],[1.0])|           3.0|   (15,[3],[1.0])|                2.0|         (6,[2],[1.0])|            2.0|    (14,[2],[1.0])|              3.0|       (5,[3],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  1.0|\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 6, 2017 2:31:24 AM",
      "dateStarted": "Feb 20, 2017 10:09:44 AM",
      "dateFinished": "Feb 20, 2017 10:09:53 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nTo run machine learning on a dataset, you need a column which contains a vector of all the features, and a column with the label.\n\nWe use the [VectorAssembler](http://spark.apache.org/docs/latest/ml-features.html#vectorassembler) to assemble all of our numeric columns and one-hot encoded categorical columns into one.\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nAdd the `VectorAssembler` stage, which takes as input all numeric columns and one hot encoded categorical columns. The `features` column will then be created. You can comment on it.",
      "dateUpdated": "Feb 7, 2017 12:55:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486113356892_-128377178",
      "id": "20170203-091556_1786454475",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eTo run machine learning on a dataset, you need a column which contains a vector of all the features, and a column with the label.\u003c/p\u003e\n\u003cp\u003eWe use the \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-features.html#vectorassembler\"\u003eVectorAssembler\u003c/a\u003e to assemble all of our numeric columns and one-hot encoded categorical columns into one.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eAdd the \u003ccode\u003eVectorAssembler\u003c/code\u003e stage, which takes as input all numeric columns and one hot encoded categorical columns. The \u003ccode\u003efeatures\u003c/code\u003e column will then be created. You can comment on it.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:15:56 AM",
      "dateStarted": "Feb 7, 2017 12:55:43 PM",
      "dateFinished": "Feb 7, 2017 12:55:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\nval categoricalCols \u003d Seq(\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\")\nval numericCols \u003d Seq(\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\")\n\n// stage for columns\nval string_indexers \u003d categoricalCols.map(item \u003d\u003e new StringIndexer().setInputCol(item).setOutputCol(item + \"Index\"))\nval ohencoders \u003d string_indexers.map(string_indexer \u003d\u003e new OneHotEncoder().setInputCol(string_indexer.getOutputCol).setOutputCol(string_indexer.getInputCol + \"ClassVec\"))\n\n// Zip values together\nval siohstages \u003d string_indexers zip ohencoders\n\n// Recreate sequences and flatten the result\nval flattened_siohstages \u003d siohstages.map{case (item1, item2) \u003d\u003e Seq(item1, item2)}.flatten\n\n// stage for label\nval label_stringIdx \u003d new StringIndexer()\n    .setInputCol(\"income\")\n    .setOutputCol(\"label\")\n    \n// Concatenate the vectors and cast as array to feed the VectorAssembler which will return the \"features\" column.\nval assemblerStage \u003d new VectorAssembler().setInputCols((numericCols ++ categoricalCols.map(w \u003d\u003e w + \"ClassVec\")).toArray).setOutputCol(\"features\")\n\n// Add the 3 stages together before we send it to the pipeline\nval stages \u003d flattened_siohstages ++ Seq(label_stringIdx) ++ Seq(assemblerStage)\n\nval pipeline \u003d new Pipeline().setStages(stages.toArray)\n\n// Apply the pipeline operations to our dataset\nval pipelineModel \u003d pipeline.fit(dataset)\n\n// Show the results\npipelineModel.transform(dataset).show()\n",
      "dateUpdated": "Feb 20, 2017 10:32:56 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486586872779_1537809361",
      "id": "20170208-204752_1997011123",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, VectorAssembler}\n\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\n\ncategoricalCols: Seq[String] \u003d List(workclass, education, marital_status, occupation, relationship, race, sex, native_country)\n\nnumericCols: Seq[String] \u003d List(age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week)\n\nstring_indexers: Seq[org.apache.spark.ml.feature.StringIndexer] \u003d List(strIdx_82ef1c82a249, strIdx_daa7f9cd8616, strIdx_6cc90d9d4a35, strIdx_94d1cd91a504, strIdx_7ab5b066cfe9, strIdx_dc83e4e2ada1, strIdx_b4ab582d74ec, strIdx_aade12f35274)\n\nohencoders: Seq[org.apache.spark.ml.feature.OneHotEncoder] \u003d List(oneHot_c1332662d89b, oneHot_945f858618e2, oneHot_d8ad2ee8417d, oneHot_fd2e142d0da0, oneHot_688dd72b40cc, oneHot_4646d73da1db, oneHot_c68a2f804e8f, oneHot_4ec4cc4de443)\n\nsiohstages: Seq[(org.apache.spark.ml.feature.StringIndexer, org.apache.spark.ml.feature.OneHotEncoder)] \u003d List((strIdx_82ef1c82a249,oneHot_c1332662d89b), (strIdx_daa7f9cd8616,oneHot_945f858618e2), (strIdx_6cc90d9d4a35,oneHot_d8ad2ee8417d), (strIdx_94d1cd91a504,oneHot_fd2e142d0da0), (strIdx_7ab5b066cfe9,oneHot_688dd72b40cc), (strIdx_dc83e4e2ada1,oneHot_4646d73da1db), (strIdx_b4ab582d74ec,oneHot_c68a2f804e8f), (strIdx_aade12f35274,oneHot_4ec4cc4de443))\nflattened_siohstages: Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.param.shared.HasInputCol with org.apache.spark.ml.util.DefaultParamsWritable}}] \u003d List(strIdx_82ef1c82a249, oneHot_c1332662d89b, strIdx_daa7f9cd8616, oneHot_945f858618e2, strIdx_6cc...\nlabel_stringIdx: org.apache.spark.ml.feature.StringIndexer \u003d strIdx_86c2780d93d5\n\nassemblerStage: org.apache.spark.ml.feature.VectorAssembler \u003d vecAssembler_51b0958b5049\nstages: Seq[org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable{def copy(extra: org.apache.spark.ml.param.ParamMap): org.apache.spark.ml.PipelineStage with org.apache.spark.ml.param.shared.HasOutputCol with org.apache.spark.ml.util.DefaultParamsWritable}}] \u003d List(strIdx_82ef1c82a249, oneHot_c1332662d89b, strIdx_daa7f9cd8616, oneHot_945f858618e2, strIdx_6cc90d9d4a35, oneHot_d8ad2ee8417d, strIdx_94d1cd91a504, oneHot_fd2e142d0da0, strIdx_7ab5b066cfe9, oneHot_688dd72b40cc, strIdx_dc83e4e2ada1, oneHot_4646d73da1db, strIdx...\npipeline: org.apache.spark.ml.Pipeline \u003d pipeline_66b2a0f4104d\n\npipelineModel: org.apache.spark.ml.PipelineModel \u003d pipeline_66b2a0f4104d\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt|    education|education_num|      marital_status|        occupation|  relationship|               race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0|    Bachelors|         13.0|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,3,5,1...|\n|50.0| Self-emp-not-inc| 83311.0|    Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          13.0| United-States| \u003c\u003d50K|           1.0|    (8,[1],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,7,1...|\n|38.0|          Private|215646.0|      HS-grad|          9.0|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           0.0|   (15,[0],[1.0])|                2.0|         (6,[2],[1.0])|            9.0|    (14,[9],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|53.0|          Private|234721.0|         11th|          7.0|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           5.0|   (15,[5],[1.0])|                0.0|         (6,[0],[1.0])|            9.0|    (14,[9],[1.0])|              0.0|       (5,[0],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|28.0|          Private|338409.0|    Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|         0.0|         0.0|          40.0|          Cuba| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            0.0|    (14,[0],[1.0])|              4.0|       (5,[4],[1.0])|      1.0|(4,[1],[1.0])|     1.0|    (1,[],[])|                9.0|        (41,[9],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|37.0|          Private|284582.0|      Masters|         14.0|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           3.0|   (15,[3],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              4.0|       (5,[4],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|49.0|          Private|160187.0|          9th|          5.0| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|         0.0|         0.0|          16.0|       Jamaica| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|          10.0|  (15,[10],[1.0])|                5.0|         (6,[5],[1.0])|            5.0|    (14,[5],[1.0])|              1.0|       (5,[1],[1.0])|      1.0|(4,[1],[1.0])|     1.0|    (1,[],[])|               11.0|       (41,[11],[1.0])|  0.0|(100,[0,1,2,5,6,2...|\n|52.0| Self-emp-not-inc|209642.0|      HS-grad|          9.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|         0.0|         0.0|          45.0| United-States|  \u003e50K|           1.0|    (8,[1],[1.0])|           0.0|   (15,[0],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|(100,[0,1,2,5,7,1...|\n|31.0|          Private| 45781.0|      Masters|         14.0|       Never-married|    Prof-specialty| Not-in-family|              White| Female|     14084.0|         0.0|          50.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           3.0|   (15,[3],[1.0])|                1.0|         (6,[1],[1.0])|            0.0|    (14,[0],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  1.0|(100,[0,1,2,3,5,6...|\n|42.0|          Private|159449.0|    Bachelors|         13.0|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|      5178.0|         0.0|          40.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|(100,[0,1,2,3,5,6...|\n|37.0|          Private|280464.0| Some-college|         10.0|  Married-civ-spouse|   Exec-managerial|       Husband|              Black|   Male|         0.0|         0.0|          80.0| United-States|  \u003e50K|           0.0|    (8,[0],[1.0])|           1.0|   (15,[1],[1.0])|                0.0|         (6,[0],[1.0])|            2.0|    (14,[2],[1.0])|              0.0|       (5,[0],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  1.0|(100,[0,1,2,5,6,1...|\n|30.0|        State-gov|141297.0|    Bachelors|         13.0|  Married-civ-spouse|    Prof-specialty|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|         India|  \u003e50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                0.0|         (6,[0],[1.0])|            0.0|    (14,[0],[1.0])|              0.0|       (5,[0],[1.0])|      2.0|(4,[2],[1.0])|     0.0|(1,[0],[1.0])|                8.0|        (41,[8],[1.0])|  1.0|(100,[0,1,2,5,10,...|\n|23.0|          Private|122272.0|    Bachelors|         13.0|       Never-married|      Adm-clerical|     Own-child|              White| Female|         0.0|         0.0|          30.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              2.0|       (5,[2],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|32.0|          Private|205019.0|   Assoc-acdm|         12.0|       Never-married|             Sales| Not-in-family|              Black|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           6.0|   (15,[6],[1.0])|                1.0|         (6,[1],[1.0])|            4.0|    (14,[4],[1.0])|              1.0|       (5,[1],[1.0])|      1.0|(4,[1],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,2...|\n|40.0|          Private|121772.0|    Assoc-voc|         11.0|  Married-civ-spouse|      Craft-repair|       Husband| Asian-Pac-Islander|   Male|         0.0|         0.0|          40.0|             ?|  \u003e50K|           0.0|    (8,[0],[1.0])|           4.0|   (15,[4],[1.0])|                0.0|         (6,[0],[1.0])|            1.0|    (14,[1],[1.0])|              0.0|       (5,[0],[1.0])|      2.0|(4,[2],[1.0])|     0.0|(1,[0],[1.0])|                2.0|        (41,[2],[1.0])|  1.0|(100,[0,1,2,5,6,1...|\n|34.0|          Private|245487.0|      7th-8th|          4.0|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|         0.0|         0.0|          45.0|        Mexico| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           8.0|   (15,[8],[1.0])|                0.0|         (6,[0],[1.0])|            8.0|    (14,[8],[1.0])|              0.0|       (5,[0],[1.0])|      3.0|(4,[3],[1.0])|     0.0|(1,[0],[1.0])|                1.0|        (41,[1],[1.0])|  0.0|(100,[0,1,2,5,6,2...|\n|25.0| Self-emp-not-inc|176756.0|      HS-grad|          9.0|       Never-married|   Farming-fishing|     Own-child|              White|   Male|         0.0|         0.0|          35.0| United-States| \u003c\u003d50K|           1.0|    (8,[1],[1.0])|           0.0|   (15,[0],[1.0])|                1.0|         (6,[1],[1.0])|           10.0|   (14,[10],[1.0])|              2.0|       (5,[2],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,7,1...|\n|32.0|          Private|186824.0|      HS-grad|          9.0|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|         0.0|         0.0|          40.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           0.0|   (15,[0],[1.0])|                1.0|         (6,[1],[1.0])|            6.0|    (14,[6],[1.0])|              3.0|       (5,[3],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|38.0|          Private| 28887.0|         11th|          7.0|  Married-civ-spouse|             Sales|       Husband|              White|   Male|         0.0|         0.0|          50.0| United-States| \u003c\u003d50K|           0.0|    (8,[0],[1.0])|           5.0|   (15,[5],[1.0])|                0.0|         (6,[0],[1.0])|            4.0|    (14,[4],[1.0])|              0.0|       (5,[0],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[0,1,2,5,6,1...|\n|43.0| Self-emp-not-inc|292175.0|      Masters|         14.0|            Divorced|   Exec-managerial|     Unmarried|              White| Female|         0.0|         0.0|          45.0| United-States|  \u003e50K|           1.0|    (8,[1],[1.0])|           3.0|   (15,[3],[1.0])|                2.0|         (6,[2],[1.0])|            2.0|    (14,[2],[1.0])|              3.0|       (5,[3],[1.0])|      0.0|(4,[0],[1.0])|     1.0|    (1,[],[])|                0.0|        (41,[0],[1.0])|  1.0|(100,[0,1,2,5,7,1...|\n+----+-----------------+--------+-------------+-------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Feb 8, 2017 8:47:52 AM",
      "dateStarted": "Feb 20, 2017 10:32:56 AM",
      "dateFinished": "Feb 20, 2017 10:33:02 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nAt this point, you should have a dataframe with a column _features_ which consists of a vector of all features in numerical form, and a column _label_ with the Income as a binary value. \n\nIt looks like this for example:\n\n```\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| \u003c\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[4,10,24,32,...|\n```\n\n\u003chr\u003e\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\nRandomly split your dataset into a 70% training set and 30% test set using a Dataframe\u0027s `randomSplit` function.",
      "dateUpdated": "Feb 7, 2017 12:55:43 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114019412_590451428",
      "id": "20170203-092659_1906384110",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003eAt this point, you should have a dataframe with a column \u003cem\u003efeatures\u003c/em\u003e which consists of a vector of all features in numerical form, and a column \u003cem\u003elabel\u003c/em\u003e with the Income as a binary value.\u003c/p\u003e\n\u003cp\u003eIt looks like this for example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n| age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|  sex|capital_gain|capital_loss|hours_per_week|native_country|income|workclassIndex|workclassClassVec|educationIndex|educationClassVec|marital_statusIndex|marital_statusClassVec|occupationIndex|occupationClassVec|relationshipIndex|relationshipClassVec|raceIndex| raceClassVec|sexIndex|  sexClassVec|native_countryIndex|native_countryClassVec|label|            features|\n+----+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-----+------------+------------+--------------+--------------+------+--------------+-----------------+--------------+-----------------+-------------------+----------------------+---------------+------------------+-----------------+--------------------+---------+-------------+--------+-------------+-------------------+----------------------+-----+--------------------+\n|39.0|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White| Male|      2174.0|         0.0|          40.0| United-States| \u0026lt;\u003d50K|           4.0|    (8,[4],[1.0])|           2.0|   (15,[2],[1.0])|                1.0|         (6,[1],[1.0])|            3.0|    (14,[3],[1.0])|              1.0|       (5,[1],[1.0])|      0.0|(4,[0],[1.0])|     0.0|(1,[0],[1.0])|                0.0|        (41,[0],[1.0])|  0.0|(100,[4,10,24,32,...|\n\u003c/code\u003e\u003c/pre\u003e\n\u003chr\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003cp\u003eRandomly split your dataset into a 70% training set and 30% test set using a Dataframe\u0027s \u003ccode\u003erandomSplit\u003c/code\u003e function.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:26:59 AM",
      "dateStarted": "Feb 7, 2017 12:55:44 PM",
      "dateFinished": "Feb 7, 2017 12:55:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val transformedDataset \u003d pipelineModel.transform(dataset)\n// Apply weights to split the dataset (70% and 30%)\nval split \u003d transformedDataset.randomSplit(Array(0.7, 0.3))\nval training_data \u003d split(0)\nval test_data \u003d split(1)\nval total_lines \u003d transformedDataset.count()\n// Print results to make sure it worked\ntraining_data.count()\ntest_data.count()",
      "dateUpdated": "Feb 20, 2017 10:55:42 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486586934289_1248321657",
      "id": "20170208-204854_1940935237",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\ntransformedDataset: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 31 more fields]\n\nsplit: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] \u003d Array([age: double, workclass: string ... 31 more fields], [age: double, workclass: string ... 31 more fields])\n\ntraining_data: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [age: double, workclass: string ... 31 more fields]\n\ntest_data: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [age: double, workclass: string ... 31 more fields]\n\ntotal_lines: Long \u003d 32561\n\nres87: Long \u003d 22845\n\nres88: Long \u003d 9716\n"
      },
      "dateCreated": "Feb 8, 2017 8:48:54 AM",
      "dateStarted": "Feb 20, 2017 10:51:06 AM",
      "dateFinished": "Feb 20, 2017 10:51:11 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nBy executing the previous cell multiple times we can observe that the number of lines returned by randomSplit isn’t exactly the same number each time, so we can assume that this is the way the split works.",
      "dateUpdated": "Feb 20, 2017 10:51:31 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487587789743_676769126",
      "id": "20170220-104949_1386025912",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eBy executing the previous cell multiple times we can observe that the number of lines returned by randomSplit isn’t exactly the same number each time, so we can assume that this is the way the split works.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 20, 2017 10:49:49 AM",
      "dateStarted": "Feb 20, 2017 10:51:28 AM",
      "dateFinished": "Feb 20, 2017 10:51:28 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## V. Creation of models\n\nWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\n\nWe have the choice between:\n- [Binomial Logistic regression](http://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression)\n- [Decision trees](http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees)\n- [Random forest](http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests)\n\nThese are the general steps we will take to build our models:\n- Create the initial model on the training set\n- Use your model to make predictions on your testing set\n- Evaluate the quality of your predictions\n\nWe will be using the `BinaryClassificationEvaluator` to evaluate our models. The default metric used here is [areaUnderROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve).\n\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\n1. Fit your data on one of the three Machine Learning models on the training dataset. This should create an Estimator.\n2. Run the estimator on the testing dataset to create a prediction column\n3. Use `BinaryClassificationEvaluator.evaluate()` to evaluate your predictions.",
      "dateUpdated": "Feb 7, 2017 12:55:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114303097_-616679895",
      "id": "20170203-093143_100322687",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eV. Creation of models\u003c/h2\u003e\n\u003cp\u003eWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\u003c/p\u003e\n\u003cp\u003eWe have the choice between:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\"\u003eBinomial Logistic regression\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees\"\u003eDecision trees\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests\"\u003eRandom forest\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese are the general steps we will take to build our models:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCreate the initial model on the training set\u003c/li\u003e\n\u003cli\u003eUse your model to make predictions on your testing set\u003c/li\u003e\n\u003cli\u003eEvaluate the quality of your predictions\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe will be using the \u003ccode\u003eBinaryClassificationEvaluator\u003c/code\u003e to evaluate our models. The default metric used here is \u003ca href\u003d\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\"\u003eareaUnderROC\u003c/a\u003e.\u003c/p\u003e\n\u003ch4 style\u003d\"color:red;\"\u003eExercise\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003eFit your data on one of the three Machine Learning models on the training dataset. This should create an Estimator.\u003c/li\u003e\n\u003cli\u003eRun the estimator on the testing dataset to create a prediction column\u003c/li\u003e\n\u003cli\u003eUse \u003ccode\u003eBinaryClassificationEvaluator.evaluate()\u003c/code\u003e to evaluate your predictions.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:31:43 AM",
      "dateStarted": "Feb 7, 2017 12:55:44 PM",
      "dateFinished": "Feb 7, 2017 12:55:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\nval lr \u003d new LogisticRegression()\n    \n// Apply the model to our training dataset\nval lrModel \u003d lr.fit(training_data)\n\n// Compute predictions on the sample dataset\nval predictions \u003d lrModel.transform(test_data)\n\n// Select only the columns we want\nval selection \u003d predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n\n// Output the result\nselection.show()\n\n// Model evaluation, the default metric used by BinaryClassificationEvaluator is areaUnderROC\n// Area under ROC is represented by a curved line which indicates the performance of a binary classifier\nval evaluator \u003d new BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)\n",
      "dateUpdated": "Feb 20, 2017 2:25:49 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487587985409_-922523138",
      "id": "20170220-105305_1582216504",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.classification.LogisticRegression\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\nlr: org.apache.spark.ml.classification.LogisticRegression \u003d logreg_07a16d69e3a8\n\nlrModel: org.apache.spark.ml.classification.LogisticRegressionModel \u003d logreg_07a16d69e3a8\n\npredictions: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 34 more fields]\n\nselection: org.apache.spark.sql.DataFrame \u003d [label: double, prediction: double ... 3 more fields]\n+-----+----------+--------------------+----+--------------+\n|label|prediction|         probability| age|    occupation|\n+-----+----------+--------------------+----+--------------+\n|  0.0|       0.0|[0.99917835668242...|17.0|             ?|\n|  0.0|       0.0|[0.99964563809281...|17.0|             ?|\n|  0.0|       0.0|[0.99849316415013...|17.0|             ?|\n|  0.0|       0.0|[0.99916509815348...|17.0|             ?|\n|  0.0|       0.0|[0.99803271539527...|17.0|             ?|\n|  0.0|       0.0|[0.99912429028218...|17.0|             ?|\n|  0.0|       0.0|[0.99844251348462...|17.0|             ?|\n|  0.0|       0.0|[0.99762204717949...|17.0|             ?|\n|  0.0|       0.0|[0.99980933602231...|17.0|             ?|\n|  0.0|       0.0|[0.99959367480789...|17.0|             ?|\n|  0.0|       0.0|[0.99907720232214...|17.0|             ?|\n|  0.0|       0.0|[0.99846191855986...|17.0|             ?|\n|  0.0|       0.0|[0.99968548990452...|17.0|             ?|\n|  0.0|       0.0|[0.99876840906164...|17.0|             ?|\n|  0.0|       1.0|[0.02381424598953...|17.0|             ?|\n|  0.0|       0.0|[0.99972344157032...|17.0|             ?|\n|  0.0|       0.0|[0.99817199270933...|17.0|             ?|\n|  0.0|       0.0|[0.98519616682228...|17.0|  Adm-clerical|\n|  0.0|       0.0|[0.99975692924032...|17.0| Other-service|\n|  0.0|       0.0|[0.99958334133609...|17.0|  Adm-clerical|\n+-----+----------+--------------------+----+--------------+\nonly showing top 20 rows\n\n\nevaluator: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator \u003d binEval_0415dc2c08e4\n\nres141: Double \u003d 0.9060079694561354\n"
      },
      "dateCreated": "Feb 20, 2017 10:53:05 AM",
      "dateStarted": "Feb 20, 2017 2:25:49 PM",
      "dateFinished": "Feb 20, 2017 2:26:01 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\nUse [cross-validation](http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation) to select the best hyperparameters for your model",
      "dateUpdated": "Feb 20, 2017 1:20:10 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486412170872_-693891339",
      "id": "20170206-201610_429327674",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\u003cp\u003eUse \u003ca href\u003d\"http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation\"\u003ecross-validation\u003c/a\u003e to select the best hyperparameters for your model\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 6, 2017 8:16:10 AM",
      "dateStarted": "Feb 7, 2017 12:55:45 PM",
      "dateFinished": "Feb 7, 2017 12:55:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nExplanation\n-----------\nCross-validation is a model validation technique which in practice is used to estimate how accurate a predictive model will be\nConventional validation splits the dataset into two sets of 70% for training and 30% for testing purposes. Cross-validation shines when there isn’t enough data. In Spark’s documentation this step is also called \"tuning\" because we’re looking for the best parameters for our model.\nCross-validation will split the dataset into k pairs and will test the data on each of these.\nIt will look for the best elasticNetParam which corresponds to α and regParam which corresponds to λ.",
      "dateUpdated": "Feb 20, 2017 1:54:31 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487596815846_-1273420787",
      "id": "20170220-132015_1994990082",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eExplanation\u003c/h2\u003e\n\u003cp\u003eCross-validation is a model validation technique which in practice is used to estimate how accurate a predictive model will be\n\u003cbr  /\u003eConventional validation splits the dataset into two sets of 70% for training and 30% for testing purposes. Cross-validation shines when there isn’t enough data. In Spark’s documentation this step is also called \u0026ldquo;tuning\u0026rdquo; because we’re looking for the best parameters for our model.\n\u003cbr  /\u003eCross-validation will split the dataset into k pairs and will test the data on each of these.\n\u003cbr  /\u003eIt will look for the best elasticNetParam which corresponds to α and regParam which corresponds to λ.\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 20, 2017 1:20:15 PM",
      "dateStarted": "Feb 20, 2017 1:54:32 PM",
      "dateFinished": "Feb 20, 2017 1:54:32 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\nimport org.apache.spark.ml.classification.LogisticRegressionModel\n\n// This will create the parameters grid. The cross validator will then have 27 parameters settings to choose from.\n// We provide 3 values for each parameter.\nval paramGrid \u003d new ParamGridBuilder()\n    .addGrid(lr.regParam, Array(0.01, 0.5, 2.0))\n    .addGrid(lr.elasticNetParam, Array(0.0, 0.5, 1.0))\n    .addGrid(lr.maxIter, Array(1, 5, 10))\n    .build()\n    \nval cross_validator \u003d new CrossValidator()\n    .setEstimator(lr) // This is the estimator that we will test\n    .setEstimatorParamMaps(paramGrid) // This is our parameters grid from which the cross validator will choose the params to test the estimator with.\n    .setEvaluator(evaluator) // Specifies the evaluator that will be used when testing\n    .setNumFolds(5) // Defines the number of random data pairs the cross validator will create in its process.\n    \n// Cross validation is used just like the estimator\n\n// Run the cross validations on our dataset\nval cross_validator_model \u003d cross_validator.fit(training_data)\nval cross_predictions \u003d cross_validator_model.transform(test_data)\n\nval bestlrmodel \u003d cross_validator_model.bestModel.asInstanceOf[LogisticRegressionModel]\n\n// Weights of our model, which are used to compensate the differences in sample and population\nbestlrmodel.coefficients\n\n// Intercept is the value at which the fitted line crosses the Y-axis\nbestlrmodel.intercept\n\n// Get the best stages\nval best_stages \u003d bestlrmodel.stages\n\n// Now print our prediction just as we did previously\nval cv_selection \u003d cross_predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\ncv_selection.show()\n\nevaluator.evaluate(cross_predictions)",
      "dateUpdated": "Feb 20, 2017 2:37:56 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487597112779_1445056242",
      "id": "20170220-132512_729873691",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "\nimport org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n\nimport org.apache.spark.ml.classification.LogisticRegressionModel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparamGrid: Array[org.apache.spark.ml.param.ParamMap] \u003d\nArray({\n\tlogreg_07a16d69e3a8-elasticNetParam: 0.0,\n\tlogreg_07a16d69e3a8-maxIter: 1,\n\tlogreg_07a16d69e3a8-regParam: 0.01\n}, {\n\tlogreg_07a16d69e3a8-elasticNetParam: 0.0,\n\tlogreg_07a16d69e3a8-maxIter: 1,\n\tlogreg_07a16d69e3a8-regParam: 0.5\n}, {\n\tlogreg_07a16d69e3a8-elasticNetParam: 0.0,\n\tlogreg_07a16d69e3a8-maxIter: 1,\n\tlogreg_07a16d69e3a8-regParam: 2.0\n}, {\n\tlogreg_07a16d69e3a8-elasticNetParam: 0.0,\n\tlogreg_07a16d69e3a8-maxIter: 5,\n\tlogreg_07a16d69e3a8-regParam: 0.01\n}, {\n\tlogreg_07a16d69e3a8-elasticNetParam: 0.0,\n\tlogreg_07a16d69e3a8-maxIter: 5,\n\tlogreg_07a16d69e3a8-regParam: 0.5\n}, {\n\tlogreg_07a16d69e3a8-elasticNetParam: 0.0,\n\tlogreg_07a16d69e3a8-maxIter: 5,\n\tlogreg_07a16d69e3a8-regParam: 2.0\n}, {\n\tlogreg_07a16d69e3a8-elasticNetParam...\ncross_validator: org.apache.spark.ml.tuning.CrossValidator \u003d cv_7400a16290be\n\ncross_validator_model: org.apache.spark.ml.tuning.CrossValidatorModel \u003d cv_7400a16290be\n\ncross_predictions: org.apache.spark.sql.DataFrame \u003d [age: double, workclass: string ... 34 more fields]\n\nbestlrmodel: org.apache.spark.ml.classification.LogisticRegressionModel \u003d logreg_07a16d69e3a8\nres148: org.apache.spark.ml.linalg.Vector \u003d [0.017865685096445604,3.967768844154347E-7,-0.02498995123445402,1.270805171087459E-4,5.10760405187202E-4,0.0217390508506064,-0.2934121887229082,-0.5802444736845727,-0.5142086912109746,-0.4842127573371585,-0.5749558448028044,-0.020428386503197976,0.11730719375386937,-2.6005879963692085,-0.5905856515386033,-0.24761899129988157,0.5755953067514141,0.9322817863992886,-0.03858374881561568,-1.159748783778088,-0.025039055043467054,-1.1657918441023756,-1.7829696269910036,1.3817315203305227,-1.416637496682101,-0.8298866889809057,1.6899340619886432,-1.455142893548472,-1.8493247854433255,0.527868195667099,-1.0262008953757613,-0.4794095782404404,-0.4546668211160966,-0.40268478386784995,-0.43998737732794224,0.27630009516012227,-0.14167763975454062,0.4589099...\nres149: Double \u003d -1.391928967866985\n\n\n\n\u003cconsole\u003e:150: error: value stages is not a member of org.apache.spark.ml.classification.LogisticRegressionModel\n       val best_stages \u003d bestlrmodel.stages\n                                     ^\n"
      },
      "dateCreated": "Feb 20, 2017 1:25:12 PM",
      "dateStarted": "Feb 20, 2017 2:37:56 PM",
      "dateFinished": "Feb 20, 2017 2:39:27 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nOther models\n--------\nJust for fun let’s try the other models",
      "dateUpdated": "Feb 20, 2017 2:40:04 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487601514068_-1622881178",
      "id": "20170220-143834_1888153066",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eOther models\u003c/h2\u003e\n\u003cp\u003eJust for fun let’s try the other models\u003c/p\u003e\n"
      },
      "dateCreated": "Feb 20, 2017 2:38:34 PM",
      "dateStarted": "Feb 20, 2017 2:40:04 PM",
      "dateFinished": "Feb 20, 2017 2:40:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Feb 20, 2017 2:40:20 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1487601610453_545733833",
      "id": "20170220-144010_1949433206",
      "dateCreated": "Feb 20, 2017 2:40:10 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\nThe column `features` is a Vector, and Spark MLlib has specific functions to analyse it. You can `collect()` the column into an array then `map` each `Row` into a `Vector`.\n\n```\nimport org.apache.spark.mllib.linalg.Vector\n\ndf.select(\"features\").rdd.map(t \u003d\u003e t.getAs[Vector](0))\n```\n\n1. Run [basic statistics](http://spark.apache.org/docs/latest/mllib-statistics.html) on the column which contains your features vector.\n2. Check for the columns that are the most [correlated](http://spark.apache.org/docs/latest/mllib-statistics.html#correlations) to your label column.\n3. Conclude on the interesting columns to use if you had to do manual feature selection. Don\u0027t forget the nature of the data you are dealing with.",
      "dateUpdated": "Feb 7, 2017 12:55:45 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486114332673_-1809154654",
      "id": "20170203-093212_958935340",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch4 style\u003d\"color:red;\"\u003eOptional question\u003c/h4\u003e\n\u003cp\u003eThe column \u003ccode\u003efeatures\u003c/code\u003e is a Vector, and Spark MLlib has specific functions to analyse it. You can \u003ccode\u003ecollect()\u003c/code\u003e the column into an array then \u003ccode\u003emap\u003c/code\u003e each \u003ccode\u003eRow\u003c/code\u003e into a \u003ccode\u003eVector\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eimport org.apache.spark.mllib.linalg.Vector\n\ndf.select(\"features\").rdd.map(t \u003d\u0026gt; t.getAs[Vector](0))\n\u003c/code\u003e\u003c/pre\u003e\n\u003col\u003e\n\u003cli\u003eRun \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html\"\u003ebasic statistics\u003c/a\u003e on the column which contains your features vector.\u003c/li\u003e\n\u003cli\u003eCheck for the columns that are the most \u003ca href\u003d\"http://spark.apache.org/docs/latest/mllib-statistics.html#correlations\"\u003ecorrelated\u003c/a\u003e to your label column.\u003c/li\u003e\n\u003cli\u003eConclude on the interesting columns to use if you had to do manual feature selection. Don\u0027t forget the nature of the data you are dealing with.\u003c/li\u003e\n\u003c/ol\u003e\n"
      },
      "dateCreated": "Feb 3, 2017 9:32:12 AM",
      "dateStarted": "Feb 7, 2017 12:55:45 PM",
      "dateFinished": "Feb 7, 2017 12:55:45 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Feb 7, 2017 12:55:46 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1486398557317_-983551642",
      "id": "20170206-162917_1903479723",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Feb 6, 2017 4:29:17 AM",
      "dateStarted": "Feb 7, 2017 12:56:52 PM",
      "dateFinished": "Feb 7, 2017 12:57:05 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "BinaryClassification",
  "id": "2C76YWXDZ",
  "angularObjects": {
    "2CBDM59Z8:shared_process": [],
    "2CATEG8B7:shared_process": [],
    "2CB595S9J:shared_process": [],
    "2C9Q96H4M:shared_process": [],
    "2CCA38X15:shared_process": [],
    "2CAZV1MT5:shared_process": [],
    "2C92V4JQ9:shared_process": [],
    "2C8Q2DUR9:shared_process": [],
    "2CB38AXYK:shared_process": [],
    "2CBKRZPB1:shared_process": [],
    "2C9P7XWN9:shared_process": [],
    "2CAH3QZUE:shared_process": [],
    "2C97CUJWC:shared_process": [],
    "2CA74QH6C:shared_process": [],
    "2C9GN7RDC:shared_process": [],
    "2CCCRWCRN:shared_process": [],
    "2C9PP5NAZ:shared_process": [],
    "2CC3P8MV9:shared_process": []
  },
  "config": {},
  "info": {}
}